{\rtf1\ansi\ansicpg1252\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Bold;\f1\froman\fcharset0 Times-Roman;\f2\fswiss\fcharset0 Helvetica;
\f3\fmodern\fcharset0 Courier;\f4\fswiss\fcharset0 Arial-BoldMT;\f5\fswiss\fcharset0 ArialMT;
}
{\colortbl;\red255\green255\blue255;\red24\green25\blue27;\red255\green255\blue255;\red0\green0\blue0;
\red24\green24\blue24;\red227\green236\blue254;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c12549\c12941\c14118;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0\c5098;
\cssrgb\c12157\c12157\c12157;\cssrgb\c90980\c94118\c99608;\cssrgb\c0\c0\c0;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid12}
{\list\listtemplateid13\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid13}
{\list\listtemplateid14\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid14}
{\list\listtemplateid15\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid15}
{\list\listtemplateid16\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid16}
{\list\listtemplateid17\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid17}
{\list\listtemplateid18\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid18}
{\list\listtemplateid19\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid19}
{\list\listtemplateid20\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat4\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid20}
{\list\listtemplateid21\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid21}
{\list\listtemplateid22\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid22}
{\list\listtemplateid23\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid23}
{\list\listtemplateid24\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid24}
{\list\listtemplateid25\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid25}
{\list\listtemplateid26\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid26}
{\list\listtemplateid27\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid27}
{\list\listtemplateid28\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid28}
{\list\listtemplateid29\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid29}
{\list\listtemplateid30\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid30}
{\list\listtemplateid31\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid31}
{\list\listtemplateid32\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid32}
{\list\listtemplateid33\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid33}
{\list\listtemplateid34\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid3301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid34}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}{\listoverride\listid13\listoverridecount0\ls13}{\listoverride\listid14\listoverridecount0\ls14}{\listoverride\listid15\listoverridecount0\ls15}{\listoverride\listid16\listoverridecount0\ls16}{\listoverride\listid17\listoverridecount0\ls17}{\listoverride\listid18\listoverridecount0\ls18}{\listoverride\listid19\listoverridecount0\ls19}{\listoverride\listid20\listoverridecount0\ls20}{\listoverride\listid21\listoverridecount0\ls21}{\listoverride\listid22\listoverridecount0\ls22}{\listoverride\listid23\listoverridecount0\ls23}{\listoverride\listid24\listoverridecount0\ls24}{\listoverride\listid25\listoverridecount0\ls25}{\listoverride\listid26\listoverridecount0\ls26}{\listoverride\listid27\listoverridecount0\ls27}{\listoverride\listid28\listoverridecount0\ls28}{\listoverride\listid29\listoverridecount0\ls29}{\listoverride\listid30\listoverridecount0\ls30}{\listoverride\listid31\listoverridecount0\ls31}{\listoverride\listid32\listoverridecount0\ls32}{\listoverride\listid33\listoverridecount0\ls33}{\listoverride\listid34\listoverridecount0\ls34}}
\paperw11900\paperh16840\margl1440\margr1440\vieww33100\viewh16740\viewkind0
\deftab720
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Overview\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 Performance tuning of BigQuery is usually carried out because we wish to reduce query execution times or cost. In this lab, we will look at a number of performance optimizations that might work for your use case. Performance tuning should be carried out only at the end of the development stage, and only if it is observed that typical queries take too long.\
It is far better to have flexible table schemas and elegant, readable, and maintainable queries than to obfuscate table layouts and queries in search of a tiny bit of performance. However, there will be instances where you do need to improve the performance of your queries, perhaps because they are carried out so often that small improvements are meaningful. Another aspect is that knowledge of performance tradeoffs can help you in deciding between alternative designs.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Objectives\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 In this lab, you learn about the following techniques for reducing BigQuery execution times and costs:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Minimizing I/O\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Caching results of previous queries\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Performing efficient joins\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Avoid overwhelming single workers\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Using approximate aggregation functions\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\cf2 \
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 Open BigQuery Console\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0
\f1\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Google Cloud Console, select\'a0
\f0\b Navigation menu
\f1\b0 \'a0>\'a0
\f0\b BigQuery
\f1\b0 .\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 The\'a0
\f0\b \cf2 \cb3 \strokec2 Welcome to BigQuery in the Cloud Console
\f1\b0 \cf2 \cb3 \strokec2 \'a0message box opens. This message box provides a link to the quickstart guide and lists UI updates.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Done
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\cf2 \strokec2 \
\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 Task 1. Minimize I/O\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 A query that computes the sum of three columns will be slower than a query that computes the sum of two columns, but most of the performance difference will be due to reading more data, not the extra addition. Therefore, a query that computes the mean of a column will be nearly as fast as a query whose aggregation method is to compute the variance of the data (even though computing variance requires BigQuery to keep track of both the sum and the sum of the squares) because most of the overhead of simple queries is caused by I/O, not by computation.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Be purposeful in SELECT\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 Because BigQuery uses columnar file formats, the fewer the columns that are read in a SELECT, the less the amount of data that needs to be read. In particular, doing a SELECT * reads every column of every row in the table, making it quite slow and expensive.\
The exception is when you use a SELECT * in a subquery, then only reference a few fields in an outer query; the BigQuery optimizer will be smart enough to only read the columns that are absolutely required.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls4\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Execute the following query in the\'a0{\field{\*\fldinst{HYPERLINK "https://console.cloud.google.com/bigquery"}}{\fldrslt BigQuery EDITOR window}}:\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  bike_id,\
  duration\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire\
ORDER BY\
  duration DESC\
LIMIT\
  1\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 In the\'a0
\f0\b \cf2 \cb3 \strokec2 Query results
\f1\b0 \cf2 \cb3 \strokec2 \'a0window notice that the query completed in ~1.2s and processed ~372MB of data.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls5\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Execute the following query in the BigQuery EDITOR window:\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  *\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire\
ORDER BY\
  duration DESC\
LIMIT\
  1\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 In the\'a0
\f0\b \cf2 \cb3 \strokec2 Query results
\f1\b0 \cf2 \cb3 \strokec2 \'a0window notice that this query completed in ~4.5s and consumed ~2.6GB of data. Much longer!\
If you require nearly all the columns in a table, consider using\'a0
\f3\fs30 \cf2 \cb4 \strokec2 SELECT * EXCEPT
\f1\fs32 \cf2 \cb3 \strokec2 \'a0so as to not read the ones you don\'92t require.\
\pard\pardeftab720\partightenfactor0

\f4\b\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf5 \cb6 \strokec5 Note:\'a0
\f1\b0 \AppleTypeServices BigQuery will cache query results to speed up repeat queries. Turn off this cache to see actual query processing performance by clicking
\f5 \AppleTypeServices\AppleTypeServicesF65539 \'a0
\f4\b \AppleTypeServices\AppleTypeServicesF65539 More > Query settings
\f5\b0 \AppleTypeServices\AppleTypeServicesF65539 \'a0
\f1 \AppleTypeServices and un-checking
\f5 \AppleTypeServices\AppleTypeServicesF65539 \'a0
\f4\b \AppleTypeServices\AppleTypeServicesF65539 Use cached results
\f1\b0 \AppleTypeServices .
\f5 \AppleTypeServices\AppleTypeServicesF65539 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \AppleTypeServices \cf2 \cb3 \strokec2 Reduce data being read\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 When tuning a query, it is important to start with the data that is being read and consider whether it is possible to reduce this. Suppose we wish to find the typical duration of the most common one-way rentals.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls6\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Execute the following query into the BigQuery editor window:\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  MIN(start_station_name) AS start_station_name,\
  MIN(end_station_name) AS end_station_name,\
  APPROX_QUANTILES(duration, 10)[OFFSET (5)] AS typical_duration,\
  COUNT(duration) AS num_trips\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire\
WHERE\
  start_station_id != end_station_id\
GROUP BY\
  start_station_id,\
  end_station_id\
ORDER BY\
  num_trips DESC\
LIMIT\
  10\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 The output of your query should look similar to the following:\
\
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \cb1 \strokec7 {{\NeXTGraphic w1OICOPlBwD39TDdWQcqdsmlna49AsHdXEcDOqXUlmc=.png \width13200 \height7660 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls7\ilvl0
\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click on the\'a0
\f0\b Execution details
\f1\b0 \'a0tab of the\'a0
\f0\b Query results
\f1\b0 \'a0window.\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 The details of the query indicate that the sorting (for the approximate quantiles for every station pair) required a repartition of the outputs of the input stage but most of the time is spent during computation.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls8\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 We can reduce the I/O overhead of the query if we do the filtering and grouping using the station name rather than the station id since we will need to read fewer columns. Execute the following query:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  start_station_name,\
  end_station_name,\
  APPROX_QUANTILES(duration, 10)[OFFSET(5)] AS typical_duration,\
  COUNT(duration) AS num_trips\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire\
WHERE\
  start_station_name != end_station_name\
GROUP BY\
  start_station_name,\
  end_station_name\
ORDER BY\
  num_trips DESC\
LIMIT\
  10\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 The above query avoids the need to read the two id columns and finishes in 10.8 seconds. This speedup is caused by the downstream effects of reading less data.\
The query result remains the same since there is a 1:1 relationship between the station name and the station id.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Reduce number of expensive computations\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 Suppose we wish to find the total distance traveled by each bicycle in our dataset.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls9\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 A naive way to do this would be to find the distance traveled in each trip undertaken by each bicycle and sum them up:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
WITH\
  trip_distance AS (\
SELECT\
  bike_id,\
  ST_Distance(ST_GeogPoint(s.longitude,\
      s.latitude),\
    ST_GeogPoint(e.longitude,\
      e.latitude)) AS distance\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire,\
  `bigquery-public-data`.london_bicycles.cycle_stations s,\
  `bigquery-public-data`.london_bicycles.cycle_stations e\
WHERE\
  start_station_id = s.id\
  AND end_station_id = e.id )\
SELECT\
  bike_id,\
  SUM(distance)/1000 AS total_distance\
FROM\
  trip_distance\
GROUP BY\
  bike_id\
ORDER BY\
  total_distance DESC\
LIMIT\
  5\
\
\
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \strokec7 {{\NeXTGraphic aS1KuNZDksjrAydT1AYbsB0NuEOaV7d4IdcqK00WGHc=.png \width4620 \height3640 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \strokec7 \
\
\pard\pardeftab720\sa480\partightenfactor0

\fs32 \cf2 \cb3 \strokec2 The above query takes 9.8 seconds (55 seconds of slot time) and shuffles 1.22 MB. The result is that some bicycles have been ridden nearly 6000 kilometers.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls10\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Computing the distance is a pretty expensive operation and we can avoid joining the\'a0
\f3\fs30 \cb4 cycle_stations
\f1\fs32 \cb3 \'a0table against the\'a0
\f3\fs30 \cb4 cycle_hire table
\f1\fs32 \cb3 \'a0if we precompute the distances between all pairs of stations:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
WITH\
  stations AS (\
SELECT\
  s.id AS start_id,\
  e.id AS end_id,\
  ST_Distance(ST_GeogPoint(s.longitude,\
      s.latitude),\
    ST_GeogPoint(e.longitude,\
      e.latitude)) AS distance\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_stations s,\
  `bigquery-public-data`.london_bicycles.cycle_stations e ),\
trip_distance AS (\
SELECT\
  bike_id,\
  distance\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire,\
  stations\
WHERE\
  start_station_id = start_id\
  AND end_station_id = end_id )\
SELECT\
  bike_id,\
  SUM(distance)/1000 AS total_distance\
FROM\
  trip_distance\
GROUP BY\
  bike_id\
ORDER BY\
  total_distance DESC\
LIMIT\
  5\
\
\cf2 \cb3 \strokec2 This query only makes 600k geo-distance calculations vs. 24M previously. Now it takes 31.5 seconds of slot time (a 30% speedup), despite shuffling 33.05MB of data.\
\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Task 2. Cache results of previous queries\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 The BigQuery service automatically caches query results in a temporary table. If the identical query is submitted within approximately 24 hours, the results are served from this temporary table without any recomputation. Cached results are extremely fast and do not incur charges.\
There are, however, a few caveats to be aware of. Query caching is based on exact string comparison. So even whitespaces can cause a cache miss. Queries are never cached if they exhibit non-deterministic behavior (for example, they use CURRENT_TIMESTAMP or RAND), if the table or view being queried has changed (even if the columns/rows of interest to the query are unchanged), if the table is associated with a streaming buffer (even if there are no new rows), if the query uses DML statements, or queries external data sources.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Cache intermediate results\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 It is possible to improve overall performance at the expense of increased I/O by taking advantage of temporary tables and materialized views.\
For example, suppose you have a number of queries that start out by finding the typical duration of trips between a pair of stations. The WITH clause (also called a Common Table Expression) improves readability but does not improve query speed or cost since results are not cached. The same holds for views and subqueries as well. If you find yourself using a WITH clause, view, or a subquery often, one way to potentially improve performance is to store the result into a table (or materialized view).\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls11\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 First you will need to create a dataset named\'a0
\f3\fs30 \cb4 mydataset
\f1\fs32 \cb3 \'a0in the\'a0
\f3\fs30 \cb4 eu (multiple regions in European Union)
\f1\fs32 \cb3 \'a0region (where the bicycle data resides) under your project in BigQuery.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls12\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the left pane in the\'a0
\f0\b Explorer
\f1\b0 \'a0section, click on the\'a0
\f0\b View action
\f1\b0 \'a0icon (three dots) near your BigQuery project (
\f3\fs30 \cb4 qwiklabs-gcp-xxxx
\f1\fs32 \cb3 ) and select\'a0
\f0\b Create dataset
\f1\b0 .\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 In the\'a0
\f0\b \cf2 \cb3 \strokec2 Create dataset
\f1\b0 \cf2 \cb3 \strokec2 \'a0dialog:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls13\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Set the\'a0
\f0\b Dataset ID
\f1\b0 \'a0to\'a0
\f3\fs30 \cb4 mydataset
\f1\fs32 \cb3 .\cb1 \
\ls13\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Set the\'a0
\f0\b Data location
\f1\b0 \'a0to\'a0
\f3\fs30 \cb4 eu (multiple regions in European Union)
\f1\fs32 \cb3 .\cb1 \
\ls13\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Leave all other options at their default values.\cb1 \
\ls13\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To finish, click the blue\'a0
\f0\b CREATE DATASET
\f1\b0 \'a0button.\cb1 \
\ls13\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Now you may execute the following query:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
CREATE OR REPLACE TABLE\
  mydataset.typical_trip AS\
SELECT\
  start_station_name,\
  end_station_name,\
  APPROX_QUANTILES(duration, 10)[OFFSET (5)] AS typical_duration,\
  COUNT(duration) AS num_trips\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire\
GROUP BY\
  start_station_name,\
  end_station_name\
\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls14\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Use the table created to find days when bicycle trips are much longer than usual:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  EXTRACT (DATE\
  FROM\
    start_date) AS trip_date,\
  APPROX_QUANTILES(duration / typical_duration, 10)[OFFSET(5)] AS ratio,\
  COUNT(*) AS num_trips_on_day\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire AS hire\
JOIN\
  mydataset.typical_trip AS trip\
ON\
  hire.start_station_name = trip.start_station_name\
  AND hire.end_station_name = trip.end_station_name\
  AND num_trips > 10\
GROUP BY\
  trip_date\
HAVING\
  num_trips_on_day > 10\
ORDER BY\
  ratio DESC\
LIMIT\
  10\
\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls15\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Use the WITH clause to find days when bicycle trips are much longer than usual:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
WITH\
typical_trip AS (\
SELECT\
  start_station_name,\
  end_station_name,\
  APPROX_QUANTILES(duration, 10)[OFFSET (5)] AS typical_duration,\
  COUNT(duration) AS num_trips\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire\
GROUP BY\
  start_station_name,\
  end_station_name )\
SELECT\
  EXTRACT (DATE\
  FROM\
    start_date) AS trip_date,\
  APPROX_QUANTILES(duration / typical_duration, 10)[\
OFFSET\
  (5)] AS ratio,\
  COUNT(*) AS num_trips_on_day\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire AS hire\
JOIN\
  typical_trip AS trip\
ON\
  hire.start_station_name = trip.start_station_name\
  AND hire.end_station_name = trip.end_station_name\
  AND num_trips > 10\
GROUP BY\
  trip_date\
HAVING\
  num_trips_on_day > 10\
ORDER BY\
  ratio DESC\
LIMIT\
10\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 Notice the ~50% speedup since the average trip duration computation is avoided. Both queries return the same result, that trips on Christmas take longer than usual. Note, the table\'a0
\f3\fs30 \cf2 \cb4 \strokec2 mydataset.typical_trip
\f1\fs32 \cf2 \cb3 \strokec2 \'a0is not refreshed when new data is added to the\'a0
\f3\fs30 \cf2 \cb4 \strokec2 cycle_hire
\f1\fs32 \cf2 \cb3 \strokec2 \'a0table.\
One way to solve this problem of stale data is to use a materialized view or to schedule queries to update the table periodically. You should measure the cost of such updates to see whether the improvement in query performance makes up for the extra cost of maintaining the table or materialized view up-to-date.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Accelerate queries with BI Engine\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 If there are tables that you access frequently in Business Intelligence (BI) settings such as dashboards with aggregations and filters, one way to speed up your queries is to employ\'a0
\f0\b \cf2 \cb3 \strokec2 BI Engine
\f1\b0 \cf2 \cb3 \strokec2 . It will automatically store relevant pieces of data in memory (either actual columns from the table or derived results), and will use a specialized query processor tuned for working with mostly in-memory data. You can reserve the amount of memory (up to a current maximum of 10 GB) that BigQuery should use for its cache from the BigQuery Admin Console, under\'a0
\f0\b \cf2 \cb3 \strokec2 BI Engine
\f1\b0 \cf2 \cb3 \strokec2 .\
Make sure to reserve this memory in the same region as the dataset you are querying. Then, BigQuery will start to cache tables, parts of tables, and aggregations in memory and serve results faster.\
A primary use case for BI Engine is for tables that are accessed from dashboard tools such as Google Data Studio. By providing memory allocation for a BI Engine reservation, we can make dashboards that rely on a BigQuery backend much more responsive.\
Click\'a0
\f0\b \cf2 \cb3 \strokec2 Check my progress
\f1\b0 \cf2 \cb3 \strokec2 \'a0to verify the objective.\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 Task 3. Efficient joins\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 Joining two tables requires data coordination and is subject to limitations imposed by the communication bandwidth between slots. If it is possible to avoid a join, or reduce the amount of data being joined, do so.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Denormalization\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 One way to improve the read performance and avoid joins is to give up on storing data efficiently, and instead add redundant copies of data. This is called denormalization.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls16\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Thus, instead of storing the bicycle station latitudes and longitudes separately from the cycle hire information, we could create a denormalized table:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
CREATE OR REPLACE TABLE\
  mydataset.london_bicycles_denorm AS\
SELECT\
  start_station_id,\
  s.latitude AS start_latitude,\
  s.longitude AS start_longitude,\
  end_station_id,\
  e.latitude AS end_latitude,\
  e.longitude AS end_longitude\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire AS h\
JOIN\
  `bigquery-public-data`.london_bicycles.cycle_stations AS s\
ON\
  h.start_station_id = s.id\
JOIN\
  `bigquery-public-data`.london_bicycles.cycle_stations AS e\
ON\
  h.end_station_id = e.id\
\
\cf2 \cb3 \strokec2 Then, all subsequent queries will not need to carry out the join because the table will contain the necessary location information for all trips.\'a0In this case, you are trading off storage and reading more data against the computational expense of a join. It is quite possible that the cost of reading more data from disk will outweigh the cost of the join -- you should measure whether denormalization brings performance benefits.\'a0Click\'a0
\f0\b \cf2 \cb3 \strokec2 Check my progress
\f1\b0 \cf2 \cb3 \strokec2 \'a0to verify the objective.\
\
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Avoid self-joins of large tables\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 Self-joins happen when a table is joined with itself. While BigQuery supports self-joins, they can lead to performance degradation if the table being joined with itself is very large. In many cases, you can avoid the self-join by taking advantage of SQL features such as aggregation and window functions.\
Let\'92s look at an example. One of the BigQuery public datasets is the dataset of baby names published by the US Social Security Administration.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls17\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 It is possible to query the dataset to find the most common male names in 2015 in the state of Massachusetts (Make sure your query is running in the US (multiple regions in United States) region. Click\'a0
\f0\b Compose New Query
\f1\b0 \'a0then select\'a0
\f0\b More
\f1\b0 \'a0>\'a0
\f0\b Query settings
\f1\b0 \'a0>\'a0
\f0\b Advanced options
\f1\b0 , uncheck\'a0
\f0\b Automatic location selection
\f1\b0 \'a0and select\'a0
\f0\b Multi Region
\f1\b0 \'a0and select\'a0
\f0\b US (Multiple Regions in United States)
\f1\b0 \'a0or leave query to use\'a0
\f0\b Automatic location
\f1\b0 \'a0selection):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  name,\
  number AS num_babies\
FROM\
  `bigquery-public-data`.usa_names.usa_1910_current\
WHERE\
  gender = 'M'\
  AND year = 2015\
  AND state = 'MA'\
ORDER BY\
  num_babies DESC\
LIMIT\
  5\
\
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \strokec7 {{\NeXTGraphic anBzTP8j3A2emvXnCLULJXqdUEBZw=.png \width3840 \height3560 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \strokec7 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls18\ilvl0
\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Similarly, query the dataset to find the most common female names in 2015 in the state of Massachusetts:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
\
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \strokec7 {{\NeXTGraphic rWO89zbfs5ELZ1hEmthfYvNATfW2xvPgUR7zO4NRl7M=.png \width3840 \height3560 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \strokec7 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls19\ilvl0
\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 What are the most common names assigned to both male and female babies in the country over all the years in the dataset? A naive way to solve this problem involves reading the input table twice and doing a self-join:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
WITH\
male_babies AS (\
SELECT\
  name,\
  number AS num_babies\
FROM\
  `bigquery-public-data`.usa_names.usa_1910_current\
WHERE\
  gender = 'M' ),\
female_babies AS (\
SELECT\
  name,\
  number AS num_babies\
FROM\
  `bigquery-public-data`.usa_names.usa_1910_current\
WHERE\
  gender = 'F' ),\
both_genders AS (\
SELECT\
  name,\
  SUM(m.num_babies) + SUM(f.num_babies) AS num_babies,\
  SUM(m.num_babies) / (SUM(m.num_babies) + SUM(f.num_babies)) AS frac_male\
FROM\
  male_babies AS m\
JOIN\
  female_babies AS f\
USING\
  (name)\
GROUP BY\
  name )\
SELECT\
  *\
FROM\
  both_genders\
WHERE\
  frac_male BETWEEN 0.3\
  AND 0.7\
ORDER BY\
  num_babies DESC\
LIMIT\
  5\
\
\cf2 \cb3 \strokec2 This took 74 seconds and yielded:\
\
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \cb1 \strokec7 {{\NeXTGraphic 4L4R0uX8T8NffH1L5yHbt7ejUte6HamV8nFUoP44FE4=.png \width6380 \height3540 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \strokec7 \
\
\pard\pardeftab720\sa480\partightenfactor0

\fs32 \cf2 \cb3 \strokec2 To add insult to injury, the answer is also wrong -- as much as we like the name Jordan, the entire US population is only 300 million, so there cannot have been 982 million babies with that name. The self-JOIN unfortunately joins across state and year boundaries.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls20\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 A faster, more elegant (and correct!) solution is to recast the query to read the input only once and avoid the self-join completely:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
WITH\
all_babies AS (\
SELECT\
  name,\
  SUM(\
  IF\
    (gender = 'M',\
      number,\
      0)) AS male_babies,\
  SUM(\
  IF\
    (gender = 'F',\
      number,\
      0)) AS female_babies\
FROM\
  `bigquery-public-data.usa_names.usa_1910_current`\
GROUP BY\
  name ),\
both_genders AS (\
SELECT\
  name,\
  (male_babies + female_babies) AS num_babies,\
  SAFE_DIVIDE(male_babies,\
    male_babies + female_babies) AS frac_male\
FROM\
  all_babies\
WHERE\
  male_babies > 0\
  AND female_babies > 0 )\
SELECT\
  *\
FROM\
  both_genders\
WHERE\
  frac_male BETWEEN 0.3\
  AND 0.7\
ORDER BY\
  num_babies DESC\
LIMIT\
  5\
\
\pard\pardeftab720\sa480\partightenfactor0

\fs24 \cf2 \strokec2 This took only 2.4 seconds, a 30x speedup.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Reduce data being joined\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs24 \cf2 It is possible to carry out the query above with an efficient join as long as we reduce the amount of data being joined by grouping the data by name and gender early on:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls21\ilvl0
\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Try the following query:\cb1 \uc0\u8232 
\fs24 \
\pard\pardeftab720\partightenfactor0

\fs32 \cf2 \strokec2 WITH\
all_names AS (\
SELECT\
  name,\
  gender,\
  SUM(number) AS num_babies\
FROM\
  `bigquery-public-data`.usa_names.usa_1910_current\
GROUP BY\
  name,\
  gender ),\
male_names AS (\
SELECT\
  name,\
  num_babies\
FROM\
  all_names\
WHERE\
  gender = 'M' ),\
female_names AS (\
SELECT\
  name,\
  num_babies\
FROM\
  all_names\
WHERE\
  gender = 'F' ),\
ratio AS (\
SELECT\
  name,\
  (f.num_babies + m.num_babies) AS num_babies,\
  m.num_babies / (f.num_babies + m.num_babies) AS frac_male\
FROM\
  male_names AS m\
JOIN\
  female_names AS f\
USING\
  (name) )\
SELECT\
  *\
FROM\
  ratio\
WHERE\
  frac_male BETWEEN 0.3\
  AND 0.7\
ORDER BY\
  num_babies DESC\
LIMIT\
  5\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls22\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The early grouping served to trim the data early in the query, before the query performs a JOIN. That way, shuffling and other complex operations are only executed on the much smaller data and remain quite efficient. The query above finished in 2 seconds and returned the correct result.\cb1 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Use a window function instead of a self-join\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 Suppose you wish to find the duration between a bike being dropped off and it being rented again, i.e., the duration that a bicycle stays at the station. This is an example of a dependent relationship between rows. It might appear that the only way to solve this is to join the table with itself, matching the\'a0
\f3\fs30 \cf2 \cb4 \strokec2 end_date
\f1\fs32 \cf2 \cb3 \strokec2 \'a0of one trip against the\'a0
\f3\fs30 \cf2 \cb4 \strokec2 start_date
\f1\fs32 \cf2 \cb3 \strokec2 \'a0of the next. (Make sure your query is running in the\'a0
\f3\fs30 \cf2 \cb4 \strokec2 eu (multiple regions in European Union)
\f1\fs32 \cf2 \cb3 \strokec2 \'a0region. Click\'a0
\f0\b \cf2 \cb3 \strokec2 Compose New Query
\f1\b0 \cf2 \cb3 \strokec2 \'a0and then select\'a0
\f0\b \cf2 \cb3 \strokec2 More
\f1\b0 \cf2 \cb3 \strokec2 \'a0>\'a0
\f0\b \cf2 \cb3 \strokec2 Query settings
\f1\b0 \cf2 \cb3 \strokec2 \'a0>\'a0
\f0\b \cf2 \cb3 \strokec2 Additional settings
\f1\b0 \cf2 \cb3 \strokec2 \'a0>\'a0
\f0\b \cf2 \cb3 \strokec2 Data location
\f1\b0 \cf2 \cb3 \strokec2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls23\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 You can, however, avoid a self-join by using a window function:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  bike_id,\
  start_date,\
  end_date,\
  TIMESTAMP_DIFF( start_date, LAG(end_date) OVER (PARTITION BY bike_id ORDER BY start_date), SECOND) AS time_at_station\
FROM\
  `bigquery-public-data`.london_bicycles.cycle_hire\
LIMIT\
  5\
\
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \strokec7 {{\NeXTGraphic Cwe7R8ygd+nZ7TynpCx3XM0cO3nIj61rzY=.png \width13640 \height2960 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \strokec7 \
\
\pard\pardeftab720\sa480\partightenfactor0

\fs32 \cf2 \cb3 \strokec2 Notice that the first row has a\'a0
\f3\fs30 \cf2 \cb4 \strokec2 null
\f1\fs32 \cf2 \cb3 \strokec2 \'a0for\'a0
\f3\fs30 \cf2 \cb4 \strokec2 time_at_station
\f1\fs32 \cf2 \cb3 \strokec2 \'a0since we don\'92t have a timestamp for the previous dropoff. After that, the\'a0
\f3\fs30 \cf2 \cb4 \strokec2 time_at_station
\f1\fs32 \cf2 \cb3 \strokec2 \'a0tracks the difference between the previous dropoff and the current pickup.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls24\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Using this, we can compute the average time that a bicycle is unused at each station and rank stations by that measure:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
WITH\
  unused AS (\
  SELECT\
    bike_id,\
    start_station_name,\
    start_date,\
    end_date,\
    TIMESTAMP_DIFF(start_date, LAG(end_date) OVER (PARTITION BY bike_id ORDER BY start_date), SECOND) AS time_at_station\
  FROM\
    `bigquery-public-data`.london_bicycles.cycle_hire )\
SELECT\
  start_station_name,\
  AVG(time_at_station) AS unused_seconds\
FROM\
  unused\
GROUP BY\
  start_station_name\
ORDER BY\
  unused_seconds ASC\
LIMIT\
  5\
\
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \strokec7 {{\NeXTGraphic dFEKbooFvzlvT64jxTaKzy0Y2Wf2gYifs=.png \width7720 \height3560 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \strokec7 \
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Join with precomputed values\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 Sometimes, it can be helpful to precompute functions on smaller tables, and then join with the precomputed values rather than repeat an expensive calculation each time.\
For example, suppose we wish to find the pair of stations between which our customers ride bicycles at the fastest pace. To compute the pace (minutes per kilometer) at which they ride, we need to divide the duration of the ride by the distance between stations.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls25\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 We could create a denormalized table with distances between stations and then compute the average pace:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
WITH\
  denormalized_table AS (\
  SELECT\
    start_station_name,\
    end_station_name,\
    ST_DISTANCE(ST_GeogPoint(s1.longitude,\
        s1.latitude),\
      ST_GeogPoint(s2.longitude,\
        s2.latitude)) AS distance,\
    duration\
  FROM\
    `bigquery-public-data`.london_bicycles.cycle_hire AS h\
  JOIN\
    `bigquery-public-data`.london_bicycles.cycle_stations AS s1\
  ON\
    h.start_station_id = s1.id\
  JOIN\
    `bigquery-public-data`.london_bicycles.cycle_stations AS s2\
  ON\
    h.end_station_id = s2.id ),\
  durations AS (\
  SELECT\
    start_station_name,\
    end_station_name,\
    MIN(distance) AS distance,\
    AVG(duration) AS duration,\
    COUNT(*) AS num_rides\
  FROM\
    denormalized_table\
  WHERE\
    duration > 0\
    AND distance > 0\
  GROUP BY\
    start_station_name,\
    end_station_name\
  HAVING\
    num_rides > 100 )\
SELECT\
  start_station_name,\
  end_station_name,\
  distance,\
  duration,\
  duration/distance AS pace\
FROM\
  durations\
ORDER BY\
  pace ASC\
LIMIT\
  5\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 The above query invokes the geospatial function\'a0
\f3\fs30 \cf2 \cb4 \strokec2 ST_DISTANCE
\f1\fs32 \cf2 \cb3 \strokec2 \'a0once for each row in the\'a0
\f3\fs30 \cf2 \cb4 \strokec2 cycle_hire
\f1\fs32 \cf2 \cb3 \strokec2 \'a0table (24 million times), takes 14.7 seconds and processes 1.9 GB.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls26\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Alternately, we can use the\'a0
\f3\fs30 \cb4 cycle_stations
\f1\fs32 \cb3 \'a0table to precompute the distance between every pair of stations (this is a self-join) and then join it with the reduced-size table of average duration between stations:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
WITH\
  distances AS (\
  SELECT\
    a.id AS start_station_id,\
    a.name AS start_station_name,\
    b.id AS end_station_id,\
    b.name AS end_station_name,\
    ST_DISTANCE(ST_GeogPoint(a.longitude,\
        a.latitude),\
      ST_GeogPoint(b.longitude,\
        b.latitude)) AS distance\
  FROM\
    `bigquery-public-data`.london_bicycles.cycle_stations a\
  CROSS JOIN\
    `bigquery-public-data`.london_bicycles.cycle_stations b\
  WHERE\
    a.id != b.id ),\
  durations AS (\
  SELECT\
    start_station_id,\
    end_station_id,\
    AVG(duration) AS duration,\
    COUNT(*) AS num_rides\
  FROM\
    `bigquery-public-data`.london_bicycles.cycle_hire\
  WHERE\
    duration > 0\
  GROUP BY\
    start_station_id,\
    end_station_id\
  HAVING\
    num_rides > 100 )\
SELECT\
  start_station_name,\
  end_station_name,\
  distance,\
  duration,\
  duration/distance AS pace\
FROM\
  distances\
JOIN\
  durations\
USING\
  (start_station_id,\
    end_station_id)\
ORDER BY\
  pace ASC\
LIMIT\
  5\
\
\cf2 \cb3 \strokec2 The recast query with the more efficient joins takes only 8.2 seconds, a 1.8x speedup and processes 554 MB, a nearly 4x reduction in cost.\
\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Task 4. Avoid overwhelming a worker\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 Some operations (e.g. ordering) have to be carried out on a single worker. Having to sort too much data can overwhelm a worker\'92s memory and result in a \'93resources exceeded\'94 error. Avoid overwhelming the worker with too much data. As the hardware in Google data centers is upgraded, what \'93too much\'94 means in this context expands over time. Currently, this is on the order of one GB.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Limiting large sorts\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls27\ilvl0
\f1\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Let\'92s say that we wish to go through the rentals and number them 1, 2, 3, etc. in the order that the rental ended. We could do that using the ROW_NUMBER() function:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  rental_id,\
  ROW_NUMBER() OVER(ORDER BY end_date) AS rental_number\
FROM\
  `bigquery-public-data.london_bicycles.cycle_hire`\
ORDER BY\
  rental_number ASC\
LIMIT\
  5\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 It takes 34.5 seconds to process just 372 MB because it needs to sort the entirety of the London bicycles dataset on a single worker. Had we processed a larger dataset, it would have overwhelmed that worker.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls28\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 We might want to consider whether it is possible to limit the large sorts and distribute them. Indeed, it is possible to extract the date from the rentals and then sort trips within each day:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
WITH\
  rentals_on_day AS (\
  SELECT\
    rental_id,\
    end_date,\
    EXTRACT(DATE\
    FROM\
      end_date) AS rental_date\
  FROM\
    `bigquery-public-data.london_bicycles.cycle_hire` )\
SELECT\
  rental_id,\
  rental_date,\
  ROW_NUMBER() OVER(PARTITION BY rental_date ORDER BY end_date) AS rental_number_on_day\
FROM\
  rentals_on_day\
ORDER BY\
  rental_date ASC,\
  rental_number_on_day ASC\
LIMIT\
  5\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 This takes 15.1 seconds (a 2x speedup) because the sorting can be done on just a single day of data at a time.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Data skew\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 The same problem of overwhelming a worker (in this case, overwhelm the memory of the worker) can happen during an ARRAY_AGG with GROUP BY if one of the keys is much more common than the others.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls29\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Because there are more than 3 million GitHub repositories and the commits are well distributed among them, this query succeeds (make sure you execute the query in the\'a0
\f3\fs30 \cb4 us (multiple regions in United States)
\f1\fs32 \cb3 \'a0processing center):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  repo_name,\
  ARRAY_AGG(STRUCT(author,\
      committer,\
      subject,\
      message,\
      trailer,\
      difference,\
      encoding)\
  ORDER BY\
    author.date.seconds)\
FROM\
  `bigquery-public-data.github_repos.commits`,\
  UNNEST(repo_name) AS repo_name\
GROUP BY\
  repo_name\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 Note, while this query will succeed, it can take upwards of 30 minutes to do so. If you understand the query, move on in the lab.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls30\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Most of the people using GitHub live in only a few time zones, so grouping by the timezone fails -- we are asking a single worker to sort a significant fraction of 750GB:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf5 \strokec5 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 SELECT\
  author.tz_offset,\
  ARRAY_AGG(STRUCT(author,\
      committer,\
      subject,\
      message,\
      trailer,\
      difference,\
      encoding)\
  ORDER BY\
    author.date.seconds)\
FROM\
  `bigquery-public-data.github_repos.commits`\
GROUP BY\
  author.tz_offset\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls31\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 If you do require sorting all the data, use more granular keys (i.e. distribute the group\'92s data over more workers) and then aggregate the results corresponding to the desired key. For example, instead of grouping only by the time zone, it is possible to group by both\'a0
\f3\fs30 \cb4 timezone
\f1\fs32 \cb3 \'a0and\'a0
\f3\fs30 \cb4 repo_name
\f1\fs32 \cb3 \'a0and then aggregate across repos to get the actual answer for each timezone:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  repo_name,\
  author.tz_offset,\
  ARRAY_AGG(STRUCT(author,\
      committer,\
      subject,\
      message,\
      trailer,\
      difference,\
      encoding)\
  ORDER BY\
    author.date.seconds)\
FROM\
  `bigquery-public-data.github_repos.commits`,\
  UNNEST(repo_name) AS repo_name\
GROUP BY\
  repo_name,\
  author.tz_offset\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 Note, while this query will succeed, it can take upwards of 15 minutes to do so. If you understand the query, move on in the lab.\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 Task 5. Approximate aggregation functions\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 BigQuery provides fast, low-memory approximations of aggregate functions. Instead of using COUNT(DISTINCT \'85), we can use APPROX_COUNT_DISTINCT on large data streams when a small statistical uncertainty in the result is tolerable.\
\pard\pardeftab720\partightenfactor0
\cf2 \cb1 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 Approximate count\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls32\ilvl0
\f1\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 We can find the number of unique GitHub repositories using:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf5 \strokec5 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 SELECT\
  COUNT(DISTINCT repo_name) AS num_repos\
FROM\
  `bigquery-public-data`.github_repos.commits,\
  UNNEST(repo_name) AS repo_name\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 The above query takes 8.3 seconds to compute the correct result of 3347770.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls33\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Using the approximate function:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
SELECT\
  APPROX_COUNT_DISTINCT(repo_name) AS num_repos\
FROM\
  `bigquery-public-data`.github_repos.commits,\
  UNNEST(repo_name) AS repo_name\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 The above query takes 3.9 seconds (a 2x speedup) and returns an approximate result of 3399473, which overestimates the correct answer by 1.5%.\
The approximate algorithm is much more efficient than the exact algorithm only on large datasets and is recommended in use-cases where errors of approximately 1% are tolerable. Before using the approximate function, measure your use case!\
Other available approximate functions include APPROX_QUANTILES to compute percentiles, APPROX_TOP_COUNT to find the top elements and APPROX_TOP_SUM to compute top elements based on the sum of an element.\
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Next steps / Learn more\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls34\ilvl0
\f1\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Google Cloud Platform\'a0{\field{\*\fldinst{HYPERLINK "https://cloud.google.com/bigquery/docs/best-practices-performance-overview"}}{\fldrslt documentation for optimizing query performance}}.\cb1 \
\ls34\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 BigQuery\'a0{\field{\*\fldinst{HYPERLINK "https://cloud.google.com/bigquery/docs/best-practices-costs"}}{\fldrslt best practices for controlling costs}}.\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb1 \
}