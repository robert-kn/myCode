{\rtf1\ansi\ansicpg1252\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Bold;\f1\froman\fcharset0 Times-Roman;\f2\fswiss\fcharset0 Helvetica;
\f3\fmodern\fcharset0 Courier;\f4\fswiss\fcharset0 Arial-BoldMT;\f5\fswiss\fcharset0 ArialMT;
\f6\fmodern\fcharset0 Courier-Bold;\f7\froman\fcharset0 Times-Italic;}
{\colortbl;\red255\green255\blue255;\red24\green25\blue27;\red255\green255\blue255;\red0\green0\blue0;
\red0\green0\blue0;\red24\green24\blue24;\red227\green236\blue254;\red254\green246\blue217;\red251\green226\blue224;
\red246\green246\blue239;\red32\green32\blue32;\red157\green225\blue43;\red115\green0\blue2;\red82\green0\blue83;
\red83\green85\blue2;\red16\green121\blue2;\red0\green0\blue117;\red11\green84\blue83;}
{\*\expandedcolortbl;;\cssrgb\c12549\c12941\c14118;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;
\cssrgb\c0\c0\c0\c5098;\cssrgb\c12157\c12157\c12157;\cssrgb\c90980\c94118\c99608;\cssrgb\c99608\c96863\c87843;\cssrgb\c98824\c90980\c90196;
\cssrgb\c97255\c97255\c94902;\cssrgb\c16863\c16863\c16863;\cssrgb\c67059\c89020\c21961;\cssrgb\c53333\c0\c0;\cssrgb\c40000\c0\c40000;
\cssrgb\c40000\c40000\c0;\cssrgb\c0\c53333\c0;\cssrgb\c0\c0\c53333;\cssrgb\c0\c40000\c40000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat6\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat7\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat8\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid12}
{\list\listtemplateid13\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid13}
{\list\listtemplateid14\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid14}
{\list\listtemplateid15\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid15}
{\list\listtemplateid16\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid16}
{\list\listtemplateid17\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid17}
{\list\listtemplateid18\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid18}
{\list\listtemplateid19\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid19}
{\list\listtemplateid20\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1901\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid20}
{\list\listtemplateid21\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid21}
{\list\listtemplateid22\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid22}
{\list\listtemplateid23\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid23}
{\list\listtemplateid24\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid24}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}{\listoverride\listid13\listoverridecount0\ls13}{\listoverride\listid14\listoverridecount0\ls14}{\listoverride\listid15\listoverridecount0\ls15}{\listoverride\listid16\listoverridecount0\ls16}{\listoverride\listid17\listoverridecount0\ls17}{\listoverride\listid18\listoverridecount0\ls18}{\listoverride\listid19\listoverridecount0\ls19}{\listoverride\listid20\listoverridecount0\ls20}{\listoverride\listid21\listoverridecount0\ls21}{\listoverride\listid22\listoverridecount0\ls22}{\listoverride\listid23\listoverridecount0\ls23}{\listoverride\listid24\listoverridecount0\ls24}}
\paperw11900\paperh16840\margl1440\margr1440\vieww33100\viewh16740\viewkind0
\deftab720
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Overview\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 In this lab, you:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Implement a pipeline that has branches.\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Filter data before writing.\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Add custom command-line parameters to a pipeline.\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 Prerequisites:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Basic familiarity with Python.\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 In the previous lab, you created a basic Extract-Transform-Load sequential pipeline and used an equivalent Dataflow Template to ingest batch data storage on Google Cloud Storage. This pipeline consists of a sequence of transformations:\
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \cb1 \strokec4 {{\NeXTGraphic Uk+45NRmCE2ywRFMkwpuotQdWhfqc+GcOyP4HQu0t5E=.png \width15820 \height3840 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\
\
\pard\pardeftab720\sa480\partightenfactor0

\fs32 \cf2 \cb3 \strokec2 Many pipelines will not exhibit such simple structure, though. In this lab, you build a more sophisticated, non-sequential pipeline.\
The use case here is to optimize resource consumption. Products vary with respect to how they consume resources. Additionally, not all data is used in the same way within a business; some data will be regularly queried, for example, within analytic workloads, and some data will only be used for recovery. In this lab, you optimize the pipeline from the first lab for resource consumption, by storing only data that analysts will use in BigQuery while archiving other data in a very low-cost, highly durable storage service: Coldline storage in Google Cloud Storage.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Check project permissions\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 \cb3 \strokec2 Before you begin your work on Google Cloud, you need to ensure that your project has the correct permissions within Identity and Access Management (IAM).\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa480\partightenfactor0
\ls3\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Google Cloud console, on the\'a0
\f0\b Navigation menu
\f1\b0 \'a0(\cb1 {{\NeXTGraphic tkgw1TDgj4Q+YKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY=.png \width300 \height260 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\cb3 ), select\'a0
\f0\b IAM & Admin
\f1\b0 \'a0>\'a0
\f0\b IAM
\f1\b0 .\cb1 \
\ls3\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Confirm that the default compute Service Account\'a0
\f3\fs30 \cb5 \{project-number\}-compute@developer.gserviceaccount.com
\f1\fs32 \cb3 \'a0is present and has the\'a0
\f3\fs30 \cb5 editor
\f1\fs32 \cb3 \'a0role assigned. The account prefix is the project number, which you can find on\'a0
\f0\b Navigation menu > Cloud Overview > Dashboard
\f1\b0 .\cb1 \
\pard\pardeftab720\partightenfactor0

\f4\b\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf6 \cb7 \strokec6 Note:\'a0
\f5\b0 \AppleTypeServices\AppleTypeServicesF65539 If the account is not present in IAM or does not have the\'a0
\f3\fs30 \AppleTypeServices \cb5 editor
\f5\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cb7 \'a0role, follow the steps below to assign the required role.\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls4\ilvl0
\f1\fs32 \AppleTypeServices \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Google Cloud console, on the\'a0
\f0\b Navigation menu
\f1\b0 , click\'a0
\f0\b Cloud Overview > Dashboard
\f1\b0 .\cb1 \
\ls4\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Copy the project number (e.g.\'a0
\f3\fs30 \cb5 729328892908
\f1\fs32 \cb3 ).\cb1 \
\ls4\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 On the\'a0
\f0\b Navigation menu
\f1\b0 , select\'a0
\f0\b IAM & Admin
\f1\b0 \'a0>\'a0
\f0\b IAM
\f1\b0 .\cb1 \
\ls4\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 At the top of the roles table, below\'a0
\f0\b View by Principals
\f1\b0 , click\'a0
\f0\b Grant Access
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls4\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For\'a0
\f0\b New principals
\f1\b0 , type:\cb1 \
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4   \{project-number\}-compute@developer.gserviceaccount.com\cf0 \
\pard\pardeftab720\partightenfactor0

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls5\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Replace\'a0
\f3\fs30 \cb5 \{project-number\}
\f1\fs32 \cb3 \'a0with your project number.\cb1 \
\ls5\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For\'a0
\f0\b Role
\f1\b0 , select\'a0
\f0\b Project
\f1\b0 \'a0(or Basic) >\'a0
\f0\b Editor
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls5\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Save
\f1\b0 .\
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \cb1 \
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Jupyter notebook-based development environment setup\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 \cb3 \strokec2 For this lab, you will be running all commands in a terminal from your notebook.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa480\partightenfactor0
\ls6\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Google Cloud Console, on the\'a0
\f0\b Navigation Menu
\f1\b0 , click\'a0
\f0\b Vertex AI > Workbench
\f1\b0 .\cb1 \
\ls6\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Enable\'a0
\f0\b Notebooks API
\f1\b0 .\cb1 \
\ls6\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 On the Workbench page, click\'a0
\f0\b CREATE NEW
\f1\b0 .\cb1 \
\ls6\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the\'a0
\f0\b New instance
\f1\b0 \'a0dialog box that appears, set the region to\'a0
\f6\b \cb8 region
\f1\b0 \cb3 \'a0and zone to\'a0
\f6\b \cb8 zone
\f1\b0 \cb3 .\cb1 \
\ls6\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For Environment, select\'a0
\f0\b Python 3 (with Intel\'ae MKL)
\f1\b0 .\cb1 \
\ls6\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b CREATE
\f1\b0 \'a0at the bottom of the dialog vox.\cb1 \
\pard\pardeftab720\partightenfactor0

\f4\b\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf6 \cb9 \strokec6 Note:\'a0
\f1\b0 \AppleTypeServices The environment may take 3 - 5 minutes to be fully provisioned. Please wait until the step is complete.\

\f5 \AppleTypeServices\AppleTypeServicesF65539 \

\f4\b \AppleTypeServices\AppleTypeServicesF65539 \cf6 \cb7 \strokec6 Note:\'a0
\f1\b0 \AppleTypeServices \cf6 \cb7 \strokec6 Click
\f5 \AppleTypeServices\AppleTypeServicesF65539 \cf6 \cb7 \strokec6 \'a0
\f4\b \AppleTypeServices\AppleTypeServicesF65539 Enable Notebook API
\f5\b0 \AppleTypeServices\AppleTypeServicesF65539 \'a0
\f1 \AppleTypeServices \cf6 \cb7 \strokec6 to enable the notebook api.\

\f5 \AppleTypeServices\AppleTypeServicesF65539 \cf6 \cb7 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls7\ilvl0
\f1\fs32 \AppleTypeServices \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Once the environment is ready, click the\'a0
\f0\b OPEN JUPYTERLAB
\f1\b0 \'a0link next to your Notebook name. This will open up your environment in a new tab in your browser.\
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls8\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Next, click\'a0
\f0\b Terminal
\f1\b0 . This will open up a terminal where you can run all the commands in this lab.\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Download Code Repository\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 \cb3 \strokec2 Next you will download a code repository for use in this lab.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls9\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the terminal you just opened, enter the following:\cb1 \
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4 git clone https://github.com/GoogleCloudPlatform/training-data-analyst\
cd /home/jupyter/training-data-analyst/quests/dataflow_python/\cf0 \

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa480\partightenfactor0
\ls10\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 On the left panel of your notebook environment, in the file browser, you will notice the\'a0
\f0\b training-data-analyst
\f1\b0 \'a0repo added.\cb1 \
\ls10\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Navigate into the cloned repo\'a0
\f3\fs30 \cb5 /training-data-analyst/quests/dataflow_python/
\f1\fs32 \cb3 . You will see a folder for each lab, which is further divided into a\'a0
\f3\fs30 \cb5 lab
\f1\fs32 \cb3 \'a0sub-folder with code to be completed by you, and a\'a0
\f3\fs30 \cb5 solution
\f1\fs32 \cb3 \'a0sub-folder with a fully workable example to reference if you get stuck.\cb1 \
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Multiple transforms process the same PCollection\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 In this lab, you write a branching pipeline that writes data to both Google Cloud Storage and to BigQuery.\
One way of writing a branching pipeline is to apply two\'a0
\f7\i \cf2 \cb3 \strokec2 different
\f1\i0 \cf2 \cb3 \strokec2 \'a0transforms to the same PCollection, resulting in two\'a0
\f7\i \cf2 \cb3 \strokec2 different
\f1\i0 \cf2 \cb3 \strokec2 \'a0PCollections:\
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf10 \cb11 \strokec10 [\cf12 \strokec12 PCollection1\cf10 \strokec10 ] = [\cf12 \strokec12 Initial\cf10 \strokec10  \cf12 \strokec12 Input\cf10 \strokec10  \cf12 \strokec12 PCollection\cf10 \strokec10 ] | [\cf12 \strokec12 A\cf10 \strokec10  \cf12 \strokec12 Transform\cf10 \strokec10 ]\
[\cf12 \strokec12 PCollection2\cf10 \strokec10 ] = [\cf12 \strokec12 Initial\cf10 \strokec10  \cf12 \strokec12 Input\cf10 \strokec10  \cf12 \strokec12 PCollection\cf10 \strokec10 ] | [\cf12 \strokec12 A\cf10 \strokec10  \cf12 \strokec12 Different\cf10 \strokec10  \cf12 \strokec12 Transform\cf10 \strokec10 ]\
\pard\tx720\pardeftab720\partightenfactor0

\f1\fs32 \cf2 \cb1 \strokec2 \
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Implementing a branching pipeline\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 If you get stuck in this or later sections, the solution is available from the\'a0{\field{\*\fldinst{HYPERLINK "https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/quests/dataflow_python/2_Branching_Pipelines/solution/my_pipeline.py"}}{\fldrslt \cf2 \cb3 \strokec2 Google Cloud training-data-analyst page}}.\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 Task 1. Add a branch to write to Cloud Storage\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 To complete this task, modify an existing pipeline by adding a branch that writes to Cloud Storage.\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f2\fs24 \cf0 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {{\NeXTGraphic Pasted Graphic.png \width11720 \height3860 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}
\f1\fs32 \
\
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Open the appropriate lab\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls11\ilvl0
\f1\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the terminal in your IDE environment, and run the following commands:\cb1 \
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf13 \cb3 \strokec13 # Change directory into the lab\cf6 \cb3 \strokec4 \
\cf14 \cb3 \strokec14 cd\cf6 \cb3 \strokec4  2_Branching_Pipelines/lab\
\cf14 \cb3 \strokec14 export\cf6 \cb3 \strokec4  BASE_DIR=$(\cf14 \cb3 \strokec14 pwd\cf6 \cb3 \strokec4 )\cf0 \
\pard\pardeftab720\partightenfactor0

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Setting up virtual environment and dependencies\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 \cb3 \strokec2 Before you can begin editing the actual pipeline code, you need to ensure that you have installed the necessary dependencies.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls12\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the terminal in your IDE environment, run the commands below create a virtual environment for your work in this lab:\cb1 \
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4 sudo apt-get update && sudo apt-get install -y python3-venv\cf0 \

\f1\fs32 \cf6 \cb1 \strokec6 \

\f3\fs28 \cb3 \strokec4  python3 -m venv df-env\cf0 \

\f1\fs32 \cf6 \cb1 \strokec6 \

\f3\fs28 \cb3 \strokec4  \cf14 \cb3 \strokec14 source\cf6 \cb3 \strokec4  df-env/bin/activate\cf0 \

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls13\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Next, install the packages you will need to execute your pipeline:\cb1 \
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4 python3 -m pip install -q --upgrade pip setuptools wheel\
python3 -m pip install apache-beam[gcp]\cf0 \

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls14\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Finally, ensure that the Dataflow API is enabled:\cb1 \
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4 gcloud services \cf14 \cb3 \strokec14 enable\cf6 \cb3 \strokec4  dataflow.googleapis.com\cf0 \

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Set up the data environment\
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf13 \cb3 \strokec13 # Create GCS buckets and BQ dataset\cf6 \cb3 \strokec4 \
\cf14 \cb3 \strokec14 cd\cf6 \cb3 \strokec4  \cf15 \cb3 \strokec15 $BASE_DIR\cf6 \cb3 \strokec4 /../..\
\cf14 \cb3 \strokec14 source\cf6 \cb3 \strokec4  create_batch_sinks.sh\
\
\cf13 \cb3 \strokec13 # Generate event dataflow\cf6 \cb3 \strokec4 \
\cf14 \cb3 \strokec14 source\cf6 \cb3 \strokec4  generate_batch_events.sh\
\
\cf13 \cb3 \strokec13 # Change to the directory containing the practice version of the code\cf6 \cb3 \strokec4 \
\cf14 \cb3 \strokec14 cd\cf6 \cb3 \strokec4  \cf15 \cb3 \strokec15 $BASE_DIR\cf6 \cb3 \strokec4 \
\pard\pardeftab720\partightenfactor0

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa480\partightenfactor0
\ls15\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Open up\'a0
\f3\fs30 \cb5 my_pipeline.py
\f1\fs32 \cb3 \'a0in your IDE, which can be found in\'a0
\f3\fs30 \cb5 training-data-analyst/quests/dataflow_python/2_Branching_Pipelines/labs/
\f1\fs32 \cb3 .\cb1 \
\ls15\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Scroll down to the run() method, where the body of the pipeline is defined. It currently looks as follows:\cb1 \
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4 (p\
    | \cf16 \cb3 \strokec16 'ReadFromGCS'\cf6 \cb3 \strokec4  >> beam.io.ReadFromText(\cf14 \cb3 \strokec14 input\cf6 \cb3 \strokec4 )\
    | \cf16 \cb3 \strokec16 'ParseJson'\cf6 \cb3 \strokec4  >> beam.Map(parse_json)\
    | \cf16 \cb3 \strokec16 'WriteToBQ'\cf6 \cb3 \strokec4  >> beam.io.WriteToBigQuery(\
        output,\
        schema=table_schema,\
        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\
        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE\
        )\
)\

\f1\fs32 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls16\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Modify this code by adding a new branching transform that writes to Cloud Storage using\'a0{\field{\*\fldinst{HYPERLINK "https://beam.apache.org/releases/pydoc/2.28.0/apache_beam.io.textio.html#apache_beam.io.textio.WriteToText"}}{\fldrslt 
\f3\fs30 \cb5 textio.WriteToText}}\'a0before each element is converted from\'a0
\f3\fs30 \cb5 json
\f1\fs32 \cb3 \'a0to\'a0
\f3\fs30 \cb5 dict
\f1\fs32 \cb3 .\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 If you get stuck in this or later sections, refer to the solution, which can be found on the\'a0{\field{\*\fldinst{HYPERLINK "https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/quests/dataflow_python/2_Branching_Pipelines/solution/my_pipeline.py"}}{\fldrslt \cf2 \cb3 \strokec2 Google Cloud training-data-analyst page}}.\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 \
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Task 2. Filter data by field\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 At the moment, the new pipeline doesn\'92t actually consume fewer resources, since all data are being stored twice. To start improving resource consumption, we need to reduce the amount of duplicated data.\
The Google Cloud Storage bucket is intended to function as archival and backup storage, so it\'92s important that all data be stored there. However, not all data necessarily need to be sent to BigQuery.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls17\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Let\'92s assume that data analysts often look at what resources users access on the website, and how those access patterns differ as a function of geography and time. Only a subset of the fields would be necessary. Since we have parsed the JSON elements into dictionaries, we can easily use the\'a0
\f3\fs30 \cb5 pop
\f1\fs32 \cb3 \'a0method to drop a field from within a Python callable:\cb1 \
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf17 \cb3 \strokec17 def\cf6 \cb3 \strokec4  \cf14 \cb3 \strokec14 drop_field\cf6 \cb3 \strokec4 (\cf14 \cb3 \strokec14 element\cf6 \cb3 \strokec4 ):\
  element.pop(\cf16 \cb3 \strokec16 'field_name'\cf6 \cb3 \strokec4 )\
  \cf17 \cb3 \strokec17 return\cf6 \cb3 \strokec4  element\cf0 \
\pard\pardeftab720\partightenfactor0

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls18\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To complete this task, use a Python callable with\'a0
\f3\fs30 \cb5 beam.Map
\f1\fs32 \cb3 \'a0to drop the field\'a0
\f3\fs30 \cb5 user_agent
\f1\fs32 \cb3 , which our analysts will not be using in BigQuery.\cb1 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 \
\cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Task 3. Filter data by element\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 There are many ways of filtering in Apache Beam. Since we are working with a PCollection of Python dictionaries, the easiest manner will be to leverage a lambda (anonymous) function as our filter, a function returning a boolean value, with\'a0
\f3\fs30 \cf2 \cb5 \strokec2 beam.Filter
\f1\fs32 \cf2 \cb3 \strokec2 . For example:\
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4 purchases | beam.Filter(\cf17 \cb3 \strokec17 lambda\cf6 \cb3 \strokec4  element : element[\cf16 \cb3 \strokec16 'cost_cents'\cf6 \cb3 \strokec4 ] > \cf18 \cb3 \strokec18 20\cf6 \cb3 \strokec4 *\cf18 \cb3 \strokec18 100\cf6 \cb3 \strokec4 )\cf0 \

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls19\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To complete this task, add a\'a0
\f3\fs30 \cb5 beam.Filter
\f1\fs32 \cb3 \'a0transform to the pipeline. You may filter on whatever criteria you wish, but as a suggestion, try eliminating rows where\'a0
\f3\fs30 \cb5 num_bytes
\f1\fs32 \cb3 \'a0is greater than or equal to 120.\
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \cb1 \strokec2 \
\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Task 4. Adding custom command-line parameters\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 The pipeline currently has a number of parameters hard-coded into it, including the path to the input and the location of the table in BigQuery. However, the pipeline would be more useful if it could read\'a0
\f7\i \cf2 \cb3 \strokec2 any
\f1\i0 \cf2 \cb3 \strokec2 \'a0JSON file in Cloud Storage. Adding this feature requires adding to the set of command-line parameters.\
Currently, we use an\'a0
\f3\fs30 \cf2 \cb5 \strokec2 ArgumentParser
\f1\fs32 \cf2 \cb3 \strokec2 \'a0to read in and parse command-line arguments. We then pass these arguments into the\'a0
\f3\fs30 \cf2 \cb5 \strokec2 PipelineOptions()
\f1\fs32 \cf2 \cb3 \strokec2 \'a0object we specify when creating our pipeline:\
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4     parser = argparse.ArgumentParser(description=\cf16 \cb3 \strokec16 '...'\cf6 \cb3 \strokec4 )\
    \cf13 \cb3 \strokec13 # Define and parse arguments\cf6 \cb3 \strokec4 \
    options = PipelineOptions()\
    \cf13 \cb3 \strokec13 # Set options values from options\cf6 \cb3 \strokec4 \
    p = beam.Pipeline(options=options)\cf0 \

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 The\'a0{\field{\*\fldinst{HYPERLINK "https://beam.apache.org/releases/pydoc/2.28.0/apache_beam.options.pipeline_options.html"}}{\fldrslt \cf2 \cb3 \strokec2 PipelineOptions}}\'a0is used to interpret the options being read by the\'a0
\f3\fs30 \cf2 \cb5 \strokec2 ArgumentParser
\f1\fs32 \cf2 \cb3 \strokec2 . To add a new command-line argument to the parser, we can use the syntax:\
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4 parser.add_argument(\cf16 \cb3 \strokec16 '--argument_name'\cf6 \cb3 \strokec4 , required=\cf18 \cb3 \strokec18 True\cf6 \cb3 \strokec4 , \cf14 \cb3 \strokec14 help\cf6 \cb3 \strokec4 =\cf16 \cb3 \strokec16 'Argument description'\cf6 \cb3 \strokec4 )\cf0 \

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 To access a command-line parameter in code, parse the arguments and refer to the field in the resulting dictionary:\
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4 opts = parser.parse_args()\
arg_value = opts.arg_name\cf0 \

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls20\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To complete this task, add command-line parameters for the input path, the Google Cloud Storage output path, and the BigQuery table name, and update the pipeline code to access those parameters instead of constants.\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Task 5. Add nullable fields to your pipeline\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 You may have noticed that the BigQuery table created in the last lab had a schema with all\'a0
\f3\fs30 \cf2 \cb5 \strokec2 REQUIRED
\f1\fs32 \cf2 \cb3 \strokec2 \'a0fields like this:\
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \cb1 \strokec4 {{\NeXTGraphic 1UgevR8rQO7O1VARFRcB2fhqq+M4sedd7F8g=.png \width10100 \height9380 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\partightenfactor0
\cf0 \strokec4 \
\
\pard\pardeftab720\sa480\partightenfactor0

\fs32 \cf2 \cb3 \strokec2 It may be desirable to create an Apache Beam schema with\'a0
\f3\fs30 \cf2 \cb5 \strokec2 NULLABLE
\f1\fs32 \cf2 \cb3 \strokec2 \'a0fields where data is missing, both for the pipeline execution itself and then for the resulting BigQuery table.\
We can update the JSON BigQuery schema by adding a new property\'a0
\f3\fs30 \cf2 \cb5 \strokec2 mode
\f1\fs32 \cf2 \cb3 \strokec2 \'a0for a field we wish to be nullable:\
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf6 \cb3 \strokec4 \{\
    \cf14 \cb3 \strokec14 "name"\cf6 \cb3 \strokec4 : \cf16 \cb3 \strokec16 "field_name"\cf6 \cb3 \strokec4 ,\
    \cf14 \cb3 \strokec14 "type"\cf6 \cb3 \strokec4 : \cf16 \cb3 \strokec16 "STRING"\cf6 \cb3 \strokec4 ,\
    \cf14 \cb3 \strokec14 "mode"\cf6 \cb3 \strokec4 : \cf16 \cb3 \strokec16 "NULLABLE"\cf6 \cb3 \strokec4 \
\}\
\pard\pardeftab720\partightenfactor0

\f1\fs32 \cf6 \cb1 \strokec6 Copied!\
\pard\pardeftab720\qc\partightenfactor0

\fs48 \cf6 \
\pard\pardeftab720\partightenfactor0
\cf6 content_copy
\fs32 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls21\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To complete this task, mark the\'a0
\f3\fs30 \cb5 lat
\f1\fs32 \cb3 \'a0and\'a0
\f3\fs30 \cb5 lon
\f1\fs32 \cb3 \'a0fields as nullable in the BigQuery schema.\
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \cb1 \strokec2 \
\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Task 6. Run your pipeline from the command line\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls22\ilvl0
\f1\b0\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To complete this task, run your pipeline from the command line and pass the appropriate parameters. Remember to take note of the resulting BigQuery schema for NULLABLE fields. Your code should look something like this:\
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f3\fs28 \cf13 \cb3 \strokec13 # Set up environment variables\cf6 \cb3 \strokec4 \
\cf14 \cb3 \strokec14 export\cf6 \cb3 \strokec4  PROJECT_ID=$(gcloud\cf14 \cb3 \strokec14  config \cf6 \cb3 \strokec4 get-value project)\
\cf14 \cb3 \strokec14 export\cf6 \cb3 \strokec4  REGION=Region\
\cf14 \cb3 \strokec14 export\cf6 \cb3 \strokec4  BUCKET=gs://$\{PROJECT_ID\}\
\cf14 \cb3 \strokec14 export\cf6 \cb3 \strokec4  COLDLINE_BUCKET=\cf15 \cb3 \strokec15 $\{BUCKET\}\cf6 \cb3 \strokec4 -coldline\
\cf14 \cb3 \strokec14 export\cf6 \cb3 \strokec4  PIPELINE_FOLDER=\cf15 \cb3 \strokec15 $\{BUCKET\}\cf6 \cb3 \strokec4 \
\cf14 \cb3 \strokec14 export\cf6 \cb3 \strokec4  RUNNER=DataflowRunner\
\cf14 \cb3 \strokec14 export\cf6 \cb3 \strokec4  INPUT_PATH=\cf15 \cb3 \strokec15 $\{PIPELINE_FOLDER\}\cf6 \cb3 \strokec4 /events.json\
\cf14 \cb3 \strokec14 export\cf6 \cb3 \strokec4  OUTPUT_PATH=\cf15 \cb3 \strokec15 $\{PIPELINE_FOLDER\}\cf6 \cb3 \strokec4 -coldline/pipeline_output\
\cf14 \cb3 \strokec14 export\cf6 \cb3 \strokec4  TABLE_NAME=\cf15 \cb3 \strokec15 $\{PROJECT_ID\}\cf6 \cb3 \strokec4 :logs.logs_filtered\
\
cd \cf15 \cb3 \strokec15 $BASE_DIR\cf6 \cb3 \strokec4 \
python3 my_pipeline.py \\\
--project=\cf15 \cb3 \strokec15 $\{PROJECT_ID\}\cf6 \cb3 \strokec4  \\\
--region=\cf15 \cb3 \strokec15 $\{REGION\}\cf6 \cb3 \strokec4  \\\
--stagingLocation=\cf15 \cb3 \strokec15 $\{PIPELINE_FOLDER\}\cf6 \cb3 \strokec4 /staging \\\
--tempLocation=\cf15 \cb3 \strokec15 $\{PIPELINE_FOLDER\}\cf6 \cb3 \strokec4 /temp \\\
--runner=\cf15 \cb3 \strokec15 $\{RUNNER\}\cf6 \cb3 \strokec4  \\\
--inputPath=\cf15 \cb3 \strokec15 $\{INPUT_PATH\}\cf6 \cb3 \strokec4  \\\
--outputPath=\cf15 \cb3 \strokec15 $\{OUTPUT_PATH\}\cf6 \cb3 \strokec4  \\\
--tableName=\cf15 \cb3 \strokec15 $\{TABLE_NAME\}\cf6 \cb3 \strokec4 \
\pard\pardeftab720\partightenfactor0

\f1\fs32 \cf6 \cb1 \strokec6 \
\pard\pardeftab720\partightenfactor0

\f4\b\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf6 \cb7 Note:\'a0
\f1\b0 \AppleTypeServices \cf6 \cb7 \strokec6 If your pipeline is building successfully, but you're seeing a lot of errors due to code or misconfiguration in the Dataflow service, you can set `runner` back to 'DirectRunner' to run it locally and receive faster feedback. This approach works in this case because the dataset is small and you are not using any features that aren't supported by DirectRunner.\
\
\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Task 7. Verify the pipeline\'92s results\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls23\ilvl0
\f1\b0\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Navigate to the\'a0{\field{\*\fldinst{HYPERLINK "https://console.cloud.google.com/dataflow"}}{\fldrslt Cloud Dataflow Jobs page}}\'a0and look at the job as it\'92s running. Its graph should resemble the following:\
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \cb1 \strokec2 \
\pard\pardeftab720\partightenfactor0

\fs24 \cf0 \strokec4 {{\NeXTGraphic VGAz0=.png \width13280 \height15460 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa480\partightenfactor0
\ls24\ilvl0
\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click on the node representing your\'a0
\f3\fs30 \cb5 Filter
\f1\fs32 \cb3 \'a0function, which in the above picture is called\'a0
\f3\fs30 \cb5 FilterFn
\f1\fs32 \cb3 . In the panel that appears on the right-hand side, you should see that more elements were added as inputs than were written as outputs.\cb1 \
\ls24\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Now click on the node representing the write to Cloud Storage. Since all elements were written, this number should agree with the number of elements in the input to the Filter function.\cb1 \
\ls24\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Once the pipeline has finished, examine the results in\'a0{\field{\*\fldinst{HYPERLINK "https://console.cloud.google.com/bigquery"}}{\fldrslt BigQuery}}\'a0by querying your table. Note that the number of records in the table should agree with the number of elements that were output by the Filter function.\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f5\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf6 \cb7 \strokec6 \
\pard\tx720\pardeftab720\partightenfactor0

\f1\fs32 \AppleTypeServices \cf2 \cb1 \strokec2 \
}