{\rtf1\ansi\ansicpg1252\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Bold;\f1\froman\fcharset0 Times-Roman;\f2\fswiss\fcharset0 Helvetica;
\f3\fmodern\fcharset0 Courier-Bold;\f4\fswiss\fcharset0 Arial-BoldMT;\f5\fswiss\fcharset0 ArialMT;
\f6\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red24\green25\blue27;\red255\green255\blue255;\red254\green246\blue217;
\red24\green24\blue24;\red251\green226\blue224;\red227\green236\blue254;\red0\green0\blue0;\red0\green0\blue0;
\red82\green0\blue83;\red83\green85\blue2;}
{\*\expandedcolortbl;;\cssrgb\c12549\c12941\c14118;\cssrgb\c100000\c100000\c100000;\cssrgb\c99608\c96863\c87843;
\cssrgb\c12157\c12157\c12157;\cssrgb\c98824\c90980\c90196;\cssrgb\c90980\c94118\c99608;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c0\c5098;
\cssrgb\c40000\c0\c40000;\cssrgb\c40000\c40000\c0;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat7\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat8\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid12}
{\list\listtemplateid13\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid13}
{\list\listtemplateid14\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid14}
{\list\listtemplateid15\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid15}
{\list\listtemplateid16\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat4\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid16}
{\list\listtemplateid17\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat5\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid17}
{\list\listtemplateid18\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid18}
{\list\listtemplateid19\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1801\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid19}
{\list\listtemplateid20\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid20}
{\list\listtemplateid21\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid21}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}{\listoverride\listid13\listoverridecount0\ls13}{\listoverride\listid14\listoverridecount0\ls14}{\listoverride\listid15\listoverridecount0\ls15}{\listoverride\listid16\listoverridecount0\ls16}{\listoverride\listid17\listoverridecount0\ls17}{\listoverride\listid18\listoverridecount0\ls18}{\listoverride\listid19\listoverridecount0\ls19}{\listoverride\listid20\listoverridecount0\ls20}{\listoverride\listid21\listoverridecount0\ls21}}
\paperw11900\paperh16840\margl1440\margr1440\vieww33100\viewh16740\viewkind0
\deftab720
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Overview\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 In this lab, you learn how to:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Recreate the pipeline from the previous lab streaming_minute_traffic_SQL_pipeline, but with SQL transforms instead.\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Use the BigQuery UI to create a streaming PubSub source.\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Create a Dataflow SQL Streaming job 100% from SQL.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\cf2 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Jupyter notebook-based development environment setup\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 \cb3 \strokec2 For this lab, you will be running all commands in a terminal from your notebook.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa480\partightenfactor0
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Google Cloud Console, on the\'a0
\f0\b Navigation Menu
\f1\b0 , click\'a0
\f0\b Vertex AI > Workbench
\f1\b0 .\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Enable\'a0
\f0\b Notebooks API
\f1\b0 .\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 On the Workbench page, click\'a0
\f0\b CREATE NEW
\f1\b0 .\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the\'a0
\f0\b New instance
\f1\b0 \'a0dialog box that appears, set the region to\'a0
\f3\b \cb4 region
\f1\b0 \cb3 \'a0and zone to\'a0
\f3\b \cb4 zone
\f1\b0 \cb3 .\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For Environment, select\'a0
\f0\b Apache Beam
\f1\b0 .\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b CREATE
\f1\b0 \'a0at the bottom of the dialog vox.\cb1 \
\pard\pardeftab720\partightenfactor0

\f4\b\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf5 \cb6 \strokec5 Note:\'a0
\f1\b0 \AppleTypeServices The environment may take 3 - 5 minutes to be fully provisioned. Please wait until the step is complete.\

\f5 \AppleTypeServices\AppleTypeServicesF65539 \

\f4\b \AppleTypeServices\AppleTypeServicesF65539 \cb7 Note:\'a0
\f1\b0 \AppleTypeServices Click
\f5 \AppleTypeServices\AppleTypeServicesF65539 \'a0
\f4\b \AppleTypeServices\AppleTypeServicesF65539 Enable Notebook API
\f5\b0 \AppleTypeServices\AppleTypeServicesF65539 \'a0
\f1 \AppleTypeServices to enable the notebook api.\

\f5 \AppleTypeServices\AppleTypeServicesF65539 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0
\f1\fs32 \AppleTypeServices \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Once the environment is ready, click the\'a0
\f0\b OPEN JUPYTERLAB
\f1\b0 \'a0link next to your Notebook name. This will open up your environment in a new tab in your browser.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls4\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Next, click\'a0
\f0\b Terminal
\f1\b0 . This will open up a terminal where you can run all the commands in this lab.\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 Download Code Repository\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 \cb3 \strokec2 Next you will download a code repository for use in this lab.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls5\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the terminal you just opened, enter the following:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 git clone https://github.com/GoogleCloudPlatform/training-data-analyst\
cd /home/jupyter/training-data-analyst/quests/dataflow_python/\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa480\partightenfactor0
\ls6\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 On the left panel of your notebook environment, in the file browser, you will notice the\'a0
\f0\b training-data-analyst
\f1\b0 \'a0repo added.\cb1 \
\ls6\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Navigate into the cloned repo\'a0
\f6\fs30 \cb9 /training-data-analyst/quests/dataflow_python/
\f1\fs32 \cb3 . You will see a folder for each lab, which is further divided into a\'a0
\f6\fs30 \cb9 lab
\f1\fs32 \cb3 \'a0sub-folder with code to be completed by you, and a\'a0
\f6\fs30 \cb9 solution
\f1\fs32 \cb3 \'a0sub-folder with a fully workable example to reference if you get stuck.\cb1 \
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Aggregating streaming site traffic by minute with SQL\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 In this lab, you rewrite your previous StreamingMinuteTraffic pipeline to perform the following:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls7\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Reads the day\'92s traffic from a PubSub topic.\cb1 \
\ls7\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Converts each event into a\'a0
\f6\fs30 \cb9 CommonLog
\f1\fs32 \cb3 \'a0object.\cb1 \
\ls7\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Uses SQL instead of Python transforms to again window the data per minute sum the total number of pageviews.\cb1 \
\ls7\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Writes the resulting data to BigQuery.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\cf2 \strokec2 \
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 Task 1. Prepare the environment\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 As in the prior labs, the first step is to generate data for the pipeline to process. You open the lab environment and generate the data as before.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Open the appropriate lab\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls8\ilvl0
\f1\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the terminal in your IDE, run the following commands to change to the directory you use for this lab:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 # Change directory into the lab\
cd 6_SQL_Streaming_Analytics/lab\
export BASE_DIR=$(pwd)\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Set up the virtual environment and dependencies\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 \cb3 \strokec2 Before you can begin editing the actual pipeline code, you need to ensure you have installed the necessary dependencies.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls9\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Execute the following to install the packages you need to execute your pipeline:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 python3 -m pip install -q --upgrade pip setuptools wheel\
python3 -m pip install apache-beam[gcp]\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls10\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ensure that the Dataflow API is enabled:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 gcloud services enable dataflow.googleapis.com\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Set up the data environment\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls11\ilvl0
\f1\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Set up your data environment:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 # Create GCS buckets and BQ dataset\
cd $BASE_DIR/../..\
source create_streaming_sinks.sh\
\
# Change to the directory containing the practice version of the code\
cd $BASE_DIR\cf0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0

\f1\fs32 \cf2 \cb1 \strokec2 \
\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 Task 2. Read from PubSub, convert to CommonLog, and add and populate the DateTime field\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 Because you have implemented this pipeline a number of times, you'll need to add most of the steps yourself.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls12\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the file explorer, navigate to\'a0
\f6\fs30 \cb9 training-data-analyst/quests/dataflow_python/6_SQL_Streaming_Analytics/lab/
\f1\fs32 \cb3 \'a0and open the\'a0
\f6\fs30 \cb9 streaming_minute_traffic_SQL_pipeline.py
\f1\fs32 \cb3 \'a0file.\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 You'll see that Command line options, the\'a0
\f6\fs30 \cf2 \cb9 \strokec2 ParseAndGetEventTimestamp
\f1\fs32 \cf2 \cb3 \strokec2 \'a0composite\'a0
\f6\fs30 \cf2 \cb9 \strokec2 Ptransform
\f1\fs32 \cf2 \cb3 \strokec2 , and the\'a0
\f6\fs30 \cf2 \cb9 \strokec2 CommonLog
\f1\fs32 \cf2 \cb3 \strokec2 \'a0class with registered coder have been provided for you, but that the pipeline still needs to be authored. To complete this task, author a pipeline that completes the following steps. Feel free and reference the\'a0{\field{\*\fldinst{HYPERLINK "https://github.com/GoogleCloudPlatform//training-data-analyst/tree/master/quests/dataflow_python/6_SQL_Streaming_Analytics/solution"}}{\fldrslt \cf2 \cb3 \strokec2 solution}}\'a0or the code you wrote in the\'a0{\field{\*\fldinst{HYPERLINK "https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/quests/dataflow_python/5_Streaming_Analytics/solution/streaming_minute_traffic_pipeline.py"}}{\fldrslt \cf2 \cb3 \strokec2 previous lab}}:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls13\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Reads from the Pub/Sub topic provided by the command line with\'a0
\f6\fs30 \cb9 beam.io.ReadFromPubSub()
\f1\fs32 \cb1 \
\ls13\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Apply the composite\'a0
\f6\fs30 \cb9 PTransform
\f1\fs32 \cb3 ,\'a0
\f6\fs30 \cb9 ParseAndGetEventTimestamp
\f1\fs32 \cb3 , to the PCollection of messages ingested from Pub/Sub\cb1 \
\pard\pardeftab720\partightenfactor0

\f4\b\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf5 \cb7 \strokec5 Note:\'a0
\f6\b0\fs30 \AppleTypeServices \cf5 \cb9 \strokec5 ParseAndGetEventTimestamp
\f5\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf5 \cb7 \strokec5 \'a0
\f1 \AppleTypeServices is an example of a composite PTransform.
\f5 \cf2 \cb1 \strokec2 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf5 \cb7 \strokec5 Transforms can have a nested structure, where a complex transform performs multiple simpler transforms (such as more than one
\f5 \AppleTypeServices\AppleTypeServicesF65539 \'a0
\f6\fs30 \AppleTypeServices \cf5 \cb9 \strokec5 ParDo
\f1\fs24 \cf5 \cb7 \strokec5 ,
\f5 \AppleTypeServices\AppleTypeServicesF65539 \'a0
\f6\fs30 \AppleTypeServices \cf5 \cb9 \strokec5 Combine
\f1\fs24 \cf5 \cb7 \strokec5 ,
\f5 \AppleTypeServices\AppleTypeServicesF65539 \'a0
\f6\fs30 \AppleTypeServices \cf5 \cb9 \strokec5 GroupByKey
\f1\fs24 \cf5 \cb7 \strokec5 , or even other composite transforms).
\f5 \cf2 \cb1 \strokec2 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \
\pard\pardeftab720\partightenfactor0

\f1 \cf5 \cb7 \strokec5 These transforms are called composite transforms. Nesting multiple transforms inside a single composite transform can make your code more modular and easier to understand. Refer to
\f5 \AppleTypeServices\AppleTypeServicesF65539 \'a0{\field{\*\fldinst{HYPERLINK "https://beam.apache.org/documentation/programming-guide/#composite-transforms"}}{\fldrslt \cf5 \cb7 \strokec5 Section 4.6. Composite transforms of the Apache Beam Programming Guide}}\'a0
\f1 \AppleTypeServices for more details.
\f5 \AppleTypeServices\AppleTypeServicesF65539 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls14\ilvl0
\f1\fs32 \AppleTypeServices \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Implement the first\'a0
\f6\fs30 \cb9 #TODO
\f1\fs32 \cb3 \'a0to apply the\'a0
\f6\fs30 \cb9 parse_json
\f1\fs32 \cb3 \'a0function:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 'ParseJson' >> beam.Map(parse_json)\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls15\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Fill out the next\'a0
\f6\fs30 \cb9 #TODO
\f1\fs32 \cb3 : apply GetEventTimestampFn DoFn:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 'GetEventTimestamp' >> beam.ParDo(GetEventTimestampFn())\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls16\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Fill out the next\'a0
\f6\fs30 \cb9 #TODO
\f1\fs32 \cb3 \'a0to read from the PubSub topic:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 beam.io.ReadFromPubSub(input_topic)\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls17\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Apply\'a0
\f6\fs30 \cb9 ParseAndGetEventTimestamp
\f1\fs32 \cb3 \'a0custom PTransform with output type CommonLog:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 ParseAndGetEventTimestamp().with_output_types(CommonLog)\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Task 3. Write an SQL statement to window and aggregate the data\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 Just as before, you can use\'a0
\f6\fs30 \cf2 \cb9 \strokec2 SqlTransform
\f1\fs32 \cf2 \cb3 \strokec2 \'a0to perform a SQL based query or aggregation on elements that have a Beam schema.\
To complete this task implement a\'a0
\f6\fs30 \cf2 \cb9 \strokec2 SqlTransform
\f1\fs32 \cf2 \cb3 \strokec2 \'a0that windows the data each minute and counts the number of pageviews. Write the results to BigQuery to the table provided by the command-line options.\
For reference, here is an example of a fixed windowed query, or you can reference the same query you implemented in the\'a0{\field{\*\fldinst{HYPERLINK "https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/quests/dataflow_python/4_SQL_Batch_Analytics/solution/batch_minute_traffic_SQL_pipeline.py"}}{\fldrslt \cf2 \cb3 \strokec2 previous SQL lab}}.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls18\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Add the following SQL query to the file in the\'a0
\f6\fs30 \cb9 query
\f1\fs32 \cb3 \'a0variable definition:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 SELECT\
    COUNT(*) AS page_views,\
    STRING(window_start) AS start_time\
FROM\
    TUMBLE(\
        (SELECT TIMESTAMP(event_timestamp) AS ts FROM PCOLLECTION),\
        DESCRIPTOR(ts),\
        'INTERVAL 1 MINUTE')\
GROUP BY window_start\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Task 4. Execute the pipeline\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls19\ilvl0
\f1\b0\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Return to the terminal and execute the following commands to run your pipeline:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf10 \cb3 \strokec10 export\cf5 \cb3 \strokec8  PROJECT_ID=$(gcloud\cf10 \cb3 \strokec10  config \cf5 \cb3 \strokec8 get-value project)\
\cf10 \cb3 \strokec10 export\cf5 \cb3 \strokec8  REGION=Region\
\cf10 \cb3 \strokec10 export\cf5 \cb3 \strokec8  BUCKET=gs://$\{PROJECT_ID\}\
\cf10 \cb3 \strokec10 export\cf5 \cb3 \strokec8  PIPELINE_FOLDER=\cf11 \cb3 \strokec11 $\{BUCKET\}\cf5 \cb3 \strokec8 \
\cf10 \cb3 \strokec10 export\cf5 \cb3 \strokec8  RUNNER=DataflowRunner\
\cf10 \cb3 \strokec10 export\cf5 \cb3 \strokec8  PUBSUB_TOPIC=projects/$\{PROJECT_ID\}/topics/my_topic\
\cf10 \cb3 \strokec10 export\cf5 \cb3 \strokec8  TABLE_NAME=\cf11 \cb3 \strokec11 $\{PROJECT_ID\}\cf5 \cb3 \strokec8 :logs.minute_traffic\
\
\
python3 streaming_minute_traffic_SQL_pipeline.py \\\
--project=\cf11 \cb3 \strokec11 $\{PROJECT_ID\}\cf5 \cb3 \strokec8  \\\
--region=\cf11 \cb3 \strokec11 $\{REGION\}\cf5 \cb3 \strokec8  \\\
--staging_location=\cf11 \cb3 \strokec11 $\{PIPELINE_FOLDER\}\cf5 \cb3 \strokec8 /staging \\\
--temp_location=\cf11 \cb3 \strokec11 $\{PIPELINE_FOLDER\}\cf5 \cb3 \strokec8 /temp \\\
--runner=\cf11 \cb3 \strokec11 $\{RUNNER\}\cf5 \cb3 \strokec8  \\\
--input_topic=\cf11 \cb3 \strokec11 $\{PUBSUB_TOPIC\}\cf5 \cb3 \strokec8  \\\
--table_name=\cf11 \cb3 \strokec11 $\{TABLE_NAME\}\cf5 \cb3 \strokec8  \\\
--experiments=use_runner_v2\
\pard\pardeftab720\partightenfactor0

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\pardeftab720\partightenfactor0

\f4\b\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf5 \cb6 \strokec5 Note:\'a0
\f1\b0 \AppleTypeServices If you get a Dataflow pipeline failed error saying that it is unable to open the
\f5 \AppleTypeServices\AppleTypeServicesF65539 \'a0
\f6\fs30 \AppleTypeServices \cf5 \cb9 \strokec5 pipeline.pb
\f5\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf5 \cb6 \strokec5 \'a0
\f1 \AppleTypeServices file, run the pipeline again and it should run with no issues.\
\
\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Task 5. Generate lag-less streaming input\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 The code for this quest includes a script for publishing JSON events using Pub/Sub. To complete this task and start publishing messages, open a\'a0
\f0\b \cf2 \cb3 \strokec2 new terminal
\f1\b0 \cf2 \cb3 \strokec2 \'a0side-by-side your current one and run the following script. It keeps publishing messages until you kill the script.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls20\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Make sure you are in the\'a0
\f6\fs30 \cb9 training-data-analyst/quests/dataflow_python
\f1\fs32 \cb3 \'a0folder:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 cd /home/jupyter/training-data-analyst/quests/dataflow_python/\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \

\f6\fs28 \cb3 \strokec8 bash generate_streaming_events.sh\cf0 \

\f1\fs32 \cf5 \cb1 \strokec5 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 Examine your results after a few minutes have windowed and written to BigQuery, then cancel the pipeline and generator.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls21\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In BigQuery, query the result data:\cb1 \
\pard\pardeftab720\partightenfactor0

\f6\fs28 \cf5 \cb3 \strokec8 SELECT * FROM logs.minute_traffic\cf0 \
\pard\pardeftab720\partightenfactor0

\f5\fs24 \AppleTypeServices\AppleTypeServicesF65539 \cf5 \cb6 \strokec5 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0

\f1\fs32 \AppleTypeServices \cf2 \cb1 \strokec2 \
}