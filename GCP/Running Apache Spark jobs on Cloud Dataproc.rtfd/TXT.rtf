{\rtf1\ansi\ansicpg1252\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Bold;\f1\froman\fcharset0 Times-Roman;\f2\fswiss\fcharset0 Helvetica;
\f3\fmodern\fcharset0 Courier;\f4\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;\red24\green25\blue27;\red255\green255\blue255;\red0\green0\blue0;
\red24\green24\blue24;\red227\green236\blue254;\red254\green246\blue217;\red251\green226\blue224;}
{\*\expandedcolortbl;;\cssrgb\c12549\c12941\c14118;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0\c5098;
\cssrgb\c12157\c12157\c12157;\cssrgb\c90980\c94118\c99608;\cssrgb\c99608\c96863\c87843;\cssrgb\c98824\c90980\c90196;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat6\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat7\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid12}
{\list\listtemplateid13\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat4\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid13}
{\list\listtemplateid14\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1301\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid14}
{\list\listtemplateid15\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid15}
{\list\listtemplateid16\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1501\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid16}
{\list\listtemplateid17\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1601\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid17}
{\list\listtemplateid18\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1701\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid18}
{\list\listtemplateid19\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid19}
{\list\listtemplateid20\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid20}
{\list\listtemplateid21\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid21}
{\list\listtemplateid22\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid22}
{\list\listtemplateid23\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid23}
{\list\listtemplateid24\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid24}
{\list\listtemplateid25\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2401\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid25}
{\list\listtemplateid26\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat9\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid26}
{\list\listtemplateid27\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat10\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid27}
{\list\listtemplateid28\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat11\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid28}
{\list\listtemplateid29\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat12\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid29}
{\list\listtemplateid30\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid2901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid30}
{\list\listtemplateid31\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid3001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid31}
{\list\listtemplateid32\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat6\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid32}
{\list\listtemplateid33\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat10\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid33}
{\list\listtemplateid34\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat11\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid34}
{\list\listtemplateid35\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat13\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid35}
{\list\listtemplateid36\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat15\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid36}
{\list\listtemplateid37\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat16\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid37}
{\list\listtemplateid38\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid38}
{\list\listtemplateid39\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid39}
{\list\listtemplateid40\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid3901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid40}
{\list\listtemplateid41\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat4\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid41}
{\list\listtemplateid42\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid42}
{\list\listtemplateid43\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid43}
{\list\listtemplateid44\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid44}
{\list\listtemplateid45\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat4\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid45}
{\list\listtemplateid46\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat6\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid46}
{\list\listtemplateid47\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat7\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid47}
{\list\listtemplateid48\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat11\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid4701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid48}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}{\listoverride\listid13\listoverridecount0\ls13}{\listoverride\listid14\listoverridecount0\ls14}{\listoverride\listid15\listoverridecount0\ls15}{\listoverride\listid16\listoverridecount0\ls16}{\listoverride\listid17\listoverridecount0\ls17}{\listoverride\listid18\listoverridecount0\ls18}{\listoverride\listid19\listoverridecount0\ls19}{\listoverride\listid20\listoverridecount0\ls20}{\listoverride\listid21\listoverridecount0\ls21}{\listoverride\listid22\listoverridecount0\ls22}{\listoverride\listid23\listoverridecount0\ls23}{\listoverride\listid24\listoverridecount0\ls24}{\listoverride\listid25\listoverridecount0\ls25}{\listoverride\listid26\listoverridecount0\ls26}{\listoverride\listid27\listoverridecount0\ls27}{\listoverride\listid28\listoverridecount0\ls28}{\listoverride\listid29\listoverridecount0\ls29}{\listoverride\listid30\listoverridecount0\ls30}{\listoverride\listid31\listoverridecount0\ls31}{\listoverride\listid32\listoverridecount0\ls32}{\listoverride\listid33\listoverridecount0\ls33}{\listoverride\listid34\listoverridecount0\ls34}{\listoverride\listid35\listoverridecount0\ls35}{\listoverride\listid36\listoverridecount0\ls36}{\listoverride\listid37\listoverridecount0\ls37}{\listoverride\listid38\listoverridecount0\ls38}{\listoverride\listid39\listoverridecount0\ls39}{\listoverride\listid40\listoverridecount0\ls40}{\listoverride\listid41\listoverridecount0\ls41}{\listoverride\listid42\listoverridecount0\ls42}{\listoverride\listid43\listoverridecount0\ls43}{\listoverride\listid44\listoverridecount0\ls44}{\listoverride\listid45\listoverridecount0\ls45}{\listoverride\listid46\listoverridecount0\ls46}{\listoverride\listid47\listoverridecount0\ls47}{\listoverride\listid48\listoverridecount0\ls48}}
\paperw11900\paperh16840\margl1440\margr1440\vieww33100\viewh16740\viewkind0
\deftab720
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Overview\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 In this lab you will learn how to migrate Apache Spark code to Cloud Dataproc. You will follow a sequence of steps progressively moving more of the job components over to Google Cloud services:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Run original Spark code on Cloud Dataproc (Lift and Shift)\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Replace HDFS with Cloud Storage (cloud-native)\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Automate everything so it runs on job-specific clusters (cloud-optimized)\cb1 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 What you'll learn\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 In this lab you will learn how to:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Migrate existing Spark jobs to Cloud Dataproc\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Modify Spark jobs to use Cloud Storage instead of HDFS\cb1 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Optimize Spark jobs to run on Job specific clusters\cb1 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 What you'll use\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0
\f1\fs32 \cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Cloud Dataproc\cb1 \
\ls3\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Apache Spark\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\cf2 \
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 Check project permissions\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 Before you begin your work on Google Cloud, you need to ensure that your project has the correct permissions within Identity and Access Management (IAM).\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls4\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Google Cloud console, on the\'a0
\f0\b Navigation menu
\f1\b0 \'a0(\cb1 {{\NeXTGraphic tkgw1TDgj4Q+YKQUW4jUFd0O5OEKlUMBRYbhlCrF0WY=.png \width300 \height260 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\cb3 ), select\'a0
\f0\b IAM & Admin
\f1\b0 \'a0>\'a0
\f0\b IAM
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls4\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Confirm that the default compute Service Account\'a0
\f3\fs30 \cb4 \{project-number\}-compute@developer.gserviceaccount.com
\f1\fs32 \cb3 \'a0is present and has the\'a0
\f3\fs30 \cb4 editor
\f1\fs32 \cb3 \'a0role assigned. The account prefix is the project number, which you can find on\'a0
\f0\b Navigation menu > Cloud Overview > Dashboard
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\cf2 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf5 \cb6 \strokec5 Note:\'a0
\f4\b0 \AppleTypeServices\AppleTypeServicesF65539 If the account is not present in IAM or does not have the\'a0
\f3\fs30 \AppleTypeServices \cb4 editor
\f4\fs32 \AppleTypeServices\AppleTypeServicesF65539 \cb6 \'a0role, follow the steps below to assign the required role.\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls5\ilvl0
\f1 \AppleTypeServices \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Google Cloud console, on the\'a0
\f0\b Navigation menu
\f1\b0 , click\'a0
\f0\b Cloud Overview > Dashboard
\f1\b0 .\cb1 \
\ls5\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Copy the project number (e.g.\'a0
\f3\fs30 \cb4 729328892908
\f1\fs32 \cb3 ).\cb1 \
\ls5\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 On the\'a0
\f0\b Navigation menu
\f1\b0 , select\'a0
\f0\b IAM & Admin
\f1\b0 \'a0>\'a0
\f0\b IAM
\f1\b0 .\cb1 \
\ls5\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 At the top of the roles table, below\'a0
\f0\b View by Principals
\f1\b0 , click\'a0
\f0\b Grant Access
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls5\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For\'a0
\f0\b New principals
\f1\b0 , type:\
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \cb1 \
  \{project-number\}-compute@developer.gserviceaccount.com\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls6\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Replace\'a0
\f3\fs30 \cb4 \{project-number\}
\f1\fs32 \cb3 \'a0with your project number.\cb1 \
\ls6\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For\'a0
\f0\b Role
\f1\b0 , select\'a0
\f0\b Project
\f1\b0 \'a0(or Basic) >\'a0
\f0\b Editor
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls6\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Save
\f1\b0 .\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \strokec2 Scenario\
\pard\pardeftab720\sa480\partightenfactor0

\f1\b0\fs32 \cf2 You are migrating an existing Spark workload to Cloud Dataproc and then progressively modifying the Spark code to make use of Google Cloud native features and services.\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 Task 1. Lift and shift\
\pard\pardeftab720\sa640\partightenfactor0

\f2\b0\fs48 \cf2 Migrate existing Spark jobs to Cloud Dataproc\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 You will create a new Cloud Dataproc cluster and then run an imported Jupyter notebook that uses the cluster's default local Hadoop Distributed File system (HDFS) to store source data and then process that data just as you would on any Hadoop cluster using Spark. This demonstrates how many existing analytics workloads such as Jupyter notebooks containing Spark code require no changes when they are migrated to a Cloud Dataproc environment.\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Configure and start a Cloud Dataproc cluster\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls7\ilvl0
\f1\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Google Cloud console, on the\'a0
\f0\b Navigation menu
\f1\b0 , in the\'a0
\f0\b Analytics
\f1\b0 \'a0section, click\'a0
\f0\b Dataproc
\f1\b0 .\cb1 \
\ls7\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Create Cluster
\f1\b0 .\cb1 \
\ls7\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Create
\f1\b0 \'a0for the item\'a0
\f0\b Cluster on Compute Engine
\f1\b0 .\cb1 \
\ls7\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Enter\'a0
\f3\fs30 \cb4 sparktodp
\f1\fs32 \cb3 \'a0for\'a0
\f0\b Cluster Name
\f1\b0 .\cb1 \
\ls7\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Set the Region to\'a0
\f3 \cb7 REGION
\f1 \cb3 \'a0and zone to\'a0
\f3 \cb7 ZONE
\f1 \cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls7\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the\'a0
\f0\b Versioning
\f1\b0 \'a0section, click\'a0
\f0\b Change
\f1\b0 \'a0and select\'a0
\f0\b 2.1 (Debian 11, Hadoop 3.3, Spark 3.3)
\f1\b0 .\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 This version includes Python3, which is required for the sample code used in this lab.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls8\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Select
\f1\b0 .\cb1 \
\ls8\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the\'a0
\f0\b Components
\f1\b0 \'a0>\'a0
\f0\b Component gateway
\f1\b0 \'a0section, select\'a0
\f0\b Enable component gateway
\f1\b0 .\cb1 \
\ls8\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	9	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Under\'a0
\f0\b Optional components
\f1\b0 , Select\'a0
\f0\b Jupyter Notebook
\f1\b0 .\cb1 \
\ls8\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	10	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Below\'a0
\f0\b Set up cluster
\f1\b0 \'a0from the list on the left side, click\'a0
\f0\b Configure nodes (optional)
\f1\b0 .\cb1 \
\ls8\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	11	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Under\'a0
\f0\b Manager node
\f1\b0 \'a0change\'a0
\f0\b Series
\f1\b0 \'a0to\'a0
\f0\b E2
\f1\b0 \'a0and\'a0
\f0\b Machine Type
\f1\b0 \'a0to\'a0
\f0\b e2-standard-2 (2 vCPU, 8 GB memory)
\f1\b0 .\cb1 \
\ls8\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	12	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Under\'a0
\f0\b Worker nodes
\f1\b0 \'a0change\'a0
\f0\b Series
\f1\b0 \'a0to\'a0
\f0\b E2
\f1\b0 \'a0and\'a0
\f0\b Machine Type
\f1\b0 \'a0to\'a0
\f0\b e2-standard-2 (2 vCPU, 8 GB memory)
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls8\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	13	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Create
\f1\b0 .\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 The cluster should start in a few minutes.\'a0
\f0\b \cf2 \cb3 \strokec2 Please wait until the Cloud Dataproc Cluster is fully deployed to proceed to the next step
\f1\b0 \cf2 \cb3 \strokec2 .\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 Clone the source repository for the lab\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 In the Cloud Shell you clone the Git repository for the lab and copy the required notebook files to the Cloud Storage bucket used by Cloud Dataproc as the home directory for Jupyter notebooks.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls9\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To clone the Git repository for the lab enter the following command in Cloud Shell:\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
git -C ~ clone https://github.com/GoogleCloudPlatform/training-data-analyst\
\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls10\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To locate the default Cloud Storage bucket used by Cloud Dataproc enter the following command in Cloud Shell:\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \strokec2 export DP_STORAGE="gs://$(gcloud dataproc clusters describe sparktodp --region=REGION --format=json | jq -r '.config.configBucket')"\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls11\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To copy the sample notebooks into the Jupyter working folder enter the following command in Cloud Shell:\
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \cb1 \strokec2 \
gcloud storage cp ~/training-data-analyst/quests/sparktobq/*.ipynb $DP_STORAGE/notebooks/jupyter\
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Log in to the Jupyter Notebook\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 As soon as the cluster has fully started up you can connect to the Web interfaces. Click the refresh button to check as it may be deployed fully by the time you reach this stage.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls12\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 On the Dataproc Clusters page wait for the cluster to finish starting and then click the name of your cluster to open the\'a0
\f0\b Cluster details
\f1\b0 \'a0page.\cb1 \
\ls12\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Web Interfaces
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls12\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click the\'a0
\f0\b Jupyter
\f1\b0 \'a0link to open a new Jupyter tab in your browser.\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 This opens the Jupyter home page. Here you can see the contents of the\'a0
\f3\fs30 \cf2 \cb4 \strokec2 /notebooks/jupyter
\f1\fs32 \cf2 \cb3 \strokec2 \'a0directory in Cloud Storage that now includes the sample Jupyter notebooks used in this lab.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls13\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Under the\'a0
\f0\b Files
\f1\b0 \'a0tab, click the\'a0
\f0\b GCS
\f1\b0 \'a0folder and then click\'a0
\f0\b 01_spark.ipynb
\f1\b0 \'a0notebook to open it.\cb1 \
\ls13\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Cell
\f1\b0 \'a0and then\'a0
\f0\b Run All
\f1\b0 \'a0to run all of the cells in the notebook.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls13\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Page back up to the top of the notebook and follow as the notebook completes runs each cell and outputs the results below them.\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 You can now step down through the cells and examine the code as it is processed so that you can see what the notebook is doing. In particular pay attention to where the data is saved and processed from.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls14\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The first code cell fetches the source data file, which is an extract from the KDD Cup competition from the Knowledge, Discovery, and Data (KDD) conference in 1999. The data relates to computer intrusion detection events.\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
!wget https://storage.googleapis.com/cloud-training/dataengineering/lab_assets/sparklab/kddcup.data_10_percent.gz\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls15\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the second code cell, the source data is copied to the default (local) Hadoop file system.\cb1 \
\pard\pardeftab720\partightenfactor0
\cf5 \strokec5 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 !hadoop fs -put kddcup* /\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls16\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the third code cell, the command lists contents of the default directory in the cluster's HDFS file system.\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
!hadoop fs -ls /\
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Reading in data\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 The data are gzipped CSV files. In Spark, these can be read directly using the textFile method and then parsed by splitting each row on commas.\
The Python Spark code starts in cell\'a0
\f3\fs30 \cf2 \cb4 \strokec2 In[4]
\f1\fs32 \cf2 \cb3 \strokec2 .\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls17\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In this cell Spark SQL is initialized and Spark is used to read in the source data as text and then returns the first 5 rows.\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
from pyspark.sql import SparkSession, SQLContext, Row\
\
spark = SparkSession.builder.appName("kdd").getOrCreate()\
sc = spark.sparkContext\
data_file = "hdfs:///kddcup.data_10_percent.gz"\
raw_rdd = sc.textFile(data_file).cache()\
raw_rdd.take(5)\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls18\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In cell\'a0
\f3\fs30 \cb4 In [5]
\f1\fs32 \cb3 \'a0each row is split, using\'a0
\f3\fs30 \cb4 ,
\f1\fs32 \cb3 \'a0as a delimiter and parsed using a prepared inline schema in the code.\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
csv_rdd = raw_rdd.map(lambda row: row.split(","))\
parsed_rdd = csv_rdd.map(lambda r: Row(\
    duration=int(r[0]),\
    protocol_type=r[1],\
    service=r[2],\
    flag=r[3],\
    src_bytes=int(r[4]),\
    dst_bytes=int(r[5]),\
    wrong_fragment=int(r[7]),\
    urgent=int(r[8]),\
    hot=int(r[9]),\
    num_failed_logins=int(r[10]),\
    num_compromised=int(r[12]),\
    su_attempted=r[14],\
    num_root=int(r[15]),\
    num_file_creations=int(r[16]),\
    label=r[-1]\
    )\
)\
parsed_rdd.take(5)\
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Spark analysis\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 In cell\'a0
\f3\fs30 \cf2 \cb4 \strokec2 In [6]\'a0
\f1\fs32 \cf2 \cb3 \strokec2 a Spark SQL context is created and a Spark dataframe using that context is created using the parsed input data from the previous stage.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls19\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Row data can be selected and displayed using the dataframe's\'a0
\f3\fs30 \cb4 .show()
\f1\fs32 \cb3 \'a0method to output a view summarizing a count of selected fields:\cb1 \
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \strokec2 \
sqlContext = SQLContext(sc)\
df = sqlContext.createDataFrame(parsed_rdd)\
connections_by_protocol = df.groupBy('protocol_type').count().orderBy('count', ascending=False)\
connections_by_protocol.show()\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 The\'a0
\f3\fs30 \cb4 .show()
\f1\fs32 \cb3 \'a0method produces an output table similar to this:\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f2\fs24 \cf0 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {{\NeXTGraphic Pasted Graphic.png \width13140 \height4360 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}
\f1\fs32 \
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 SparkSQL can also be used to query the parsed data stored in the Dataframe.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls20\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In cell\'a0
\f3\fs30 \cb4 In [7]
\f1\fs32 \cb3 \'a0a temporary table (
\f3\fs30 \cb4 connections
\f1\fs32 \cb3 ) is registered that is then referenced inside the subsequent SparkSQL SQL query statement:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf5 \strokec5 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf5 df.registerTempTable("connections")\
attack_stats = sqlContext.sql("""\
    SELECT\
      protocol_type,\
      CASE label\
        WHEN 'normal.' THEN 'no attack'\
        ELSE 'attack'\
      END AS state,\
      COUNT(*) as total_freq,\
      ROUND(AVG(src_bytes), 2) as mean_src_bytes,\
      ROUND(AVG(dst_bytes), 2) as mean_dst_bytes,\
      ROUND(AVG(duration), 2) as mean_duration,\
      SUM(num_failed_logins) as total_failed_logins,\
      SUM(num_compromised) as total_compromised,\
      SUM(num_file_creations) as total_file_creations,\
      SUM(su_attempted) as total_root_attempts,\
      SUM(num_root) as total_root_acceses\
    FROM connections\
    GROUP BY protocol_type, state\
    ORDER BY 3 DESC\
    """)\
attack_stats.show()\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 \
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 You will see output similar to this truncated example when the query has finished:\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f2\fs24 \cf0 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {{\NeXTGraphic Pasted Graphic 1.png \width13140 \height5800 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\fs32 \cf0 \
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 And you can now also display this data visually using bar charts.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls21\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The last cell,\'a0
\f3\fs30 \cb4 In [8]
\f1\fs32 \cb3 \'a0uses the\'a0
\f3\fs30 \cb4 %matplotlib inline
\f1\fs32 \cb3 \'a0Jupyter magic function to redirect matplotlib to render a graphic figure inline in the notebook instead of just dumping the data into a variable. This cell displays a bar chart using the\'a0
\f3\fs30 \cb4 attack_stats
\f1\fs32 \cb3 \'a0query from the previous step.\cb1 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf2 \cb3 \strokec2 \
%matplotlib inline\
ax = attack_stats.toPandas().plot.bar(x='protocol_type', subplots=True, figsize=(10,25))\
\
\pard\pardeftab720\partightenfactor0
\cf2 The first part of the output should look like the following chart once all cells in the notebook have run successfully. You can scroll down in your notebook to see the complete output chart.\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f2\fs24 \cf0 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {{\NeXTGraphic Pasted Graphic 2.png \width13140 \height5800 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\fs32 \cf0 \
\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Task 2. Separate compute and storage\
\pard\pardeftab720\sa640\partightenfactor0

\f2\b0\fs48 \cf2 Modify Spark jobs to use Cloud Storage instead of HDFS\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 Taking this original 'Lift & Shift' sample notebook you will now create a copy that decouples the storage requirements for the job from the compute requirements. In this case, all you have to do is replace the Hadoop file system calls with Cloud Storage calls by replacing\'a0
\f3\fs30 \cf2 \cb4 \strokec2 hdfs://
\f1\fs32 \cf2 \cb3 \strokec2 \'a0storage references with\'a0
\f3\fs30 \cf2 \cb4 \strokec2 gs://
\f1\fs32 \cf2 \cb3 \strokec2 \'a0references in the code and adjusting folder names as necessary.\
You start by using the cloud shell to place a copy of the source data in a new Cloud Storage bucket.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls22\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Cloud Shell create a new storage bucket for your source data:\cb1 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf2 \cb3 \strokec2 \
export PROJECT_ID=$(gcloud info --format='value(config.project)')\
gcloud storage buckets create gs://$PROJECT_ID\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls23\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Cloud Shell copy the source data into the bucket:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf5 \strokec5 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf2 \cb3 \strokec2 wget https://storage.googleapis.com/cloud-training/dataengineering/lab_assets/sparklab/kddcup.data_10_percent.gz\
gcloud storage cp kddcup.data_10_percent.gz gs://$PROJECT_ID/\
\
\pard\pardeftab720\partightenfactor0
\cf2 Make sure that the last command completes and the file has been copied to your new storage bucket.\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls24\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Switch back to the\'a0
\f3\fs30 \cb4 01_spark
\f1\fs32 \cb3 \'a0Jupyter Notebook tab in your browser.\cb1 \
\ls24\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b File
\f1\b0 \'a0and then select\'a0
\f0\b Make a Copy
\f1\b0 .\cb1 \
\ls24\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 When the copy opens, click the\'a0
\f0\b 01_spark-Copy1
\f1\b0 \'a0title and rename it to\'a0
\f3\fs30 \cb4 De-couple-storage
\f1\fs32 \cb3 .\cb1 \
\ls24\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Open the Jupyter tab for\'a0
\f3\fs30 \cb4 01_spark
\f1\fs32 \cb3 .\cb1 \
\ls24\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b File
\f1\b0 \'a0and then\'a0
\f0\b Save and checkpoint
\f1\b0 \'a0to save the notebook.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls24\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b File
\f1\b0 \'a0and then\'a0
\f0\b Close and Halt
\f1\b0 \'a0to shutdown the notebook.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls25\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 If you are prompted to confirm that you want to close the notebook click\'a0
\f0\b Leave
\f1\b0 \'a0or\'a0
\f0\b Cancel
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls26\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	9	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Switch back to the\'a0
\f3\fs30 \cb4 De-couple-storage
\f1\fs32 \cb3 \'a0Jupyter Notebook tab in your browser, if necessary.\
\pard\tx720\pardeftab720\partightenfactor0
\cf2 \cb1 \strokec2 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 You no longer need the cells that download and copy the data onto the cluster's internal HDFS file system so you will remove those first.\
To delete a cell, you click in the cell to select it and then click the\'a0
\f0\b \cf2 \cb3 \strokec2 cut selected cells
\f1\b0 \cf2 \cb3 \strokec2 \'a0icon (the scissors) on the notebook toolbar.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls27\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	10	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Delete the initial comment cells and the first three code cells (\'a0
\f3\fs30 \cb4 In [1]
\f1\fs32 \cb3 ,\'a0
\f3\fs30 \cb4 In [2]
\f1\fs32 \cb3 , and\'a0
\f3\fs30 \cb4 In [3]
\f1\fs32 \cb3 ) so that the notebook now starts with the section\'a0
\f0\b Reading in Data
\f1\b0 .\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 You will now change the code in the first cell ( still called\'a0
\f3\fs30 \cf2 \cb4 \strokec2 In[4]
\f1\fs32 \cf2 \cb3 \strokec2 \'a0unless you have rerun the notebook ) that defines the data file source location and reads in the source data. The cell currently contains the following code:\
from pyspark.sql import SparkSession, SQLContext, Row\
spark = SparkSession.builder.appName("kdd").getOrCreate()\
sc = spark.sparkContext\
data_file = "hdfs:///kddcup.data_10_percent.gz"\
raw_rdd = sc.textFile(data_file).cache()\
raw_rdd.take(5)\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls28\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	11	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Replace the contents of cell\'a0
\f3\fs30 \cb4 In [4]
\f1\fs32 \cb3 \'a0with the following code. The only change here is create a variable to store a Cloud Storage bucket name and then to point the\'a0
\f3\fs30 \cb4 data_file
\f1\fs32 \cb3 \'a0to the bucket we used to store the source data on Cloud Storage:\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 \
from pyspark.sql import SparkSession, SQLContext, Row\
gcs_bucket='[Your-Bucket-Name]'\
spark = SparkSession.builder.appName("kdd").getOrCreate()\
sc = spark.sparkContext\
data_file = "gs://"+gcs_bucket+"//kddcup.data_10_percent.gz"\
raw_rdd = sc.textFile(data_file).cache()\
raw_rdd.take(5)\
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 When you have replaced the code the first cell will look similar to the following, with your lab project ID as the bucket name:\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f2\fs24 \cf0 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {{\NeXTGraphic Pasted Graphic 3.png \width13140 \height3020 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\fs32 \cf0 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls29\ilvl0\cf2 \cb3 {\listtext	12	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the cell you just updated, replace the placeholder\'a0
\f3\fs30 \cb4 [Your-Bucket-Name]
\f1\fs32 \cb3 \'a0with the name of the storage bucket you created in the first step of this section. You created that bucket using the Project ID as the name, which you can copy here from the Qwiklabs lab login information panel on the left of this screen. Replace all of the placeholder text, including the brackets\'a0
\f3\fs30 \cb4 []
\f1\fs32 \cb3 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls29\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	13	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Cell
\f1\b0 \'a0and then\'a0
\f0\b Run All
\f1\b0 \'a0to run all of the cells in the notebook.\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 You will see exactly the same output as you did when the file was loaded and run from internal cluster storage. Moving the source data files to Cloud Storage only requires that you repoint your storage source reference from\'a0
\f3\fs30 \cf2 \cb4 \strokec2 hdfs://
\f1\fs32 \cf2 \cb3 \strokec2 \'a0to\'a0
\f3\fs30 \cf2 \cb4 \strokec2 gs://
\f1\fs32 \cf2 \cb3 \strokec2 .\
\pard\pardeftab720\sa640\partightenfactor0

\f0\b\fs60 \cf2 Task 3. Deploy Spark jobs\
\pard\pardeftab720\sa640\partightenfactor0

\f2\b0\fs48 \cf2 Optimize Spark jobs to run on Job specific clusters\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 You now create a standalone Python file, that can be deployed as a Cloud Dataproc Job, that will perform the same functions as this notebook. To do this you add magic commands to the Python cells in a copy of this notebook to write the cell contents out to a file. You will also add an input parameter handler to set the storage bucket location when the Python script is called to make the code more portable.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls30\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the\'a0
\f3\fs30 \cb4 De-couple-storage
\f1\fs32 \cb3 \'a0Jupyter Notebook menu, click\'a0
\f0\b File
\f1\b0 \'a0and select\'a0
\f0\b Make a Copy
\f1\b0 .\cb1 \
\ls30\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 When the copy opens, click the\'a0
\f0\b De-couple-storage-Copy1
\f1\b0 \'a0and rename it to\'a0
\f3\fs30 \cb4 PySpark-analysis-file
\f1\fs32 \cb3 .\cb1 \
\ls30\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Open the Jupyter tab for\'a0
\f3\fs30 \cb4 De-couple-storage
\f1\fs32 \cb3 .\cb1 \
\ls30\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b File
\f1\b0 \'a0and then\'a0
\f0\b Save and checkpoint
\f1\b0 \'a0to save the notebook.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls30\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b File
\f1\b0 \'a0and then\'a0
\f0\b Close and Halt
\f1\b0 \'a0to shutdown the notebook.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls31\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 If you are prompted to confirm that you want to close the notebook click\'a0
\f0\b Leave
\f1\b0 \'a0or\'a0
\f0\b Cancel
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls32\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Switch back to the\'a0
\f3\fs30 \cb4 PySpark-analysis-file
\f1\fs32 \cb3 \'a0Jupyter Notebook tab in your browser, if necessary.\cb1 \
\ls32\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click the first cell at the top of the notebook.\cb1 \
\ls32\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Insert
\f1\b0 \'a0and select\'a0
\f0\b Insert Cell Above
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls32\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	9	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Paste the following library import and parameter handling code into this new first code cell:\cb1 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf2 \cb3 \strokec2 \
%%writefile spark_analysis.py\
\
import matplotlib\
matplotlib.use('agg')\
\
import argparse\
parser = argparse.ArgumentParser()\
parser.add_argument("--bucket", help="bucket for input and output")\
args = parser.parse_args()\
\
BUCKET = args.bucket\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 The\'a0
\f3\fs30 \cf2 \cb4 \strokec2 %%writefile spark_analysis.py
\f1\fs32 \cf2 \cb3 \strokec2 \'a0Jupyter magic command creates a new output file to contain your standalone python script. You will add a variation of this to the remaining cells to append the contents of each cell to the standalone script file.\
This code also imports the\'a0
\f3\fs30 \cf2 \cb4 \strokec2 matplotlib
\f1\fs32 \cf2 \cb3 \strokec2 \'a0module and explicitly sets the default plotting backend via\'a0
\f3\fs30 \cf2 \cb4 \strokec2 matplotlib.use('agg')
\f1\fs32 \cf2 \cb3 \strokec2 \'a0so that the plotting code runs outside of a Jupyter notebook.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls33\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	10	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For the remaining cells insert\'a0
\f3\fs30 \cb4 %%writefile -a spark_analysis.py
\f1\fs32 \cb3 \'a0at the start of each Python code cell. These are the five cells labelled\'a0
\f0\b In [x]
\f1\b0 .\cb1 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf2 \cb3 \strokec2 \
%%writefile -a spark_analysis.py\
\
\pard\pardeftab720\partightenfactor0
\cf2 For example the next cell should now look as follows:\
\
%%writefile -a spark_analysis.py\
\
from pyspark.sql import SparkSession, SQLContext, Row\
\
spark = SparkSession.builder.appName("kdd").getOrCreate()\
sc = spark.sparkContext\
data_file = "gs://\{\}/kddcup.data_10_percent.gz".format(BUCKET)\
raw_rdd = sc.textFile(data_file).cache()\
#raw_rdd.take(5)\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls34\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	11	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Repeat this step, inserting\'a0
\f3\fs30 \cb4 %%writefile -a spark_analysis.py
\f1\fs32 \cb3 \'a0at the start of each code cell until you reach the end.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls34\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	12	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the last cell, where the Pandas bar chart is plotted, remove the\'a0
\f3\fs30 \cb4 %matplotlib inline
\f1\fs32 \cb3 \'a0magic command.\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f0\b \cf5 \cb8 \strokec5 Note:\'a0
\f4\b0 \AppleTypeServices\AppleTypeServicesF65539 You must remove this inline matplotlib Jupyter magic directive or your script will fail when you run it.\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls35\ilvl0
\f1 \AppleTypeServices \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	13	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Make sure you have selected the last code cell in the notebook then, in the menu bar, click\'a0
\f0\b Insert
\f1\b0 \'a0and select\'a0
\f0\b Insert Cell Below
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls35\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	14	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Paste the following code into the new cell:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
%%writefile -a spark_analysis.py\
\
ax[0].get_figure().savefig('report.png');\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls36\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	15	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Add another new cell at the end of the notebook and paste in the following:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
%%writefile -a spark_analysis.py\
\
import google.cloud.storage as gcs\
bucket = gcs.Client().get_bucket(BUCKET)\
for blob in bucket.list_blobs(prefix='sparktodp/'):\
    blob.delete()\
bucket.blob('sparktodp/report.png').upload_from_filename('report.png')\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls37\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	16	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Add a new cell at the end of the notebook and paste in the following:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
%%writefile -a spark_analysis.py\
\
connections_by_protocol.write.format("csv").mode("overwrite").save(\
    "gs://\{\}/sparktodp/connections_by_protocol".format(BUCKET))\
\
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \cf2 \cb3 \strokec2 Test automation\
\pard\pardeftab720\sa480\partightenfactor0

\f1\fs32 \cf2 You now test that the PySpark code runs successfully as a file by calling the local copy from inside the notebook, passing in a parameter to identify the storage bucket you created earlier that stores the input data for this job. The same bucket will be used to store the report data files produced by the script.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls38\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the\'a0
\f3\fs30 \cb4 PySpark-analysis-file
\f1\fs32 \cb3 \'a0notebook add a new cell at the end of the notebook and paste in the following:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
\
BUCKET_list = !gcloud info --format='value(config.project)'\
BUCKET=BUCKET_list[0]\
print('Writing to \{\}'.format(BUCKET))\
!/opt/conda/miniconda3/bin/python spark_analysis.py --bucket=$BUCKET\
\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 This code assumes that you have followed the earlier instructions and created a Cloud Storage Bucket using your lab Project ID as the Storage Bucket name. If you used a different name modify this code to set the\'a0
\f3\fs30 \cf2 \cb4 \strokec2 BUCKET
\f1\fs32 \cf2 \cb3 \strokec2 \'a0variable to the name you used.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls39\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Add a new cell at the end of the notebook and paste in the following:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
\
!gcloud storage ls gs://$BUCKET/sparktodp/**\
\
\
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 This lists the script output files that have been saved to your Cloud Storage bucket.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls40\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To save a copy of the Python file to persistent storage, add a new cell and paste in the following:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
\
!gcloud storage cp spark_analysis.py gs://$BUCKET/sparktodp/spark_analysis.py\
\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls41\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Cell
\f1\b0 \'a0and then\'a0
\f0\b Run All
\f1\b0 \'a0to run all of the cells in the notebook.\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 If the notebook successfully creates and runs the Python file you should see output similar to the following for the last two cells. This indicates that the script has run to completion saving the output to the Cloud Storage bucket you created earlier in the lab.\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f2\fs24 \cf0 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {{\NeXTGraphic Pasted Graphic 4.png \width13140 \height3020 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f1\fs32 \cf0 \
\
\pard\pardeftab720\partightenfactor0

\f0\b \cf5 \cb6 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 Note:\'a0
\f4\b0 \AppleTypeServices\AppleTypeServicesF65539 The most likely source of an error at this stage is that you did not remove the matplotlib directive in\'a0
\f0\b \AppleTypeServices In [7]
\f4\b0 \AppleTypeServices\AppleTypeServicesF65539 . Recheck that you have modified all of the cells as per the instructions above, and have not skipped any steps.\
\
\pard\pardeftab720\sa640\partightenfactor0

\f2\fs48 \AppleTypeServices \cf2 \cb3 \strokec2 Run the Analysis Job from Cloud Shell.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls42\ilvl0
\f1\fs32 \cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Switch back to your Cloud Shell and copy the Python script from Cloud Storage so you can run it as a Cloud Dataproc Job:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
gcloud storage cp gs://$PROJECT_ID/sparktodp/spark_analysis.py spark_analysis.py\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls43\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Create a launch script:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
nano submit_onejob.sh\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls44\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Paste the following into the script:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
#!/bin/bash\
gcloud dataproc jobs submit pyspark \\\
       --cluster sparktodp \\\
       --region REGION \\\
       spark_analysis.py \\\
       -- --bucket=$1\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls45\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Press\'a0
\f3\fs30 \cb4 CTRL+X
\f1\fs32 \cb3 \'a0then\'a0
\f3\fs30 \cb4 Y
\f1\fs32 \cb3 \'a0and\'a0
\f3\fs30 \cb4 Enter
\f1\fs32 \cb3 \'a0key to exit and save.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls45\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	5	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Make the script executable:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
chmod +x submit_onejob.sh\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls46\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	6	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Launch the PySpark Analysis job:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
./submit_onejob.sh $PROJECT_ID\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls47\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	7	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the Cloud Console tab navigate to the\'a0
\f0\b Dataproc
\f1\b0 \'a0>\'a0
\f0\b Clusters
\f1\b0 \'a0page if it is not already open.\cb1 \
\ls47\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	8	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b Jobs
\f1\b0 .\cb1 \
\ls47\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	9	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click the name of the job that is listed. You can monitor progress here as well as from the Cloud shell. Wait for the Job to complete successfully.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls47\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	10	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Navigate to your storage bucket and note that the output report,\'a0
\f3\fs30 \cb4 /sparktodp/report.png
\f1\fs32 \cb3 \'a0has an updated time-stamp indicating that the stand-alone job has completed successfully.\cb1 \
\pard\pardeftab720\sa480\partightenfactor0
\cf2 \cb3 \strokec2 The storage bucket used by this Job for input and output data storage is the bucket that is used just the Project ID as the name.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa360\partightenfactor0
\ls48\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	11	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Navigate back to the\'a0
\f0\b Dataproc
\f1\b0 \'a0>\'a0
\f0\b Clusters
\f1\b0 \'a0page.\cb1 \
\ls48\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	12	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Select the\'a0
\f0\b sparktodp
\f1\b0 \'a0cluster and click\'a0
\f0\b Delete
\f1\b0 . You don't need it any more.\cb1 \
\ls48\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	13	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Click\'a0
\f0\b CONFIRM
\f1\b0 .\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls48\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	14	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Close the\'a0
\f0\b Jupyter
\f1\b0 \'a0tabs in your browser.\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 \
\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf2 \
\
\pard\pardeftab720\partightenfactor0
\cf2 \
\cf0 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \
\cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \
}