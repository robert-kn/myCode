for the client side, kafka provides different types of clients such as:

- kafka cli: a collection of shell scripts to communicate with the kafka server
- many high level programming apis such as python, java and scala, go, c/c++
- rest apis
- specific third party clients made by kafka community

you can choose different clients based on your requirements.

see kafkaArchitecture.png

kafka-python is a python client for the apache kafka distributed stream processing system. It aims
to provide similar functionalities as the main kafka java client. With kafka-python you can 
interact with the kafka server to manage topics, publish and consume messages in the python 
programming language.

You must install kafka-python using pip3 installer:

pip3 install kafka-python

"KafkaAdminClient" class

The main purpose of KafkaAdminClient class is to enable fundamental administrative management 
operations on kafka server such as creating/deleting topic, retrieving, and updating topic 
configurations and so on.

Let's check some code examples:

To use KafkaAdminClient, you first need to define and create a KafkaAdminClient object.

admin_client = KafkaAdminClient(bootstrap_servers="localhost:9092", client_id='test')

bootstrap_servers="localhost:9092" argument specifies the host/IP and port that the consumer should contact to bootstrap initial cluster metadata
client_id specifies an id of current admin client

The most common use of the admin_client is managing topics, such as creating and deleting topics. To create topics, you must first define an empty topic list:

topic_list = []

Then, you use the NewTopic class to create a topic with name, partition, and replication 
factors. For example, name equals bankbranch, partition nums equals 2, and replication factor 
equals 1.

new_topic = NewTopic(name="bankbranch", num_partitions= 2, replication_factor=1)
topic_list.append(new_topic)

You can use create_topics(...) method to create topics.
admin_client.create_topics(new_topics=topic_list)

Note: The create topic operation used above is equivalent to using kafka-topics.sh --topic in Kafka CLI client.


Describe a topic

After the topics are created, you can check its configuration details using the 
describe_configs() method.

configs = admin_client.describe_configs(
    config_resources=[ConfigResource(ConfigResourceType.TOPIC, "bankbranch")])

Note: The describe topic operation used above is equivalent to using kafka-topics.sh --describe in Kafka CLI client.


KafkaProducer

Having created the new bankbranch topic, you can start producing messages.

For kafka-python, you will use KafkaProducer class to produce messages. Since many real-world 
message values are in the JSON format, let's look at how to publish JSON messages as an example.

First, let's define and create a KafkaProducer.

producer = KafkaProducer(value_serializer=lambda v: json.dumps(v).encode('utf-8'))

Since Kafka produces and consumes messages in raw bytes, you need to encode our JSON messages 
and serialize them into bytes. For the value_serializer argument, you will define a lambda 
function to take a Python dict/list object and serialize it into bytes.

Then, with the KafkaProducer created, you can use it to produce two ATM transaction messages in JSON format as follows:

producer.send("bankbranch", {'atmid':1, 'transid':100})
producer.send("bankbranch", {'atmid':2, 'transid':101})

The first argument specifies the topic bankbranch to be sent and the second argument represents
the message value in a Python dict format and will be serialized into bytes.

Note: The above producing message operation is equivalent to using kafka-console-producer.sh --topic in Kafka CLI client.


KafkaConsumer

In the previous step, you published two JSON messages. Now, you can use the KafkaConsumer 
class to consume the messages.

Define and create a KafkaConsumer subscribing to the topic bankbranch:

consumer = KafkaConsumer('bankbranch')

Once the consumer is created, it will receive all available messages from the topic bankbranch.
Then, you can iterate and print them with the following code snippet:

for msg in consumer:
    print(msg.value.decode("utf-8"))

Note: The above consuming message operation is equivalent to using kafka-console-consumer.sh --topic in Kafka CLI client.