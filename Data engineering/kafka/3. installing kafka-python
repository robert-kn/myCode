Download and extract Kafka

wget https://downloads.apache.org/kafka/                      (retrieve the desired binary from folder)

tar -xzf                                                      (to extract the compressed files)

cd                                                            (into the extracted folder)   

Configure KRaft and start server

KAFKA_CLUSTER_ID="$(bin/kafka-storage.sh random-uuid)"        (generate a cluster UUID that will uniquely identify the kafka cluster. This cluster id will be used by the KRaft controller.)

bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties (KRaft requires the log directories to be configured. Run the following command to configure the log directories passing the cluster ID.)

bin/kafka-server-start.sh config/kraft/server.properties (Now that KRaft is configured, you can start the Kafka server by running the following command.)


Create a topic in the admin.py file


Open a new terminal and navigate to the kafka_2.12-3.7.0 directory.

Install the kafka-python package by running the following command.

pip3 install kafka-python

Create a file named admin.py by running the following command.

open the file in edit mode and paste the following content in the file and save it.

from kafka.admin import KafkaAdminClient,NewTopic
admin_client = KafkaAdminClient(bootstrap_servers="localhost:9092", client_id='test')
topic_list = []
new_topic = NewTopic(name="bankbranch", num_partitions= 2, replication_factor=1)
topic_list.append(new_topic)
admin_client.create_topics(new_topics=topic_list)

Note: We are creating a topic "bankbranch" through this code.

Create the producer.py file

Create a file named producer.py by running the following command.

open the file in edit mode and paste the following content in the file and save it.

from kafka import KafkaProducer
import json
producer = KafkaProducer(value_serializer=lambda v: json.dumps(v).encode('utf-8'))
producer.send("bankbranch", {'atmid':1, 'transid':100})
producer.send("bankbranch", {'atmid':2, 'transid':101})

producer.flush()

producer.close()

In the above code, the producer is sending across two messages through this code. These messages will be received by the consumer.


Create the consumer.py file

touch consumer.py

open the file in edit mode and paste the following content in the file and save it.

from kafka import KafkaConsumer
consumer = KafkaConsumer('bankbranch',
                        group_id=None,
                         bootstrap_servers=['localhost:9092'],
                         auto_offset_reset = 'earliest')
print("Hello")
print(consumer)

for msg in consumer:
    print(msg.value.decode("utf-8"))


Execute the three Python files

Execute admin.py and producer.py using the following commands in terminal:

python3 admin.py
python3 producer.py

Open a new terminal and execute the following commands to run consumer.py:

cd kafka_2.12-3.7.0
python3 consumer.py



Practice Exercise

Create a new producer from bankbranch in a file named new_producer.py which will take user input as long as 
the user wants and accept user input for the ATM number they want to transact with (1 or 2) and stream the 
transaction.

Observe the consumer getting the events streamed by the producer in real time.

from kafka import KafkaProducer
import json
producer = KafkaProducer(value_serializer=lambda v: json.dumps(v).encode('utf-8'))
transid = 102
while True:
        user_input = input("Do you want to add a transaction? (press 'n' to stop): ")
        if user_input.lower() == 'n':
            print("Stopping the transactions")
            break
        else:
            atm_choice = input("Which ATM you want to transact in? 1 or 2 ")
            if (atm_choice == '1' or atm_choice == '2'):
                producer.send("bankbranch", {'atmid':int(atm_choice), 'transid':transid})
                producer.flush()
                transid = transid + 1
            else:
                print('Invalid ATM number')
                continue

producer.close()