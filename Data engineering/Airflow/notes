what is apache airflow? see airflow.png

lifecycle of an apache airflow task state? see airflowjobstatus.png

apache airflow features? see airflowFeatures1.png airflowFeatures2.png

what is a dag? see whatisadag1.png and whatisadag2.png

tasks and operators? see tasksandoperators.png

dag definition components? see dagdefcomponents1.png and dagdefcomponents2.png

airflow logging and monitoring? see loggingandmonitoring1.png and loggingandmonitoring2.png

Apache Airflow is a Python framework that helps create workflows using multiple technologies using both CLI and a user-friendly WebUI. An Apache Airflow Directed Acyclic Graph (DAG) is a Python program where you define the tasks and the pipeline with the order in which the tasks will be executed.

Airflow offers a wide range of operators, including many that are built into the core or are provided by pre-installed providers. Some popular core operators include:

BashOperator - executes a bash command

PythonOperator - calls an arbitrary Python function

EmailOperator - sends an email

The other core operators available include:

BaseBranchOperator - A base class for creating operators with branching functionality

BranchDateTimeOperator

EmptyOperator - Operator that does nothing

GenericTransfer - Moves data from on database connection to another.

LatestOnlyOperator - Skip tasks that are not running during the most recent schedule interval.

TriggerDagRunOperator - Triggers a DAG run for a specified dag_id.

Besides these, there are also many community provided operators. Some of the popular and useful ones are:

HttpOperator

MySqlOperator

PostgresOperator

MsSqlOperator

OracleOperator

JdbcOperator

DockerOperator

HiveOperator

S3FileTransformOperator

PrestoToMySqlOperator

SlackAPIOperator

In addition to operators, you also have sensors and decorators that allow you to combine bash and Python. You can find more information regarding the same in this https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/index.html

