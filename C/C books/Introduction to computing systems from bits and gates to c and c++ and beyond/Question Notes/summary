what should you know about fundamentals? they do not change very often

what will mastery of the fundamentals yield? there is no limit to how high I will soar provided I continue to put in the
work 

what is this book about? mastering the fundamentals of computing

what is the conventional wisdom when it comes to teaching computer science? start with a high level programming language
which leads to the memorisation of technical details without an understanding of basic underpinnings

how does the book approach mastering computing fundamentals? a bottom up approach where it continually builds on what is 
covered (scaffolding)

what is technique is widely pervasive when it comes to teaching students any subject? information hiding approach

why is it used? because it is a useful productivity enhancer and allows the student to hit the ground running

what are its drawbacks? information hiding gets in the way of understanding which leads to problems when students have to
think from first principles about for example why a particular error is happening (understanding not memorising)

information hiding is only useful once one has an understanding of the fundamentals. bottom up approach is best for learning
in order to acquire an understanding

does that mean that the top down design approach is flawed?

what was their concern about including C++ in their instructional approach? many of the languages features are too far 
abstracted from the underlying layers to make for an easy fit to their instructional approach. Additionally C++ is a vast 
language that would have necessiated more pages to be added to the book. 

why do they still use C in the book? serves as the defacto development language for systems and hardware oriented projects

what are the two major segments that the book can be broken down into? (a) the underlying structure of a computer (b) programming
in a high level language

why does the C programming language fit very nicely with the bottom up approach? its low level nature allows students to see
clearly the connection between software and the underlying hardware 

why lc-3 ISA and not ARM or RISCV? because commercial ISAs have no place in an introductory course but still have to be
understood in order to be used effectively. They wanted an ISA that was clean with no special cases to deal with, with as few
opcodes as necessary so that you the student spends all your time on the fundamental concepts of the course and very little 
time on the nuances of the instruction set

the lc-3 instruction set with only 15 four-bit opcodes, is small enough that the students can absorb the ISA without struggling
too much

what are the stand out observations of the approach taken in the book?

(a) understanding and not memorising: bottom up learning approach leads to less memorisation of seemingly arbitrary rules
which is prevalent in traditional programming courses. by the time a topic is taught, you will have an understanding of how
the topic is implemented at the levels below it. this approach is good for design courses where understanding of and insights
gained from fundamentals are essential to making the required design trade offs.
(b) you get to debug your own programs
(c) preparation for the future: cutting through protective layers; as a professional, if you are ignorant of what is going
on inside computers you will likely discover the hard way that the effectiveness of your solutions is impacted adversely by
things other than the actual programs you write. serious programmers will write more efficient code if they understand what
is going on beyond the statements in their high level language. high level programming language courses where the compiler 
protects the student from everything ugly underneath does not serve most engineering students well
(d) rippling effects through the curriculum: the material taught in the book has a rippling effect on what can be taught in 
subsequent courses. subsequent programming courses cannot only assume the students know the syntax of C/C++ but also understand
how it relates to the underlying architecture. ergo, the focus can be on problem solving and more sophisticated data structures

how to install the simulator debugger written by the authors for the lc-3 ISA:

download link for the material can be found here: https://highered.mheducation.com/sites/1260150534/student_view0/lc-3_simulator.html

LC3Tools is a cross-platform set of tools to build code for and simulate the LC-3 system described in the book.

The latest version of LC3Tools for all platforms can be found at https://github.com/chiragsakhuja/lc3tools/releases

Windows Users: lc3tools-setup-VERSION.exe
macOS Users: LC3Tools-VERSION.dmg
Linux Users: lc3tools-VERSION-x86_64.AppImage

There are several other resources, including more documentation and instructions on the command line tools, at https://github.com/chiragsakhuja/lc3tools.git 

chapter 1

1. what is the intent of the book? there is no magic to computing as computers are deterministic systems; computers are not 
electronic geniues infact they are electronic idiots that do exactly as they are told 

2. a computer is a complex system made up of? systematically interconnected collection of very simple parts; it is
these simple parts that the book will introduce, explain and tie together to show how they make up a computer

3. what is the main goal of the book? by the time you are finished, you will be able to write programs using a language like C 
and be able to understand what is going on underneath the computer

4. how will we get there? you will see that all information processed by computers is in the form of 0's and 1's. therefore, all 
information processed by computers is encoded as 0's and 1's. you will learn how to process such information

5. what is meant by all information processed by computers is encoded in 0's and 1's? each piece of information has a code point made up
of 1's and 0's

6. what is the lc-3? it is a microprocessor that has all the important characteristics of real microprocessors without being so complicated that it gets in the way of my understanding. so it is a piece of hardware except that it doesn't exist hence when you write code in assembly language or machine language for the lc3 processor, you will need a simulator to see what would happen in the registers and memory of a real lc3 during the execution of a program. all that exists is the ISA and microarchitecture which would implement the ISA

7. what do high level languages enable programmers to do? effectively develop complex sofware by abstracting away the details of the underlying hardware

8. what are the two recurring themes in the book? abstraction and not separating hardware and software layers of a computer

9. define abstraction? technique of establishing a simpler way to interact with a system

10. what is the premise that allows us to use abstraction effectively? allows not getting bogged down in the details of a system when everything is working fine; establishes a simpler way for a person to interect with a system

11. why is abstraction favoured? it is a productivity enhancer as i can deal with a situation at a higher level focusing on the essential aspects whilst keeping component ideas in the background

12. when the detail is not working fine, what must you be able to do? unabstract i.e. go from the abstraction back to its component parts

13. what are modern processors comprised of? transistors

14. what do transistors combine to form? logic gates 

15. what opportunity do logic gates provide? the ability to think in 1's and 0's instead of varying voltages across the transistor wires

16. what does a combination of logic gates produce? a logic circuit - a further abstraction

17. when putting together logic circuits, should a designer be thinking of the internals of each individual gate or treat each gate as a component? treat each gate as a component as thinking of the internals of each gate would slow down the process of designing the logic circuit

18. how can the above thinking be applied to the design of an application program? each component should be thought of as an abstraction (thinking about the internals of each component would be detrimental to progress)

19. why should you be careful about letting abstractions be the deepest level of my understanding? because you will be at the mercy of the component parts working together; if one of them breaks then you won't be able to intervene to get the system up and running again

20. how will the material in the book be presented in terms of abstraction? the level of abstraction will be continually raised i.e. from individual transistors to gates to logic circuits to even larger abstractions

21. what should you keep in mind during your study and practice of computing? hardware and software are component parts of a computing system that work best when they are designed by people who take into account the capabilities and limitations of both

22. what allows engineers to be able to work on computing systems whilst ignoring the other side i.e. software people ignoring the hardware it runs on, and hardware people ignoring the software that will run on it? abstraction

23. why is being clueless about the underlying layers not advisable? because you will not be able to take advantage of the nuances of underlying layers when it is important to be able to do so

24. what do the authors suggest about the your study and practice of computing? that hardware and software are names for components of two parts of a computing system that work best when they are designed by people who take into account the capabilities and limitations of both

25. what path will the book set you on? the path to mastery of computer hardware and computer software which will make you more capable as a software engineer i.e. you will be able to come up with better solutions to computing problems when you have the capability of both at your finger tips

26. what is the definition of a computer? system consisting of software that directs and specifies the processing of information and the hardware that performs the actual processing of information in response to what the software specifies

27. what piece of hardware actually does the processing in a computer? CPU

28. when did the first computers show their face on planet earth? 1940s

29. what was the name of one the the first computers? ENIAC

30. what is marked about the computing devices of today and those of yesteryear? the weights have decreased tremendously, so has the power consumption all the whilst the computing power has increased by many orders of magnitude

31. If you want to see a picture of the ENIAC see figure1.1 (17,000 vacuum tubes, 2.4 metres high, 30 metres wide, 30 tons weight, 140kw to operate)

32. 40 years later (in the 1980s) and many computing companies later, the burroughs A series was created. you can see a picture of it in figure 1.2 (one of the dozen or so boards 18 inch boards that comprised the machine). each board contained 50 or more integrated circuit packages. weighed about 1 ton, and required approximately 25 kw to operate 

33. fast forward to today and the relative weights and power consumption of computing devices has decreased massively. the speed at which they process information has also increased enormously. they estimate that the computing power in a smartphone today is more than 4 million times the computing power of the ENIAC

34. what has brought about this increase in computational power? integrated circuit packages have seen phenomenal improvement e.g first  intel microprocessor in 1971 (intel 4004) contained 2300 transistors and operated at 106 KHz; one of the latest intel microprocessors Core i9-13900K contains a reported 25.9 billion transistors and and can operate at a frequency of 5.8 GHz. this factor of one million since 1971 in both the number of transistors and the frequency of microprocessors has had important implications

35. what are these implications? the fact that each operation can be performed in one millionth of the time it took in 1971 means that the processor can do one million things today in the time it took to do one thing in 1971. the fact that there are more than a million times as many transistors on a chip means we can do a lot more things at the same time today than we could do in 1971

36. what does this result in? we have computers today that seem able to understand languages people speak, recognise peoples faces which many see as the magic of artificial intelligence. however, these magical feats are are really due to fact that electronic idiots are able to run simple operations blazingly fast concurrently 

37. figure 1.6 shows a modern day microprocessor 

38. what two core ideas are presented at the end of the first chapter of the book? (a) all computers (fastest, slowest, cheapest, most expensive) are capable of computing exactly the same things if they are given enough time and memory (b) problems are expressed in human language but are solved by electrons moving due to voltage potentials inside the computer. this means a series of systematic transformations have to be made to convert a problem expressed in a human language in order for the electrons to do our bidding inside a computer

39. what has happened to these sequence of transformations over the last 70 years? they have been developed, refined and improved 

40. Before modern computers there were many kind of calculating machines. Give an example? analog machines 

41. how do analogue machines work? produce an answer by measuring some physical quantity such as distance or voltage

42. why are analogue machines difficult to work with? it is very hard to increase their accuracy 

43. why did digital machines (machines that perform computations by manipulating a fixed finite set of digits or letters) come to dominate computing by ? it is easy to increase their accuracy

44. what limitations did digital machines of yesteryear (adding machines or abacus) have? the mechanical or electro-mechanical devices could only perform a specific type of computation

45. why are computers referred to as universal computation devices? when you think of a new computation, you do not have to buy or design a new computer, you just give the same computer a new set of instructions to carry out the new computation

46. what does the study of computing involve? study the fundamentals of all computing along with learning what computation is and what can be computed

47. who is attributed with the idea of a universal computation device?

48. what did alan turing propose? that all computations could be carried out by a particular kind of machine - a turing machine. he gave a mathematical description of the machine but never built one

49. what was he more interested in? defining computation

50. Figure 1.7 shows what we call “black box” models of Turing machines that add and multiply. In each case, the operation to be performed is described in the box. The data elements on which to operate are shown as inputs to the box. The result of the operation is shown as output from the box. A black box model provides no information as to exactly how the operation is performed

51. what did turing propose? that every computation can be performed by some Turing machine. We call this Turing’s thesis. Although Turing’s thesis has never been proved, there does exist a lot of evidence to suggest it is true. 

52. what argument did he give to support his thesis? that one way to try to construct a machine more powerful than any particular 
turing machine was to make a machine U that could simulate all turing machines. you would simply describe to U the particular turing machine you wanted it to simulate, give U the input data, and U would compute the appropriate output. Turing then showed that there was, in fact, a Turing machine that could do this

53. what do computers and turing machines have in common? they are programmable hence can compute anything that can be computed

54. what implication do the immediately above points have? big or expensive computers cannot do anything that a small cheap computer can't; more money will buy you a faster computer but if you have a small inexpensive laptop then you already have a universal computation device

55. how do we get the electrons to do our bidding inside of a computer? work through the levels of transformation for a particular problem see figure 1.9

56. what is the first level of transformation? describe a problem in a natural language whilst avoiding ambiguity because the electronic idiot would not know what to do

57. what is the second level of transformation? convert the problem expressed in natural language into an algorithm thereby getting rid of the ambiguity inherent in natural language. an algorithm is a step by step procedure that is guaranteed to terminate

58. what are the three characteristics of an algorithm? finiteness (guaranteed to terminate), definteness (each step is precisely stated), and effective computability (can be carried out by a computer)

59. For every problem there are usually many diﬀerent algorithms for solving that problem. One algorithm may require the fewest steps. Another algorithm may allow some steps to be performed concurrently. A computer that allows more than one thing to be done at a time can often solve the problem in less time, even though it is likely that the total number of steps to be performed has increased.

60. what is the 3rd level of transformation? transform the algorithm into source code using a chosen programming language. programming languages are mechanical languages (lacking the ambiguity of natural languages) that were invented to specify instructions to a computer

61. what are the two kinds of programming language that exist? high level and low level

62. Give a definition for a high level language? independent of the computer from which they will execute on i.e. they are machine 
independent

63. give a definition for a low level langauge? tied to the computer on which the programs will execute i.e. assembly language

64. what is the fourth level of transformation? translating the source code into the ISA of the computer that will be used to
execute the program.

65. what does ISA specify? the interface between the source code and the hardware of the machine that will be used to execute the program

66. with regards to ISA, use the automobile and driver analogy to help better understand the concept? the human driver of a car represents the computer program represented as 0's and 1's in the computer; the car corresponds to the microprocessor hardware. the ISA of the automobile is the specification of everything the human needs to know in order to get the car to move and everything the car needs to know to carry out the tasks specified by the human driver

67. what do opcode and operand mean in relation to ISA of a computer? opcode refers to and operation the computer can perform whilst operand is an individual data value

68. ISA specifies the acceptable representations for operands, what are the operands called? data types (is a representation of an operand such that the computer can perform operations on that representation)

69. ISA specifies the mechanisms that the computer can use to figure out where operands are located. what are these mechanisms called? addressing modes

70. are the number of opcodes, operands and addressing modes unique to each ISA? yes

71. name a few ISAs in use today? x86 by intel (currently also developed by AMD an other companies), SPARC oracle, power (IBM), arm and thumb (ARM)

72. what is the name of the program that is used to translate source code into the ISA of the machine that will be responsible for 
executing it? compiler

73. what is the name of the program that translates assembly language of a computer to its ISA? assembler

74. what is the 5th level of transformation? the implementation of the ISA referred to as its micro-architecture which is about what goes on underneath the hood

75. using the automobile analogy from earlier where the automobile ISA describes what the driver needs to know as he/she sits inside
the automobile to make the automobile carry out the driver's wishes, how can you use it to describe the microarchitecture that implements the ISA? since microarchitecture is about what goes on underneath the hood, here all automobile models can be different depending on the cost  and performance tradeoffs made by the designer of the car

76. previously you were introduced to a number of ISAs (x86 intel, powerpc IBM and motorola, thumb arm), what can you say about the implementation of these ISAs? each has been implemented by many different microarchitectures e.g. x86 original implementation was in 1979 was the 8086 followed by 80286, 80386 amongst others in the 1980s. more recently in 2015, intel introduced skylake. each of these x86 microprocessors has its own microarchitecture

77. Each microarchitecture is an opportunity for computer designers to make different tradeoﬀs between the cost of the microprocessor, the performance that the microprocessor will provide, and the energy that is required to power the micro- processor. Computer design is always an exercise in tradeoﬀs, as the designer opts for higher (or lower) performance, more (or less) energy required, at greater (or lesser) cost.

78. what is the 6th level of transformation? logic circuits i.e. implement each component of the microarchitecture out of simple logic circuits

79. are there choices to be made in the 6th level? yes, the logic designer decides how to best make the tradeoffs between cost and performance so for example even for operation as simple as addition, there are several choices of logic circuits to perform the operation at differing speeds and energy costs.

80. what is 7th level of transformation? each logic circuits is implemented in accordance with the requirements of the particular  device technologies used e.g. CMOS circuits, NMOS circuits, and gallium arsenide circuits all differ from each other

81. what else does ISA specify (apart from opcodes, operands, and addressing modes)? number of unique locations that comprise the computers memory (address space) and the number of bits contained in each location (addressability)

82. At each level of transformation, there are choices as to how to proceed. Our handling of those choices determines the resulting cost and performance of our computer. this book describe each of these transformations. We show how tran- sistors combine to form logic circuits, how logic circuits combine to form the microarchitecture, and how the microarchitecture implements a particular ISA.
In our case, the ISA is the LC-3. We complete the process by going from the English-language description of a problem to a C or C++ program that solves the problem, and we show how that C or C++ program is translated (i.e., compiled) to the ISA of the LC-3.


chapter 2

1. how is a computer organised? as a system with several levels of transformation i.e. a problem stated in a natural language is
actually solved by electrons moving around inside the components of a computer

2. what do you call the tiny little devices inside computer that control the movement of said electrons by reacting to the presence or absence of voltages in electronic circuits?

3. could these tiny devices be designed to detect actual value of voltages instead of the presence or absence of them? yes

4. why is this not done? it would make the control and detection circuits more complex than they need to be; it is much easier to
detect whether or not a voltage exists at a point in a circuit than it is to measure exactly what that voltage is

5. how do we symbollicaly represent the presence of a voltage? 1

6. how do we symbollically represent the absence of a voltage? 0

7. what word is used to refer to each 0 and each 1? bit which is a shortened form binary digit

8. is it the case that computers differentiate the absolute presence of a voltage (i.e. 1) from the absolute absence of a voltage
(i.e. 0)? no, electronic circuits in the computer differentiate voltages very close to 0 from voltages very far from 0

9. how many things can we differentiate with one wire and what values are assigned to them? two things; one of them can be assigned
the value 0 and the other can be assigned a value of 1

10. in order to get useful work done by a computer, it is necessary to be able to distinguish a large number of distinct values and assign each of them a unique representation. what is done in order to achieve this? combining many wires, that is, many bits. for
example, if we use eight bits (corresponding to the voltage present on each of eight wires), we can represent one particular value as 01001110, and another value as 11100111. In fact, if we are limited to eight bits, we can differentiate at most only 256 (i.e.
2^8) different things 

11. what qualifies a representation of information as a data type? if there are operations in the computer that can operate on information encoded in that representation

12. Each instruction set architecture (ISA) has its own set of data types and its own set of instructions that can operate on those data types. 

13. what data types will be used in the book? 2’s complement integers for representing positive and negative integers that we wish to perform arithmetic on, and ASCII codes for representing characters that we wish to input to a computer via the keyboard or output from the computer via a monitor. 

14. describe the unsigned integer representation?

15. describe the signed integer number representation (how many bits are assigned to positive numbers and how many bits to negative 
numbers)? each takes half the amount of bits available

16. how do signed magnitude, 1's complement, and 2's complement encode information? see figure 2.1

17. The ﬁrst thought that usually comes to mind is: If a leading 0 signiﬁes a positive integer, how about letting a leading 1 signify a negative integer? The result is the signed-magnitude data type. A second thought (which was actually used on some early computers such as the Control Data Corpora- tion 6600) was the following: Let a negative number be represented by taking the representation of the positive number having the same magnitude, and “ﬂipping” all the bits. That is, if the original representation had a 0, replace it with a 1; if it originally had a 1, replace it with a 0. This data type is referred to in the computer engineering community as 1’s complement 

18. can a computer designer assign any bit pattern he wants to represent any integer he wants? yes

19. why would this not be a good idea? it would complicate matters when they try to build electronic circuits capable of adding the numbers. In fact, the signed-magnitude and 1’s complement data types both require unnecessarily cumbersome hardware to do addition. 

20. how are negative integers represented in 2's complement encoding? choice of representations for the negative integers is based on the wish to keep the logic circuits as simple as possible. all computers use the same basic mechanism to perform addition. It is called an arithmetic and logic unit, usually known by its acronym ALU. It performs addition by adding the binary bit patterns at its inputs, producing a bit pattern at its output that is the sum of the two input bit patterns. What is particularly relevant is that the binary ALU does not know (and does not care) what the two patterns it is adding represent. the 2’s complement data type speciﬁes the representation for each negative integer so that when the ALU adds it to the representation of the positive integer of the same magnitude, the result will be the representation for 0. Moreover, and actually more importantly, as we sequence through representations of say −15 to +15 (as seen in figure 2.1), the ALU is adding 00001 to each successive representation. using this system, any carries are always ignored

21. almost all computers use the same mechanism to perform addition, what is it called? ALU

22. if you know the bit representation of integer A, what is a short cut you can use to work out -A? flip all of the bits and add 1
see example21.png 

23. algorithm for binary to decimal conversion see binaryToDecimal.png example22.png

24. algorith for the conversion of decimal to binary see decimalToBinary

25. algorithm to convert fractional binary to fractional decimal see binaryFractionToDecimal.png 

26. operations on bits: addition and subtraction see example23 example24 example25

27. why is sign extension used? in order to be able to operate on representations of different lengths

28. what happens if the sum of two integers is not small enough to be represented by the available bits? overflow of the msb occurs

29. what must you watch out for when dealing with overflow in signed encoding e.g. 2's complement? addition of positive numbers that
result in overflow into msb which indicate the sign of the value. since the result is negative, this is easy to detect. likewise when adding two negative numbers and the msb overflows and becomes zero, detection would be easy since the result of the ALU operation would positive

30. what are the basic logical operations performed by the ALU? binary logical AND function that requires two source operands see example26 and example27, binary logical OR function that aalso requires two source operands see example28, unary logical function NOT which operates on only one source operand (also known as the complement operation), the binary logical XOR function that requires two source operands see example29 and example210

31. what do you call an m-bit pattern where each bit has a logical value (0 or 1) independent of the other bits? a bit vector. It is a convenient mechanism for identifying a property such that some of the bits identify the presence of the property and other bits identify the absence of the property.

32. There are many uses for bit vectors. The most common use is a bit mask. The bit mask is a bit vector, where our choice of 0 or 1 for each bit allows us to isolate the bits we are interested in focusing on and ignore the bits that don’t matter. Another common use of bit vectors involves managing a complex system made up of several units, each of which is individually and independently either busy or available. The system could be a manufacturing plant where each unit is a particular machine. Or the system could be a taxicab network where each unit is a particular taxicab. In both cases, it is important to identify which units are busy and which are available so that work can be properly assigned. Say we have m such units. We can keep track of these m units with a bit vector, where a bit is 1 if the unit is free and 0 if the unit is busy. see example211

33. There are many other representations of information that are used in computers. can you name two that are among the most useful?
ASCII and floating point representation

34. what encoding format does the lc-3 use to represent integers? 16 bit 2's complement where the msb (most significant bit) identifies whether the number is positive or negative and the rest of the bits represent the magnitude of the value. with 16 bits used this way, we can express integer values between -32768 and 32767, that is between -2^(15) and (2^15) - 1.

35. what do we say about the precision of the value and its range? precision of the value is 15 bits and the range is 2^(16)

36. what if you need to represent fractional decimals (such as avogadros constant) inside of a computer? can you do it with the 16 bit 2's complement encoding format used to represent integers? no, because the range of avogadros constant 10^(23) is far too great to be expressed in the range available 2^(15) - 1. on the other hand, the 15 bits of precision is overkill for expressing the four significant decimal digits (6022) 

37. what data type can solve this problem? floating point data type

38. how does it solve this problem? instead of using most of the bits to represent the precision of a value, the floating point data type allocates some of the bits to the range of values that can be expressed. the rest of the bits (except for the sign bit) are used for precision

39. most ISA's today specify more than one floating point data type; float and double

40. how many bits does the float data type have? 32 bits

41. how are the 32 bits of the float data apportioned? 1 bit (the msb) for the sign (positive or negative), 8 bits for the range (exponent), 23 bits for the precision (the fraction field) see figure23

42. what types of numbers are represented by floating data type? numbers expressed in scientific notation as follows

N = (-1)^S x 1.fraction x 2^(exponent-127), where the exponent is greater than or equal to 1 and less than or equal to 254

here S, fraction, and exponent are the binary numbers in the fields of figure 2.3

43. what form is the equation noted in point 42 in? normalised form

44. why is the equation referred to as being in normalised form? because the data represents a floating point number only if the 8 bit exponent is restricted to 254 unsigned integer values, 1 (00000001) through 254 (11111110)

45. how many values can be represented uniquely with 8 bits? 256 values

46. which two integer values does the exponent not represent normalised values? 00000000 and 11111111

47. what values does the sign bit take? it is a single binary digit; 0 for positive numbers and 1 for negative numbers. it evaluates to +1 if S=0 and -1 if S=1

48. what do the 23 fraction bits form a part of in normalised form? a 24 bit quantity represnted by 1.fraction as the normalised form demands exactly one none zero binary digit to the left of the binary point. this one non zero bit does not need to be explicitly stored in the 32 bit floating point format. This is infact how we get 24 bits of precision

49. how are the 8 exponent bits (the range) in the format? in excess code

50. why is it referred to as an excess code? because one can get the *real* exponent by treating the code as an unsigned integer and subtracting the bias/excess 

51. what is the range of the exponent field in normalised form? exponent ﬁeld gives us numbers as large as 2^(127) for an exponent field containing 254 and as small as 2^(-126) for an exponent ﬁeld containing 1. see example212, example213, example214

52. what numbers are represented by the floating point data type when the exponent contains all 1's i.e. 11111111? the notion of infinity

53. what must the fractional field contain when infinity is being represented? all zeros

54. how are positive infinity and negative infinity distinguished? positive infinity is distinguished by the sign bit being 0 and negative infinity is distinguished by the sign bit being set to 1

55. what is the smallest number that can be represented in normalised form? 1.00000000000000000000000 × 2^(-126)

56. what are subnormal numbers? numbers smaller than 2^(-126) but larger than 0. they are given this name because they cannot be represented in normalised form.

57. what is the largest subnormal number? 0.11111111111111111111111 × 2^(-126)

58. what is the smallest subnormal number? 0.00000000000000000000001 × 2^(-126)

59. what equation is used to represent subnormal numbers? (-1)^S x 0.fraction x 2^(-126)

60. how is the exponent field represented for subnormal numbers? 00000000. see example215

61. why are subnormal numbers used? allows very, very tiny numbers to be represented

62. wht are ASCII codes used for? transferring characters between main computer processing unit and the input and output devices

63. how many bits is the ASCII code made up of? 8 bits

64. how does ascii work? Each key on the keyboard is identiﬁed by its unique ASCII code. When you type a key on the keyboard, the corresponding eight-bit code is stored and made available to the computer (PC?). Most keys are associated with more than one code. For example, the ASCII code for the letter E is 01000101, and the ASCII code for the letter e is 01100101.


chapter 3

1. what are most computer processors today constructed out of? out of MOS transistors

2. what does MOS stand for? metal oxide semiconductor

3. what are the two type of MOS transistors? p-type and n-type

4. how many terminals does a transistor have? 3

5. what are they called? gate, source, and drain see figure32

6. how do n type transistors work? when the gate is supplied with 1.2v, the transistor acts like a piece of wire (short circuit); when supplied with 0 volts it acts like an open wire (open circuit) see figure32

7. what of the p type transistor - how does it work? When the gate is supplied with 0 volts, the P-type transistor acts (more or less) like a piece of wire, closing the circuit. When the gate is supplied with 1.2 volts, the P-type transistor acts like an open circuit. see figure33

8. because the p-type and n-type transistors work in a complimentary manner, what do we refer to circuits that contain both of them? CMOS circuits

9. what is the next step up from logic elements? logic gate ie transistor circuits (comprising of a combination of the logic elements) that implement the logical values of AND, OR, NOT

10. how is the NOT gate (inverter) constructed? from two MOS transistors; n-type and p-type see figure34

11. how does the inverter work? when supplied with 0 volts, P-type transistor acts like a short circuit and the N-type transistor acts like an open circuit. The output is, therefore, connected to 1.2 volts. On the other hand, if the input is supplied with 1.2 volts, the P-type transistor acts like an open circuit, but the N-type transistor acts like a short circuit. The output in this case is connected to ground (i.e., 0 volts). 

12. how is the NOR contructed? made out of 2 p-type and 2 n-type transistors see figure35

13. how does the NOR gate work? if A is supplied with 0 volts and B is supplied with 1.2 volts. In this case, the lower of the two P-type transistors produces an open circuit, and the output C is disconnected from the 1.2-volt power supply. However, the leftmost N-type transistor acts like a piece of wire, connecting the output C to 0 volts.

Note that if both A and B are supplied with 0 volts, the two P-type transistors conduct, and the output C is connected to 1.2 volts. Note further that there is no ambiguity here, since both N-type transistors act as open circuits, and so C is disconnected from ground.

If either A or B is supplied with 1.2 volts, the corresponding P-type transistor results in an open circuit. That is suﬃcient to break the connection from C to the 1.2-volt source. However, 1.2 volts supplied to the gate of one of the N-type transistors is suﬃcient to cause that transistor to conduct, resulting in C being connected to ground (i.e., 0 volts).

14. how is the OR gate constructed? made out of 2 p-type and 2 n-type transistors (similar to NOR gate) but augmented by adding an inverter at its output, as shown in Figure 3.6a

15. how is the AND gate contructed? made out of 2 p-type and 2 n-type transistors along with an inverter see figure38

16. how does it work? if either A or B is supplied with 0 volts, there is a direct connection from C to the 1.2-volt power supply. The fact that C is at 1.2 volts means the N-type transistor whose gate is connected to C provides a path from D to ground. Therefore, if either A or B is supplied with 0 volts, the output D of the circuit of Figure 3.8 is 0 volts.

On the other hand, if both A and B are supplied with 1.2 volts, then both of their corresponding P-type transistors are open. However, their corresponding N-type transistors act like pieces of wire, providing a direct connection from C to ground. Because C is at ground, the rightmost P-type transistor acts like a closed circuit, forcing D to 1.2 volts.

17. The gates just discussed are very common in digital logic circuits and in digital computers. There are billions of inverters (NOT gates) in Intel’s Skylake microprocessor. As a convenience, we can represent each of these gates by stan- dard symbols, as shown in Figure 3.9. The bubble shown in the inverter, NAND, and NOR gates signiﬁes the complement (i.e., NOT) function.

18. Gates with More Than Two Inputs: the notion of AND, OR, NAND, and NOR gates extends to larger numbers of inputs. One could build a three-input AND gate or a four-input OR gate, for example. An n-input AND gate has an output value of 1 only if ALL n input variables have values of 1. If anyofthen inputs has a value of 0, the output of the n-input AND gate is 0. An n-input OR gate has an output value of 1 if ANY of the n input variables has a value of 1. That is, an n-input OR gate has an output value of 0 only if ALL n input variables have values of 0. see figure310

19. Now that we understand the workings of the basic logic gates, what is the next step? build some of the logic structures that are important components of the microarchitecture of a computer.

20. there are two types of logic structures, what are they called and what do? those that include storage of information and those that do not. those that do not store information are called decision elements or combinational logic structures. those that store information and make decisions as well are called sequential logic circuits

21. why are combinational logic structures called so? because their outputs are strictly dependent on the combination of input values that are being applied to the structure right now. Their outputs are not at all dependent on any past history of information that is stored internally, since no information can be stored internally in a combinational logic circuit.

22. name three decision elements? decoder, mux (multiplexer), full adder 

23. how does the decoder work? has the property that exactly one of its outputs is 1 and all the rest are 0s. The one output that is logically 1 is the output corresponding to the input pattern that it is expected to detect. In general, decoders have n inputs and 2^n outputs. We say the output line that detects the input pattern is asserted. That is, that output line has the value 1, rather than 0 as is the case for all the other output lines. see figure311. The decoder is useful in determining how to interpret a bit pattern. 

24. how does the mux work? multiplexer, more commonly referred to as a mux is used to select one of the inputs (A or B) and connect it to the output. The select signal (S in Figure 3.12) determines which input is connected to the output.

The mux of Figure 3.12 works as follows: Suppose S  =  0, as shown in Figure 3.12b. Since the output of an AND gate is 0 unless all inputs are 1, the out- put of the rightmost AND gate is 0. Also, the output of the leftmost AND gate is whatever the input A is. That is, if A = 0, then the output of the leftmost AND gate is 0, and if A = 1, then the output of the leftmost AND gate is 1. Since the output of the rightmost AND gate is 0, it has no eﬀect on the OR gate. Consequently, the output at C is exactly the same as the output of the leftmost AND gate. The net result of all this is that if S = 0, the output C is identical to the input A.

On the other hand, if S = 1, it is B that is ANDed with 1, resulting in the output of the OR gate having the value of B. We say S selects the source of the mux (either A or B) to be routed through to the output C. In general, a mux consists of 2^n  inputs and n select lines. see figure313

25. how does the One-Bit Adder (a.k.a. a Full Adder) work? Figure 3.14 is a truth table that describes the result of binary addition on one column of bits within two n-bit operands. At each column, there are three values that must be added: one bit from each of the two operands A and B and the carry from the previous column. Note that if only one of the three bits equals 1, we get a sum of 1, and no carry (i.e., Ci+1 = 0). If two of the three bits equal 1, we get a sum of 0, and a carry of 1. If all three bits equal 1, the sum is 3, which in binary corresponds to a sum of 1 and a carry of 1.

Figure 3.15 shows a logic gate implementation of a one-bit adder. Note that each AND gate in Figure 3.15 produces an output 1 for exactly one of the eight input combinations. The output of the OR gate for Ci+1 must be 1 in exactly those cases where the corresponding input combinations in Figure 3.14 produce an output 1. Therefore, the inputs to the OR gate that generates Ci+1 are the outputs of the AND gates corresponding to those input combinations. Similarly, the inputs to the OR gate that generates Si are the outputs of the AND gates corresponding to the input combinations that require an output 1 for Si in the truth table of Figure 3.14. Note that since the input combination 000 does not result in an output 1 for either Ci+1 or Si, its corresponding AND gate is not an input to either of the two OR gates.

26. what does Figure 3.16 show? a circuit for adding two 4-bit binary numbers, using four of the one-bit adder circuits of Figure 3.15. Note that the carry out of column i is an input to the addition performed in column i + 1. 

27. if you wish to implement a logic circuit for adding two 16 bit numbers, how many one bit adders will you require? 16 one bit adders

28. describe the half adder? Note that the carry into the rightmost column in Figure 3.16 is 0. That is, in the rightmost circuit, S0 and C1 depend only on two inputs, A and B . Since that circuit depends on only two inputs, it has been referred to as a half adder. Since the other circuits depend on all three inputs, they are referred to as full adders. 

29. what is the name of the building block that is used to implement any collection of logic functions? a programmable logic array (PLA)

30. what does the PLA consist of? an array of AND gates (called an AND array) followed by an array of OR gates (called an OR array). The number of AND gates corresponds to the number of input combinations (rows) in the truth table. For n-input logic functions, we need a PLA with 2^n n-input AND gates. In Figure 3.17, we have 2^3 three-input AND gates, corresponding to three logical input variables. 

31. what does the number of OR gates correspond to in the PLA? the number of logic functions that we wish to implement i.e. the number of output columns in the truth table. The implementation algorithm is simply to connect the output of an AND gate to the input of an OR gate if the corresponding row of the truth table produces an output 1 for that output column. Hence the notion of programmable.

Figure 3.15 shows seven AND gates connected to two OR gates since our requirement was to implement two functions (sum and carry) of three input variables. Figure 3.17 shows a PLA that can implement any four functions of three variables by appropriately connecting AND gate outputs to OR gate inputs. That is, any function of three variables can be implemented by connecting the outputs of all AND gates corresponding to input combinations for which the output is 1 to inputs of one of the OR gates. Thus, we could implement the one-bit adder by programming the two OR gates in Figure 3.17 whose outputs are W and X by connecting or not connecting the outputs of the AND gates to the inputs of those two OR gates as speciﬁed by the two output columns of Figure 3.14.

32. describe the concept of logical completeness: set of gates {AND, OR, and NOT} (provided by the PLA) is logically complete because a barrel of AND gates, a barrel of OR gates, and a barrel of NOT gates are suﬃcient to build a logic circuit that carries out the speciﬁcation of any desired truth table. 

33. name 2 logic structures that do include the storage information? R-S latch and gated D latch

34. how does the R-S latch work? stores 1 bit of information, a 0 or a 1. can be implemented in many ways simplest one is shown in figure318 where two 2-input NAND gates are connected such that the output of each is connected to one of the inputs of the other; inputs S and R are normally held at a logic level 1.

35. where does the RS latch get its name? because setting the latch to store a 1 was referred to as setting the latch, and setting the latch to store a 0 was referred to as resetting the latch. Ergo, R-S

36. what is meant when we state that the R-S latch is in a quiescent state? when the latch is storing a value, either 0 or 1, and nothing is trying to change that value. 

37. what contributes to this quiescent state? the fact that both R and S are held at a logic level of 1

38. what letter in figure318 designates the value that is currently stored in the latch? letter a; also referred to as the output of the latch.

39. Consider ﬁrst the case where the value stored and therefore the output a is 1. Since that means the value A is 1 (and since we know the input R is 1 because we are in the quiescent state), the NAND gate’s output b must be 0. That, in turn, means B must be 0, which results in the output a equal to 1. As long as the inputs S and R remain 1, the state of the circuit will not change. That is, the R-S latch will continue to store the value 1 (the value of the output a).

40. If, on the other hand, we assume the output a is 0, then A must be 0, and the output b must be 1. That, in turn, results in B equal to 1, and combined with the input S equal to 1 (again due to quiescence), results in the output a equal to 0. Again, as long as the inputs S and R remain 1, the state of the circuit will not change. In this case, we say the R-S latch stores the value 0.

41. how can you set the latch to a 1 or a 0? you an set the latch to a 1 by temporarily setting s to 0 and having R remain at logic level 1; the latch can be set to 0 by temporarily setting R to 0 and having S remain at logic level 1

42. in order for the R-S latch to work properly, what must be done to R and S? must never be set to 0 at the same time

43. If we set S to 0 for a very brief period of time, this causes a to equal 1, which in turn causes A to equal 1. Since R is also 1, the output at b must be 0. This causes B to be 0, which in turn makes a equal to 1. If, after that very brief period of time, we now return S to 1, it does not aﬀect a. Why? Answer: Since B is also 0, and since only one input 0 to a NAND gate is enough to guarantee that the output of the NAND gate is 1, the latch will continue to store a 1 long after S returns to 1.

44. what can you do to clear the latch? we can clear the latch (set the latch to 0) by setting R to 0 for a very short period of time.

45. what happens if both S and R are set to 0 at the same time? outputs a and b would both be 1 and the final state of the latch would depend on the electrical properties of the transistors making up the gates and not on the logic being performed.

46. we should note that when a digital circuit is powered on, the latch can be in either of its two states, 0 or 1. It does not matter which state since we never use that information until after we have set it to 1 or 0.

47. how is the gated d latch implemented? It consists of the R-S latch of Figure 3.18, plus two additional NAND gates that allow the latch to be set to the value of D, but only when WE is asserted (i.e., when WE equals 1). WE stands for write enable. see figure319

48. what happens when WE is not asserted (i.e., when WE equals 0)? the outputs of S and R are both equal to a 1. Since S and R are inputs to the R-S latch, if they are kept at 1, the value stored in the latch remains unchanged

49. what happens when WE is momentarily set to 1? exactly one of the outputs S or R is set to 0, depending on the value of D.IfD equals 1, then S is set to 0. If D equals 0, then both inputs to the lower NAND gate are 1, resulting in R being set to 0. As we saw earlier, if S is set to 0, the R-S latch is set to 1. If R is set to 0, the R-S latch is set to 0. Thus, the R-S latch is set to 1 or 0 according to whether D is 1 or 0. When WE returns to 0, S and R return to 1, and the value stored in the R-S latch persists.

50. what is memory made up of? a (usually large) number of locations, each uniquely identiﬁable and each having the ability to store a value. 

51. what do we call the unique identiﬁer associated with each memory location? address

52. what name do we give to the number of bits of information stored in each location? addressability

53. what do we call the total number of uniquely identiﬁable memory locations? address space

54. what do we mean by stating that a computing device has a 2GB memory? colloquially we say the computing device has 2 billion memory locations, however, the address space is actually 1024x1024x1024x2 which yields 2,147,483,648 locations

55. why 1024? because 1024 bytes make a kb and 1024 kb make a mb and 1024 mb make a GB

56. Actually, the number two billion is only an approximation, due to the way we specify memory locations. Since everything else in the computer is represented by sequences of 0s and 1s, it should not be surprising that memory locations are identiﬁed by binary addresses as well. With n bits of address, we can uniquely identify 2^n locations. Ten bits provide 1024 locations, which is approximately 1000. If we have 20 bits to represent each address, we have 2^(20) uniquely identiﬁable locations, which is approximately one million. With 30 bits, we have 2^(30) locations, which is approximately one billion. In the same way we use the preﬁxes “kilo” to represent 2^(10) (approximately 1000) and “mega” to represent 2^(20) (approximately one million), we use the preﬁx “giga” to represent 2^(30) (approximately one billion). Thus, 2 giga really corresponds to the number of uniquely iden- tiﬁable locations that can be speciﬁed with 31 address bits. We say the address space is 2^(31), which is exactly 2,147,483,648 locations, rather than 2,000,000,000, although we colloquially refer to it as two billion. 

57. A 2-gigabyte memory (written 2GB) is a memory consisting of 2,147,483,648 memory locations, each containing one byte (i.e., eight bits) of storage. 

58. why are most memories byte-adddressable? most computers got their start processing data where one character stroke on the keyboard corresponds to one 8-bit ASCII code. If the memory is byte-addressable, then each ASCII character occupies one location in memory. Uniquely identifying each byte of memory allows individual bytes of stored information to be changed easily.

59. Many computers that have been designed speciﬁcally to perform large scientiﬁc calculations are 64-bit addressable. This is due to the fact that numbers used in scientiﬁc calculations are often represented as 64-bit ﬂoating-point quantities. Since scientiﬁc calculations are likely to use numbers that require 64 bits to represent them, it is reasonable to design a memory for such a computer that stores one such number in each uniquely identiﬁable memory location.

60. Figure 3.20 illustrates a memory of size 2^2 by 3 bits. That is, the memory has an address space of four locations and an addressability of three bits. A memory of size 2^2 requires two bits to specify the address. We describe the two-bit address as A[1:0]. A memory of addressability three stores three bits of information in each memory location. We describe the three bits of data as D[2:0]. In both cases, our notation A[high:low] and D[high:low] reﬂects the fact that we have numbered the bits of address and data from right to left, in order, starting with the rightmost bit, which is numbered 0. The notation [high:low] means a sequence of high − low + 1 bits such that “high” is the bit number of the leftmost (or high) bit number in the sequence and “low” is the bit number of the rightmost (or low) bit number in the sequence.

Accesses of memory require decoding the address bits. Note that the address decoder takes as input the address bits A[1:0] and asserts exactly one of its four outputs, corresponding to the word line being addressed. In Figure 3.20, each row of the memory corresponds to a unique three-bit word, thus the term word line. Memory can be read by applying the address A[1:0], which asserts the word line to be read. Note that each bit of the memory is ANDed with its word line and then ORed with the corresponding bits of the other words. Since only one word line can be asserted at a time, this is eﬀectively a mux with the output of the decoder providing the select function to each bit line. Thus, the appropriate word is read at D[2:0].

Figure 3.21 shows the process of reading location 3. The code for 3 is 11. The address A[1:0]=11 is decoded, and the bottom word line is asserted. Note that the three other decoder outputs are not asserted. That is, they have the value 0. The value stored in location 3 is 101. These three bits are each ANDed with their word line producing the bits 101, which are supplied to the three output OR gates. Note that all other inputs to the OR gates are 0, since they have been produced by ANDing with their unasserted word lines. The result is that D[2:0] = 101. That is, the value stored in location 3 is output by the OR gates.

Memory can be written in a similar fashion. The address speciﬁed by A[1:0] is presented to the address decoder, resulting in the correct word line being asserted. With write enable (WE) also asserted, the three bits D[2:0] can be written into the three gated latches corresponding to that word line.

61. summarise how sequential logic circuits operate? they base their decisions not only on the input values now present but also on what has happened before; they contain storage elements that allow them to keep track of prior history information (what distinguishes from combinational logic circuits) see figure322 (Note the storage elements. Note also that the output can be dependent on both the inputs now and the values stored in the storage elements. The values stored in the storage elements reﬂect the history of what has happened before)

62. what machines are sequential logic circuits used to implement? finite state machines

63. can you give two examples; one for a combination decision element and the other for a sequential logic element? combination lock and sequential locks respectively see figure323

64. define what is meant by the state of a mechanism/system? snapshot of a system with all relevant items explicitly expressed.

65. how many elements does a finite state machine consist of? 5

66. can you state all 5? a finite number of states, a finite number of external inputs, a finite number of external outputs, 
an explicit specification of all state transitions, an explicit specification of what determines each external output value

67. what does the set of states of a system represent? all possible snapshots/configurations that the system can be in. Each state transition describes what it takes to get from one state to another. 

68. A state diagram is a convenient representation of a ﬁnite state machine. see figure326. The explicit speciﬁcations of all state transitions are shown by the arrows in the state diagram. The arrowhead on each arc speciﬁes which state the system is coming from and which state it is going to. We refer to the state the system is coming from as the current state, and the state it is going to as the next state. The combination lock has eight state transitions. Associated with each transition is the input that causes the transition from the current state to the next state.

A couple of things are worth noting. First, it is usually the case that from a current state there are multiple transitions to next states. The state transition that occurs depends on both the current state and the value of the external input. In short, the next state is determined by the combination of the current state and the current external input.

The output values of a system can also be determined by the combination of the current state and the value of the current external input. However, as is the case for the combination lock, where states A, B, and C specify the lock is “locked,” and state D speciﬁes the lock is “unlocked,” the output can also be determined solely by the current state of the system. In all the systems we will study in this book, the output values will be speciﬁed solely by the current state of the system.

69. what is a characteristic of asynchronous finite state machines? there is nothing that synchronises when each state transition occurs; a transition from a current state to a next state in our ﬁnite state machine happened when it happened

70. are computers synchronous or aynchronous systems? synchronous because state transitions take place one after another at identical fixed units of time.

71. what is the important common characteristic shared between synchronous and asynchronous finite state machines? they carry out work, one state transition at a time, moving closer to a goal

72. what controls the behaviour of a synchronous finite state machine as it transitions from a current state to its next state after an identical fixed interval of time? a clock circuit produces a signal, called THE clock, whose value alternates between 0 volts and some specified fixed voltage. In digital logic terms, the clock is a signal whose value alternates between 0 and 1. figure328 shows the value of the clock signal as a function of time. Each of the repeated sequence of identical intervals is referred to as a clock cycle. 

73. what is meant by a laptop running at a frequency of 2GHz? it can perform 2 billion pieces of work each second since 2 GHz means 2 billion clock cycles each second 

74. how many state transitions does a synchronous finite state machine make each clock cycle? one state transition

75. In electronic circuit implementations of a synchronous ﬁnite state machine, the transition from one state to the next occurs at the start of each clock cycle.

76. A Danger Sign: Figure 3.29 shows the danger sign; it contains 5 lights labelled 1 to 5. The synchronous ﬁnite state machine will be used to control it. The purpose of the synchronous finite state machine (a.k.a. a controller) is to direct the behaviour of the system i.e. the set of lights. The controller is equipped with a switch. When the switch is in the ON position, the controller directs the lights as follows: During one unit of time, all lights will be oﬀ. In the next unit of time, lights 1 and 2 will be on. The next unit of time, lights 1, 2, 3, and 4 will be on. Then all ﬁve lights will be on. Then the sequence repeats. The lights continue to sequence through these four states as long as the switch is on. If the switch is turned oﬀ, all the lights are turned oﬀ and remain oﬀ. Figure 3.30 is a state diagram for the synchronous ﬁnite state machine that controls the lights. There are four states, one for each of the four conditions corresponding to which lights are on. Note that the outputs (whether each light is on or oﬀ) are determined by the current state of the system. If the switch is on (input  =  1), the transition from each state to the next state happens at one-second intervals, causing the lights to ﬂash in the sequence described. If the switch is turned oﬀ (input = 0), the state always transitions to state A, the “all oﬀ” state.

77. Figure 3.31 is a block diagram of the speciﬁc sequential logic circuit we need to control the lights. Several things are important to note in this ﬁgure. First, the two external inputs: the switch and the clock. The switch determines whether the ﬁnite state machine will transition through the four states or whether it will transition to state A, where all lights are oﬀ. The other input (the clock) controls the transition from state A to B, B to C, C to D, and D to A by controlling the state of the storage elements. 

78. Second, there are two storage elements for storing state information. Since there are four states, and since each storage element can store one bit of informa- tion, the four states are identiﬁed by the contents of the two storage elements: A (00), B (01), C (10), and D (11). Storage element 2 contains the high bit; storage element 1 contains the low bit.

79. Third, combinational logic circuit 1 shows that the on/oﬀ behavior of the lights is controlled by the storage elements. That is, the input to the combinational logic circuit is from the two storage elements, that is, the current state of the ﬁnite state machine.

80. Finally, combinational logic circuit 2 shows that the transition from the cur- rent state to the next state depends on the two storage elements and the switch. If the switch is on, the output of combinational logic circuit 2 depends on the state of the two storage elements.

81. Figure 3.32 shows the logic that implements combinational logic circuits 1 and 2. Two sets of outputs are required for the controller to work properly: a set of external outputs for the lights and a set of internal outputs for the inputs to the two storage elements that keep track of the state. Light 5 is controlled by the output of the AND gate labeled V, since the only time light 5 is on is when the controller is in state 11. Lights 3 and 4 are controlled by the output of the OR gate labeled X, since there are two states in which those lights are on, those labeled 10 and 11.

82. Why are lights 1 and 2 controlled by the output of the OR gate labeled W? because input to OR gate W comes from the top NAND gate whose output is 1 when the storage elements are set to 01

83. Storage element 2 should be set to 1 for the next clock cycle if the next state is 10 or 11. This is true only if the switch is on and the current state is either 01 or 10. Therefore, the output signal that will make storage element 2 be 1 in the next clock cycle is the output of the OR gate labeled Y. if you look at the diagram you should be able to deduce why

84. Why is the next state of storage element 1 controlled by the output of the OR gate labeled Z? storage element 1 should be set to 1 in the next clock cycle if the switch is on and the current state is either 00 or 10

85. In order for the danger sign controller to work, the state transitions must occur once per second when the switch is on.

86. what is the problem with having gated D latches as the storage elements? when WE is asserted (i.e. the clock signal value is 1), the the output of OR gates Y and Z would immediately change the bits stored in the two gated D latches. This would produce new input values to the three AND gates that are input to OR gates Y and Z, producing new outputs that would be applied to the inputs of the gated latches, which would in turn change the bits stored in the gated latches, which would in turn mean new inputs to the three AND gates and new outputs of OR gates Y and Z. This would happen again and again, continually changing the bits stored in the two storage elements as long as the Write Enable signal to the gated D latches was asserted. The result: We have no idea what the state of the ﬁnite state machine would be for the next clock cycle. And, even in the current clock cycle, the state of the storage elements would change so fast that the ﬁve lights would behave erratically.

87. what is the problem is the gated D latch? We want the output of OR gates Y and Z to transition to the next state at the end of the current clock cycle and allow the current state to remain unchanged until then. That is, we do not want the input to the storage elements to take eﬀect until the end of the current clock cycle. We need storage elements that allow us to read the current state throughout the current clock cycle, and not write the next state values into the storage elements until the beginning of the next clock cycle.

88. how do flip flops work? they are storage elements that allow the reading of the current state throughout the current clock cycle and not write the next state into the storage elements until the beginning of the next clock cycle. reading must be allowed throughout the current clock cycle and writing must only occur at the end of the clock cycle

89. what is a flip flop made of? two gated D latches in a master/slave relationship; the write enable signal of the master is 1 when the clock is 0, and the write enable signal of the slave is 1 when the clock is 1. see figure333

90. how do flip flops work when used as storage elements? see Figure 3.34 (timing diagram for the master/slave ﬂip-ﬂop). A timing diagram shows time passing from left to right. Note that clock cycle n starts at the time labeled 1 and ends at the time labeled 4. Clock cycle n+1 starts at the time labeled 4. at the start of each clock cycle, the output of the storage elements are the outputs of the two slave latches. These outputs (starting at time 1) are input to the AND gates, resulting in OR gates Y and Z producing the next state values for the storage elements (at time 2). The timing diagram shows the propagation delay of the combinational logic, that is, the time it takes for the combinational logic to produce outputs of OR gates Y and Z. Although OR gates Y and Z produce the Next State value sometime during half-cycle A, the write enable signal to the master latches is 0, so the next state cannot be written into the master latches.

91. what happens in half cycle b? At the start of half-cycle B (at time 3), the clock signal is 0, which means the write enable signal to the master latches is 1, and the master latches can be written. However, during the half-cycle B, the write enable to the slave latches is 0, so the slave latches cannot write the new information now stored in the master latches. At the start of clock cycle n+1 (at time 4), the write enable signal to the slave latches is 1, so the slave latches can store the next state value that was created by the combinational logic during clock cycle n. This becomes the current state for clock cycle n+1.

Since the write enable signal to the master latches is now 0, the state of the master latches cannot change. Thus, although the write enable signal to the slave latches is 1, those latches do not change because the master latches cannot change.

92. In short, the output of the slave latches contains the current state of the system for the duration of the clock cycle and produces the inputs to the six AND gates in the combinational logic circuits. Their state changes at the start of the clock cycle by storing the next state information created by the combinational logic during the previous cycle but does not change again during the clock cycle.

93. why don't they change? During half-cycle A, the master latches cannot change, so the slave latches continue to see the state information that is the current state for the new clock cycle. During half-cycle B, the slave latches cannot change because the clock signal is 0. Meanwhile, during half-cycle B, the master latches can store the next state information produced by the combinational logic, but they cannot write it into the slave latches until the start of the next clock cycle, when it becomes the state information for the next clock cycle.

94. what does the data path of a computer consist of? all of the logic structures that combine to process information in the core of the computer see Figure 3.35 you should be able to spot 5 muxes, adder (ALU with +), ALU, PC, IR, MAR, and MDR are all 16-bit registers that store 16 bits of information each, three 1-bit registers, N, Z, and P

The arrows in Figure 3.35 represent wires that transmit values from one structure to another. Most of the arrows include a cross-hatch with a number next to it. The number represents the number of wires, corresponding to the number of bits being transmitted. 

95. what is a register made of? a set of n flip flops that collectively are used to store one n-bit value. i.e. gated D latches where one bit of information can be stored in one flip flop hence a 16 bit register is composed of 16 flip flops see figure336

96. why use flip flops to make registers instead of latches? because it is usually important to be able to both read the contents of a register throughout a clock cycle and also store a new value at the end of the clock cycle

chapter 4

1. what two things do you need to get a task done by a computer? a computer that will do the work and a computer program specifying the task that needs to be achieved

2. what is a computer program comprised of? a set of instructions, each specifying a well-deﬁned piece of work for the computer to carry out. 

3. what is the name of the smallest piece of work specified in a computer program? an instruction

4. who proposed the fundamental model of computers? john von neumann

5. what are the 5 basic components of the model? memory, cpu, input, output, and control unit see figure41

6. in which of the components is the computer program contained in? memory

7. which of the components can hold the data that the program will operate on? memory or input device

8. which component controls the order in which operations are carried out? control unit

9. what does the 16GB when talking about memory refer to? the "16 giga" refers to 2^(34) memory locations and the "byte" refers to the eight bits stored in each location. the term is 16 giga because 16 is 2^(4) and giga is the term used to represent 2^(30) which is approximately one billion, 2^(4) x 2^(30) = 2^(34)

10. if you have k bits, how many unique items can you represent? 2^k

11. ergo, to uniquely identify 2^(34) memory locations, how many bits do you need? 34 bits where each location must have its own 34-bit address

12. to read the contents of a memory location, where do we place the address of that location in memory? in the memory address register (MAR) and then interrogate the computer's memory

13. where will the information stored in the address stored in MAR be placed? in the MDR register

14. what is the process of writing or storing a value in a memory location? location of the address to be written to is first stored in MAR and the data to be written is stored in the MDR register. computer memory is then interrogated with the WE signal asserted such that the information stored in MDR is written to the address stored in MAR

15. what are the two characteristics of a memory location? its address and what is stored there

16. what component carries out the processing of information in a computer? processing unit

17. what is processing unit in a computer comprised of? many sophisticated functional units each performing one particular operation (divide, square root etc) 

18. what is the name of simplest processing unit and the one thought of when discussing the von neumann model? ALU which is capable of performing basic arithmetic functions and basic logic operations 

19. what is the name given to the fixed size elements that the ALU processes? word length of the computer; the data elements are called words

20. what specifies the word length (depends on the intended use of the computer) of a computer? the ISA

21. what word length is specified by most ISAs today? 64 bits and 32 bits (though 32 bits has mostly been done away with)

22. what range of word lengths can you expect to find being processed in inexpensive processors today? 8 bits to 16 bits

23. how many bits are processed in the ALU of the lc-3? 16 bits

24. It is almost always the case that a computer provides some small amount of storage very close to the ALU to allow results to be temporarily stored if they will be needed to produce additional results in the near future. what is the most common form of aforementioned temporary storage? a set of registers

25. typically what is the size of one of these register's equal to? values being processed by the ALU i.e. a word 

26. Current microprocessors typically contain 32 registers, each consisting of 32 or 64 bits, depending on the architecture. These serve the same purpose as the eight 16-bit registers in the LC-3. 

27. what is the consequence of the importance of temporary storage for values that most modern computers will need shortly? many processors have access to an additional set of special purpose registers consisting of 128 bits to handle special needs

28. what component is used to keep track of both where we are within the process of executing a program and where we are in the process of executing an instruction? control unit

29. what mechanism does the control unit use to keep track of which instruction is being executed? the instruction register contains the instruction being executed

30. what mechanism does the control unit use to keep track of which instruction is to be executed next? program counter(instruction pointer) contains the next instructions address

31. We  constructed  Figure  4.3  by  starting  with  the  LC-3’s  full  data  path (Figure 3.35) and removing all elements that are not essential to pointing out the ﬁve basic components of the von Neumann model. Note that there are two kinds of arrowheads in Figure 4.3: ﬁlled-in and not-ﬁlled-in. Filled-in arrowheads denote data elements that ﬂow along the corresponding paths. Not-ﬁlled-in arrowheads denote control signals that control the processing of the data elements. For example, the box labeled ALU in the processing unit processes two 16-bit values and produces a 16-bit result. The two sources and the result are all data, and are designated by ﬁlled-in arrowheads. The operation performed on those two 16-bit data elements (it is labeled ALUK) is part of the control—therefore, a not-ﬁlled-in arrowhead.

32. MEMORY consists of the storage elements, along with the Memory Address Register (MAR) for addressing individual locations and the Memory Data Register (MDR) for holding the contents of a memory location on its way to/from the storage.
Note that the MAR contains 16 bits, reﬂecting the fact that the memory address space of the LC-3 is 2^(16) memory locations. The MDR contains 16 bits, reﬂecting the fact that each memory location contains 16 bits—that is, the LC-3 is 16-bit addressable.

33. INPUT/OUTPUT consists of a keyboard and a monitor. The simplest keyboard requires two registers: a keyboard data register (KBDR) for holding the ASCII codes of keys struck and a keyboard status register (KBSR) for maintaining status information about the keys struck.

34. The simplest monitor also requires two registers: a display data register (DDR) for holding the ASCII code of something to be displayed on the screen and a display status register (DSR) for maintaining associated status information. 

35. THE PROCESSING UNIT consists of a functional unit (ALU) that performs arithmetic and logic operations and eight registers (R0, … R7) for storing temporary values that will be needed in the near future as operands for subsequent instructions. The LC-3 ALU can perform one arithmetic operation (addition) and two logical operations (bitwise AND and bitwise NOT).

36. THE CONTROL UNIT consists of all the structures needed to manage the processing that is carried out by the computer. Its most important structure is the ﬁnite state machine, which directs all the activity. Processing is carried out step by step, or rather, clock cycle by clock cycle. Note the CLK input to the ﬁnite state machine in Figure 4.3. It speciﬁes how long each clock cycle lasts. The instruction register (IR) is also an input to the ﬁnite state machine since
the LC-3 instruction being processed determines what activities must be carried out. The program counter (PC) is also a part of the control unit; it keeps track of the next instruction to be executed after the current instruction ﬁnishes.

37. Note that all the external outputs of the ﬁnite state machine in Figure 4.3 have arrowheads that are not ﬁlled in. These outputs control the processing throughout the computer. For example, one of these outputs (two bits) is ALUK, which controls the operation performed in the ALU (ADD, AND, or NOT) during the current clock cycle. Another output is GateALU, which determines whether or not the output of the ALU is provided to the processor bus during the current clock cycle.

38. what is the central idea in the von neumann model of computer processing? program and data are both stored as sequences of bits in the computer's memory and the program is executed one instruction at a time under the direction of the control unit

39. what is the most basic unit of computer processing? an instruction

40. what is an instruction made up of? opcode (what the instruction does) and operand (what is does it to)

41. there are fundamentally 3 types of instructions, what are they? operates, data movement, and control, although many ISAs have some special instructions that are necessary for those ISAs.

42. what do operate instruction do? operate on data. The LC-3 has three operate instructions: one arithmetic (ADD) and two logicals (AND and NOT).

43. what do data movement instructions do? move data from processing unit to and from memory and to and from input/output devices. The LC-3 has six data movement instructions.

44. what do control instructions do? they alter the sequential processing of instructions; that is, normally the next instruction executed is the instruction contained in the next memory location.

45. for LC-3, which has 16 bits, and are numbered from left to right, bit [15] to bit [0], how are they divided? bits 15:12 contain the opcode and bits 11:0 are used to figure out where the operands are

46. how many opcodes does the LC-3 have? 15 opcodes; one is reserved for future use

47. how many operands does the ADD operate instruction have? 3 operands, two source operands (the numbers to be added) and one destination operand (where the sum is to be stored after the addition is performed)

48. what does the ADD operate require? at least one of the two source operands must be stored in one of the 8 registers; the result should also be written to one of the 8 registers

49. since the LC-3 has 8 registers, how many bits are necessry to identify each register? 3

50. how many forms does the 16-bit LC-3 ADD instruction have? 2 forms

51. what is the four bit opcode (from 15:12) for the ADD operate in LC-3? 0001

52. in the ADD instruction, what do bits 11:9 specify? the register for storing the result 

53. in the ADD instruction, what do bits 8:6 specify? the register storing one of the two source operands

54. what is the difference between the two formats of the ADD instruction? the 1 or 0 stored in bit 5 and what they each mean

55. what does the 0 stored in bit 5 in the instruction mean? that the second source operand is in the register specified by bits 2:0

56. what does the 1 stored in bit 5 in the instruction mean? the second source operand is formed by sign-extending the integer in bits [4:0] to 16 bits. see example410 and example411

57. what is the four bit opcode (from 15:12) for the AND operate in LC-3? 0101 see example42

58. what is the four bit opcode (from 15:12) for the LD operate in LC-3? 0010

59. what is load instruction used for? goes to a particular memory location, reads the value that is stored there and stores that value in one of the registers

60. how many operands does the LD instruction require and what are they? two operands; the value to be read from memory and the destination register that will contain the value after the instruction has completed processing 

61. There are many formulas that can be used for calculating the address of the memory location to be read. what is each formula called? an addressing mode.

62. what addressing mode does the LD instruction use? PC+OFFSET (computed by sign-extending the 2’s complement integer contained in bits [8:0] to 16 bits and adding it to the current contents of the program counter) see example43 

63. what system is used to control instruction processing in a step by step manner? the control unit

64. what is the entire sequence of steps needed to process an instruction called? instruction cycle

65. how many steps does the instruction cycle consist of? 6 sequential phases, each phase consisting of zero or more steps  

66. why do we say that each phase requires "zero" or more steps? we say zero steps to indicate that most computers have been designed that not all instructions require all 6 phases

67. name the six phases of the instruction life cycle? fetch, decode, evaluate address, fetch operands, execute, store result

68. what does the fetch stage involve? fetches the next instruction from memory and loads it in the IR of the control unit. Recall that a computer program consists of a number of instructions, that each instruction is represented by a sequence of bits, and that the entire program (in the von Neumann model) is stored in the computer’s memory. In order to carry out the work of an instruction, we must ﬁrst identify where it is. 

69. which structure contains the address of the next instruction to be processed? the program counter

70. what are the steps taken in the FETCH phase? First the MAR is loaded with the contents of the PC, and simultaneously  increment  the  PC; Next, the memory  is interrogated, which results in the next instruction being placed by the memory into the MDR; Finally, the IR is loaded with the contents of the MDR.

71. Each of these steps in the FETCH phase is under the direction of the control unit; how many clock cycles does each take? Step 1 takes one clock cycle. Step 2 could take one clock cycle or many clock cycles, depending on how long it takes to access the computer’s memory. Step 3 takes one clock cycle.

72. in a modern digital computer, how long is a clock cycle? a very small fraction of a second; indeed, a 3.1 GHz Intel Core i7 completes 3.1 billion clock cycles in one second. Said another way, one clock cycle takes 0.322 billionths of a second (0.322 nanoseconds).

73. what does the decode phase of the instruction life cycle do? examines an instruction to figure out what the micro architecture is being asked to do. 

74. how does the decode phase work? In the LC-3, a 4-to-16 decoder identiﬁes which of the 16 opcodes is to be processed (even though one of the 16 is not used) with the input being bits 15:12. The output line asserted is the one corresponding to the opcode at the input. Depending on which output of the decoder is asserted, the remaining 12 bits identify what else is needed to process that instruction.

75. what occurs in the evaluate address phase? computes the address of the memory location that is needed to process the instruction; not all instructions access memory to load or store data. For example, we have already seen that the ADD and AND instructions in the LC-3 obtain their source operands from registers or from the instruction itself and store the result of the ADD or AND instruction in a register. For those instructions, the EVALUATE ADDRESS phase is not needed. In contrast, the LD instruction causes a value stored in memory to be loaded into a register. The address was obtained by sign-extending bits [8:0] of the instruction to 16 bits and adding that value to the current contents of the PC. This calculation is performed during the EVALUATE ADDRESS phase. 

76. what occurs in the fetch operands phase? obtains the source operands needed to process the instruction. In the LD example, this phase took two steps: loading MAR with the address calculated in the EVALUATE ADDRESS phase and reading memory that resulted in the source operand being placed in MDR. In the ADD example, this phase consisted of obtaining the source operands from R2 and R6. In most current microprocessors, this phase (for the ADD instruction) can be done at the same time the instruction is being executed (the ﬁfth phase of the instruction cycle). Exactly how we can speed up the processing of an instruction in this way is a fascinating subject, but it is one we are forced to leave for later in your education.

77. what happens in the execute phase? carries out the execution of the instruction. 

78. what is notable about the store result phase? The result is written to its designated destination. In many computers, this action is performed during the EXECUTE phase. That is, in many computers, including the LC-3, an ADD instruction can fetch its source operands, perform the ADD in the ALU, and store the result in the destination register all in a single clock cycle. Hence a separate store result phase is not needed

79. Once the instruction cycle has been completed, the control unit begins the instruction cycle for the next instruction, starting from the top with the FETCH phase. Since the PC was updated during the previous instruction cycle, it contains at this point the address of the instruction stored in the next sequential memory location. Thus, the next sequential instruction is fetched next. Processing continues in this way until something breaks this sequential ﬂow, or the program ﬁnishes execution.

80. It is worth noting again that although the instruction cycle consists of six phases, not all instructions require all six phases. As already pointed out, the LC- 3 ADD instruction does not require a separate EVALUATE ADDRESS phase or a separate STORE RESULT phase. The LC-3 LD instruction does not require an EXECUTE phase. On the other hand, there are instructions in other ISAs that require all six phases. see example44

81. Everything we have said thus far happens when a computer program is executed in sequence. That is, the ﬁrst instruction is executed, then the second instruction is executed, followed by the third instruction, and so on.

82. so far you have come across 2 types of instructions; operate (ADD, AND) and data movement (LOAD), what is the 3rd type of instruction called? control instruction

83. what do control instructions do? they change the sequence of instruction execution

84. if you want to change the sequence of instructions executed, what must be done? the contents of the PC must change between the time it is incremented (during the FETCH phase of one instruction) and the start of the FETCH phase of the next instruction

85. at which stage do the control instructions load the PC with the new address? execute phase

86. what is the most common control instruction? conditional branching; which either changes the contents of the PC or does not change the contents of the PC, depending on the result of a previous instruction (usually the instruction that is executed immediately before the conditional branch instruction). see example450 and example451

87. what is the instruction cycle controlled by? a synchronous finite state machine; An abbreviated version of its state diagram, highlighting a few of the LC-3 instructions discussed in this chapter, is shown in Figure 4.4. Each state corresponds to one machine cycle of activity that takes one clock cycle to perform. The processing controlled by each state is described within the node representing that state. The arcs show the next state transitions.

88. Processing starts with State 1. The FETCH phase takes three clock cycles, corresponding to the three steps described earlier. In the ﬁrst clock cycle, the MAR is loaded with the contents of the PC, and the PC is incremented. In order for the contents of the PC to be loaded into the MAR (see Figure 4.3), the ﬁnite state machine must assert GatePC and LD.MAR. GatePC connects the PC to the processor bus. LD.MAR, the write enable signal of the MAR register, loads the contents of the bus into the MAR at the end of the current clock cycle. (Registers are loaded at the end of the clock cycle if the corresponding control signal is asserted.)

89. what happens in each of the 3 clock cycles of the FETCH phase? MAR <- PC and PC <- PC + 1; MDR <- MAR; IR <- MDR

90. In order for the PC to be incremented (again, see Figure 4.3), the ﬁnite state machine must assert the PCMUX select lines to choose the output of the box labeled +1 and must also assert the LD.PC signal to load the output of the PCMUX into the PC at the end of the current cycle. The ﬁnite state machine then goes to State 2. Here, the MDR is loaded with the instruction, which is read from memory.

91. In State 3, the instruction is transferred from the MDR to the instruction register (IR). This requires the ﬁnite state machine to assert GateMDR and LD.IR, which causes the IR to be loaded at the end of the clock cycle, concluding the FETCH phase of the instruction cycle.

92. The DECODE phase takes one clock cycle. In State 4, using the external input IR, and in particular the opcode bits of the instruction, the ﬁnite state machine can go to the appropriate next state for processing instructions depending on the particular opcode in IR [15:12]. Three of the 15 paths out of State 4 are shown. Processing continues clock cycle by clock cycle until the instruction completes execution, and the next state logic returns the ﬁnite state machine to State 1.

93. As has already been discussed, it is sometimes necessary not to execute the next sequential instruction but rather to access another location to ﬁnd the next instruction to execute. As we have said, instructions that change the ﬂow of instruction processing in this way are called control instructions. In the case of the conditional branch instruction (BR), at the end of its instruction cycle, the PC contains one of two addresses: either the incremented PC that was loaded in State 1 or the new address computed from sign-extending bits [8:0] of the BR instruction and adding it to the PC, which was loaded in State 63. Which address gets loaded into the PC depends on the test of the most recent result.

94. From everything we have said, it appears that the computer will continue processing instructions, carrying out the instruction cycle again and again, ad nauseum. Since the computer does not have the capacity to be bored, must this continue until someone pulls the plug and disconnects power to the computer?

95. what controls the execution of a user program in a computer? the OS

96. Operating systems are just computer programs themselves. As far as the computer is concerned, the instruction cycle continues whether a user program is being processed or the operating system is being processed. This is ﬁne as far as user programs are concerned since each user program terminates with a control instruction that changes the PC to again start processing the operating system—often to initiate the execution of another user program.

97. what can we do if we want to stop the infinite sequence of instruction cycles? stopping the clock which controls the transition from state cycle to a different state cycle

98. Figure 4.5a shows a block diagram of the clock circuit, consisting primarily of a clock generator and a RUN latch. The clock generator is a crystal oscillator, a piezoelectric device that you may have studied in your physics or chemistry class. For our purposes, the crystal oscillator is a black box that produces the oscillating voltage shown in Figure 4.5b. Every clock cycle, the voltage rises to 1.2 volts and then drops back to 0 volts.

99. If the RUN latch is in the 1 state (i.e., Q = 1), the output of the clock circuit is the same as the output of the clock generator. If the RUN latch is in the 0 state (i.e., Q = 0), the output of the clock circuit is 0. Thus, stopping the instruction cycle requires only clearing the RUN latch.

100. how do machines set this run latch to 0? in some older machines, the HALT instruction is executed; in the LC-3 the TRAP instruction (with opcode 1111 and an eight bit code called a trap vector x25) informs the OS that a program has finished executing and ergo the PC can stop executing instructions

101. What is misleading about the name program counter? The program counter does not maintain a count of any sort. 

100. Why is the name instruction pointer more insightful? The value stored in the program counter is the address of the next instruction 
to be processed. Hence the name ’Instruction Pointer’is more appropriate for it.

101. If a HALT instruction can clear the RUN latch, thereby stopping the instruction cycle, what instruction is needed to set the RUN 
latch, thereby reinitiating the instruction cycle? Once the RUN latch is cleared, the clock stops, so no instructions can be processed. 
Thus, no instruction can be used to set the RUN latch. In order to re-initiate the instruction cycle, an external input must be applied. 
This can be in the form of an interrupt signal or a front panel switch, for example.

chapter 5

1. what does the ISA specify? all the information about the computer that the sofware has to be aware of i.e. specifies everything in the computer that is available to a programmer when they write programs in the computer's own machine language. The ISA also specifies everything in the computer that is needed by someone (a compiler writer) who wishes to translate programs written in a high level language into the machine language of the computer

2. what 3 things does ISA specify? memory organisation, register set, and instruction set, including the opcodes, data types, and addressing modes of the instructions in the instruction set

3. The LC-3 memory has an address space of 2^(16) (i.e., 65,536) locations, and an addressability of 16 bits. Not all 65,536 addresses are actually used for memory locations. Since the normal unit of data that is processed in the LC-3 is 16 bits, we refer to 16 bits as one word, and we say the LC-3 is word-addressable.

4. why do computers such as the LC-3 use a set of registers? it takes more than one clock cycle to access an address in memory. registers can be accessed in one clock cycle. Each register in the set is called a general purpose register (GPR). Like memory locations, registers store information that can be operated on later. 

5. what do you call the number of bits stored in a register? a word. In the LC-3, this means 16 bits.

6. Registers must be uniquely identiﬁable. The LC-3 speciﬁes eight GPRs, each identiﬁed by a three-bit register number. They are referred to as R0, R1, … R7. Figure 5.1 shows a snapshot of the LC-3’s register set, sometimes called a register ﬁle, with the eight values 1, 3, 5, 7, −2, −4, −6, and −8 stored in R0, … R7, respectively. Figure 5.2 shows the contents of the register ﬁle of Figure 5.1 AFTER the instruction ADD  R2,  R1,  R0 is exucuted

7. what is an instruction made up of? opcode (what the instruction is asking the computer to do)
and its operands (what the computer is expected to do it to)

8. what is the instruction set defined by? by its set of opcodes, data types, and addressing modes

9. what does the addressing mode determine? where operands are located. The instruction ADD R2, R0, R1 has an opcode ADD, one addressing mode (register mode), and one data type (2’s complement integer). The instruction directs the computer to perform a 2’s complement integer addition and speci- ﬁes the locations (GPRs) where the computer is expected to ﬁnd the operands and the location (a GPR) where the computer is to write the result.

10. We saw in Chapter 4 that the ADD instruction can also have two addressing modes (register mode and immediate mode), where one of the two operands is literally contained in bits [4:0] of the instruction. Figure 5.3 lists all the instructions of the LC-3, the bit encoding [15:12] for each opcode, and the format of each instruction. 

11. how is the data type represented? as a representation of the operands in 0's and 1's or you can also say it is a representation of information such that the ISA has opcodes that operate on that representation

12. what does the memory organisation specified by an ISA entail? address space (quantity of memory locations) and addressability (amount of bits in each memory location)

13. Some ISAs have a very large number of opcodes, one for each of a very large number of tasks that a program may wish to carry out. The x86 ISA has more than 200 opcodes. Other ISAs have a very small set of opcodes. Some ISAs have specific opcodes to help with processing scientific calculations. For example, the Hewlett Packard Precision Architecture can specify the compound operation (A ⋅ B) + C with one opcode; that is, a multiply, followed by an add on three source operands A, B, and C.

14. Other ISAs have instructions that process video images obtained from the World Wide Web. The Intel x86 ISA added a number of instructions which they originally called MMX instructions because they eXtended the ISA to assist with MultiMedia applications that use the web. Still other ISAs have specific opcodes to help with handling the tasks of the operating system. For example, the VAX ISA, popular in the 1980s, used a single opcode instead of a long sequence of instructions that other computers used to save the information associated with a program that was in the middle of executing prior to switching to another program. 

15. The decision as to which instructions to include or leave out of an ISA is usually a hotly debated topic in a company when a new ISA is being specified. The LC-3 ISA has 15 instructions, each identiﬁed by its unique opcode. The opcode is speciﬁed in bits [15:12] of the instruction. Since four bits are used to specify the opcode, 16 distinct opcodes are possible. However, the LC-3 ISA speciﬁes only 15 opcodes. The code 1101 has been left unspeciﬁed, reserved for some future need that we are not able to anticipate today.

16. there are 3 different types of instructions, what are they? operate (process information), data movement (move information between memory and the registers and between registers/memory and input/output devices), and control (change the sequence of instructions that will be executed; that is, they enable the execution of an instruction other than the one that is stored in the next sequential location in memory)

17. A data type is a representation of information such that the ISA has opcodes that operate on that representation. There are many ways to represent the same information in a computer. That should not surprise us, since in our daily lives, we regularly represent the same information in many diﬀerent ways. 

18. In addition to the representation of a single number by diﬀerent bit patterns in diﬀerent data types, it is also the case that the same bit pattern can correspond to diﬀerent numbers, depending on the data type. For example, the 16 bits 0011000100110000 represent the 2’s complement integer 12,592, the ASCII code for 10 or a bit vector. This should also not surprise us, since in our daily lives, the same representation can correspond to multiple interpretations, as is the case with a red light. When you see it on the roadway while you are driving, it means you should stop. If you see a police car driving past with their lights flashing red, it means that they are on the way to respond to an incident that has occured.

19. how do opcodes interpret bit patterns of an operand? according to the data type it is designed to support. In the case of the ADD opcode, for example, the hardware will interpret the bit patterns of its operands as 2’s complement integers. Therefore, if a programmer stored the bit pattern 0011000100110000 in R3, thinking that the bit pattern represented the integer 10, the instruction ADD R4, R3, #10 would write the integer 12,602 into R4, and not the ASCII code for the integer 20. Why? Because the opcode ADD interprets the bit patterns of its operands as 2’s complement integers, and not ASCII codes, regardless what the person creating those numbers intended.

20. what is an addressing mode? is a mechanism for specifying where an operand is located.

21. An operand can generally be found in one of three places, what are they? in memory, in a register, or as part of an instruction

22. if an operand is part of an instruction, what do we refer to it as? a literal or an immediate operand

23. where does the term 'literal' come from? from the fact that the bits of the instruction literally form the operand

24. where does the term immediate come from? from the fact that we can obtain the operand immediately from the instruction i.e. we do Not have to look elsewhere for it

25. what are the 5 addressing modes supported by the LC-3? literal (or immediate), register, PC-relative, indirect, and base + offset

26. operate instructions use two addressing modes, what are they? register and immediate

27. how many addressing modes do data movement instructions use? 4 of 5 of the addressing modes

28. how many 3 single bit registers does the LC-3 have and what are they called? 3; they are referred to as N, Z, and P

29. what do N, Z, and P stand for? N stands for negative, Z stands for zero, and P stands for positive

30. how are these 3 single bit registers used? they are individually set (set to 1) or cleared (set to 0) each time one of the eight GPR's is written into as a result of execution of one of the operate instructions or one of the load instructions 

31. how do the operate and load instructions work with respect to the GPRs? each operate instruction performs a computation and writes the result into a GPR; each load instruction reads the contents of a memory location and writes the value found there into a general purpose register

32. what is the set of the 3 single bit registers referred to as? condition codes 

33. why are the 3 single bit registers referred to as condition codes? because the condition of the 3 bits is used to change the sequence of execution of the instructions in a computer program. Many ISAs use condition codes to change the execution sequence. 

34. The LC-3 has three operate instructions: ADD, AND, and NOT.

35. how many source operands does the NOT instruction operate on and what addressing mode does it use for both source and destination? one; register mode. The NOT instruction bit-wise complements a 16-bit source operand and stores the result in a destination register. NOT uses the register addressing mode for both its source and destination. Bits [8:6] specify the source register and bits [11:9] specify the destination register.

36. in the NOT instruction, what must bits 5:0 contain? all 1's

37. Figure 5.4 shows the key parts of the data path that are used to perform the NOT instruction shown here. Since NOT is a unary operation, only the A input of the ALU is relevant. It is sourced from R5. The control signal to the ALU directs the ALU to perform the bit-wise complement operation. The output of the ALU (the result of the operation) is stored in R3 and the condition codes are set, completing the execution of the NOT instruction.

38. Recall from Chapter 4 that the ADD (opcode = 0001) and AND (opcode = 0101) instructions both perform binary operations; they require two 16-bit source operands. The ADD instruction performs a 2’s complement addition of its two source operands. The AND instruction performs a bit-wise AND of each pair of bits of its two 16-bit operands. Like the NOT, the ADD and AND use the register addressing mode for one of the source operands and for the destina- tion operand. Bits [8:6] specify the source register, and bits [11:9] specify the destination register (where the result will be written).

39. what 2 addressing modes can be used to specify the second source operand for the AND and ADD instructions? register mode for one of the source operands and the destination operand; second operand is specified by either register mode or as an immediate operand

40. which bit determines which addressing mode will be used for the second operand in the AND and ADD instructions? bit 5

41. if bit 5 is 0 which addressing mode is used and what are bits 4:3 set to? register mode; set to 0

42. if bit 5 is 1 which addressing mode is used and what is done to bits 4:0? literal or immediate mode; they are sign extended to 16 bits

43. what must happen at the end of executing the AND and ADD Instruction (infact for load intructions as well)? the condition codes must be set

44. Figure 5.5 shows the key parts of the data path that are used to perform the instruction ADD  R1,  R4,  #-2.

45. what implication does using immediate addressing mode present? since the literal operand must fit into bits 4:0 of the instruction, not all 2 complement integers can be used as immediate operands

46. Which integers are OK (i.e., which integers can be used as immediate operands)? range of -16 through to 8 see example51, example52, example53

47. can a register can be used as a source and also as a destination in the same instruction? yes

48. what does the LEA instruction do? loads a register specified by bits 11:9 with an address specified by adding the PC + sign extended bits 8:0 of the instruction (the address is not accessed). Perhaps a better name for this opcode would be CEA (for Compute Eﬀective Address). If memory location x4018 contains the instruction LEA R5, #−3, and the PC contains x4018, R5 will contain x4016 after the instruction at x4018 is executed. Question: Why will R5 not contain the address x4015? because the PC is incremented before the offset is added to the incremented value

49. Figure 5.6 shows the relevant parts of the data path required to execute the LEA instruction. Note that the value to be loaded into the register does not involve any access to memory and nor does it have any eﬀect on the condition codes.

50. what do data movement instructions do? move information between GPRs and memory and between GPRs and input/output devices

51. what do you call the process of moving information from memory to a register? loading

52. what do you call the process of moving information from a register to a memory? storing

53. In both cases, the information in the location containing the source operand remains unchanged. In both cases, the location of the destination operand is over-written with the source operand, destroying in the process the previous value that was in the destination location.

54. how many instructions does the LC-3 contain for moving information? 6 (LD, LDR, LDI, ST, STR, and STI)

55. how many operands do data movement instructions require? two operands; a source and a destination. The source is the data to be moved; the destination is the location where it is moved to. One of these locations is a register, the other is a memory location or an input/output device. The format of the load and store instructions is as follows:

15  14  13  12  11  10  9  8  7  6  5  4  3  2  1  0
   opcode     | DR or SR |       Addr Gen bits

56. Bits [11:9] specify one of these operands, the register. If the instruction is a load, DR refers to the destination general purpose register that will contain the value after it is read from memory (at the completion of the instruction cycle). If the instruction is a store, SR refers to the register that contains the value that will be written to memory.
Bits [8:0] contain the address generation bits. That is, bits [8:0] contain information that is used to compute the 16-bit address of the second operand. 

57. in the case of LC-3, how many ways are there to interpret bits 8:0 for data movement instructions? 3 ways that are called addressing modes. The opcode speciﬁes how to interpret bits [8:0]. That is, the LC-3’s opcode speciﬁes which of the three addressing modes should be used to obtain the address of the operand from bits [8:0] of the instruction.

58. what two data movement instructions specify the PC-relative addressing mode? LD and ST

59. why is the PC-relative addressing mode named as such? because bits 8:0 of the instruction specify an offset relative to the PC

60. how is the memory address computed in pc-relative addressing mode? by sign extending bit 8:0 to 16 bits and adding the result to the incremented PC

61. in this case, what happens if the instruction is LD? the computed address (PC + offset) specifies the memory to be accessed. its contents are loaded into register specified by bits 11:9 of the instruction. If the following instruction is located at x4018, it will cause the contents of x3FC8 to be loaded into R2.

15  14  13  12  11  10  9   8  7  6  5  4  3  2  1  0
0   0   1   0 | 0   1   0 | 1  1  0  1  0  1  1  1  1
    LD             R2               X1AF

62. Figure 5.7 shows the relevant parts of the data path required to execute this instruction. The three steps of the LD instruction are identiﬁed. In step 1, the incremented PC (x4019) is added to the sign-extended value contained in IR [8:0] (xFFAF), and the result (x3FC8) is loaded into the MAR. In step 2, memory is read and the contents of x3FC8 is loaded into the MDR. Suppose the value stored in x3FC8 is 5. In step 3, the value 5 is loaded into R2, and the NZP condition codes are set, completing the instruction cycle.

63. what if the instruction is ST? the contents of the register specified by bits 11:9 of the instruction is written into the memory location whose address is PC + offset

64. what happens after either the LD or ST instruction has been executed? the N, Z, P condition codes are set depending on whether the value loaded is negative, positive, or zero.

65. what stands about the address generated in pc-relative addressing mode using bits 8:0? the range is limited to within ranges 256 and -256 f0r the ld and st instruction. If a load instruction needs to access a memory location further away from the load instruction, one of the other two addressing modes must be used. 

66. which two instructions use indirect addressing mode? LDI and STI

67. how are the LDI and STI operand addresses formed? the same way LD and ST are formed i.e. sign extending bits 8:0 from the instruction and adding it to the incremented value of the PC

68. how is the addressing mode of the LDI and STI instructions different from that of the LD and ST instructions? instead of this address being the address of the operand to be loaded or stored, it is the address of the address of the operand to be loaded or stored. hence the name indirect

69. what is the difference between the indirect mode and PC relative addressing modes in terms of the address of the operand in a computers memory? for indirect addressing mode, the address of the operand can be anywhere in the computers memory and not just within the range provided by bits 8:0 of the instruction

If the instruction

15  14  13  12  11  10  9   8  7  6  5  4  3  2  1  0
1   0   1   0 | 0   1   1 | 1  1  1  0  0  1  1  0  0
    LDI             R3               X1CC

is in x4A1B, and the contents of x49E8 is x2110, execution of this instruction results in the contents of x2110 being loaded into R3.

70. Figure 5.8 shows the relevant parts of the data path required to execute this instruction. As is the case with the LD and ST instructions, the ﬁrst step consists of adding the incremented PC (x4A1C) to the sign-extended value contained in IR [8:0] (xFFCC), and the result (x49E8) loaded into the MAR. In step 2, memory is in x4A1B and x2110 is in x49E8, and execution of this instruction results in the contents of x2110 being loaded into R3. In step 3, since x2110 is not the operand, but the address of the operand, it is loaded into the MAR. In step 4, memory is again read, and the MDR again loaded. This time the MDR is loaded with the contents of x2110. Suppose the value −1 is stored in memory location x2110. In step 5, the contents of the MDR (i.e., −1) is loaded into R3 and the NZP condition codes are set, completing the instruction cycle.

71. which two instructions use the base + offset addressing mode? LDR and STR

72. how does the base + offset addressing mode work? address of the operand is obtained by adding a sign extended six bit offset (5:0) to a base register specified by bits 8:6 

If R2 contains the 16-bit quantity x2345, the following instruction loads R1 with the contents of x2362.

15  14  13  12  11  10  9   8  7  6   5  4  3  2  1  0
0   1   1   0 | 0   0   1 | 0  1  0 | 0  1  1  1  0  1
    LDR             R1         R2          X1D

73. does the Base+oﬀset addressing mode also allow the address of the operand to be anywhere in 
the computer’s memory like indirect addressing mode? yes

74. Figure 5.9 shows the relevant parts of the data path required to execute this instruction. First the contents of R2 (x2345) is added to the sign-extended value contained in IR [5:0] (x001D), and the result (x2362) is loaded into the MAR. Second, memory is read, and the contents of x2362 is loaded into the MDR. Suppose the value stored in memory location x2362 is x0F0F. Third, and ﬁnally, the contents of the MDR (in this case, x0F0F) is loaded into R1 and the NZP condition codes are set, completing the execution of the LDR instruction.

75. Assume the contents of memory locations x30F6 through x30FC are as shown in Figure 5.10, and the PC contains x30F6. We will examine the eﬀects of carrying out the seven instructions starting at location x30FC. Since the PC points initially to location x30F6, the ﬁrst instruction to be executed is the one stored in location x30F6. The opcode of that instruction is 1110, load eﬀective address (LEA). LEA loads the register speciﬁed by bits [11:9] with the address formed by sign-extending bits [8:0] of the instruction and adding the result to the incremented PC. The 16-bit value obtained by sign-extending bits [8:0] of the instruction is xFFFD. The incremented PC is x30F7. Therefore, at the end of execution of the LEA instruction, R1 contains x30F4, and the PC contains x30F7.

76. Next, the instruction stored in location x30F7 is executed. Since the opcode 0001 speciﬁes ADD, the sign-extended immediate in bits [4:0] (since bit [5] is 1) is added to the contents of the register speciﬁed in bits [8:6], and the result is written to the register speciﬁed by bits [11:9]. Since the previous instruction wrote x30F4 into R1, and the sign-extended immediate value is x000E, the sum is x3102. At the end of execution of this instruction, R2 contains x3102, and the PC contains x30F8. R1 still contains x30F4.

77. Next, the instruction stored in x30F8. The opcode 0011 speciﬁes the ST instruction, which stores the contents of the register speciﬁed by bits [11:9] (R2) into the memory location whose address is computed using the PC-relative addressing mode. That is, the address is computed by adding the incremented PC (x30F9) to the 16-bit value obtained by sign-extending bits [8:0] of the instruction (xFFFB). Therefore, at the end of execution of the ST instruction, memory location x30F4 (i.e., x30F9 + xFFFB) contains the value stored in R2 (x3102) and the PC contains x30F9. 

78. Next the instruction at x30F9. The AND instruction, with an immediate operand x0000. At the end of execution, R2 contains the value 0, and the PC contains x30FA. At x30FA, the opcode 0001 speciﬁes the ADD instruction. After execution, R2 contains the value 5, and the PC contains x30FB.

79. At x30FB, the opcode 0111 signiﬁes the STR instruction. STR (like LDR) uses the Base+oﬀset addressing mode. The memory address is obtained by adding the contents of the BASE register (speciﬁed by bits [8:6]) to the sign-extended oﬀset contained in bits [5:0]. In this case, bits [8:6] specify R1, which contains x30F4. The 16-bit sign-extended oﬀset is x000E. Since x30F4 + x000E is x3102, the memory address is x3102. The STR instruction stores into x3102 the contents of the register speciﬁed by bits [11:9], in this case R2. Since R2 contains the value 5, at the end of execution of this instruction, M[x3102] contains the value 5, and the PC contains x30FC.

80. Finally the instruction at x30FC. The opcode 1010 speciﬁes LDI. LDI (like STI) uses the indirect addressing mode. The memory address is obtained by ﬁrst forming an address as is done in the PC-relative addressing mode. Bits [8:0] are sign-extended to 16 bits (xFFF7) and added to the incremented PC (x30FD). Their sum (x30F4) is the address of the operand address. Since M[x30F4] con- tains x3102, x3102 is the operand address. The LDI instruction loads the value found at this address (in this case 5) into the register identiﬁed by bits [11:9] of the instruction (in this case R3). At the end of execution of this instruction, R3 contains the value 5 and the PC contains x30FD.

81. what do control instructions do? they change the sequence of instructions to be executed otherwise the next instruction fetched would always be after the current instruction finishes in the next sequential memory location. As you know, this is because the PC is incremented in the FETCH phase of each instruction cycle.

82. how many opcodes does the LC-3 have that allow sequential execution flow to be broken? 5; conditional branch, unconditional jump, subroutine call (sometimes called function), TRAP, and RTI (return from trap or interrupt)

83. what does the TRAP instruction (often called service call) do? allows a programmer to get help from operating system to do things that the typical programmer does not understand how to do e.g. getting information from input device into the cpu, displaying information to output device. it breaks the sequential execution of a user program to start a sequence of instructions in the OS 

84. summarise how the conditional branch (BR which is opcode 0000) works? when executed it decides based on a test whether to execute the next instruction in memory or to jump to another instruction in a different part of the memory that was allocated to the program by the OS

85. what stage of instruction cycle does the BR instruction decide whether to load the PC with a new address? in the EXECUTE stage; if  nothing occurs in this stage then the incremented PC will remain unchanged and the next instruction executed will be the next instruction in the sequence, otherwise a new address will be loaded

86. what is the decision, whether to do nothing to the incremented PC or whether to change it, based on? it is based on the execution of previous instruction in the program which is reflected in the condition codes (the conditional branch's execute phase results in either doing nothing or it loads the PC with the address of the instruction it wishes to execute next) 

The format of the conditional branch instruction is as follows:

15  14  13  12  11  10  9   8  7  6  5  4  3  2  1  0
0   0   0   0 | n   z   p |          PCoﬀset
    

87. what is the format of the conditional branch instruction? bits 15:12 display the opcode which in this case is all 0's; bits 11:9 display the condition codes N, Z, P respectively; bits 8:0 are sign extended to make 16 bits which are then added to the incremented PC

88. in the LC-3, what instructions write into the GPR's and also set the condition codes? the operate instructions (ADD, AND, and NOT) and the three load instructions (LD, LDI, LDR)

89. what can you summise about the contents of bits 11:9 in the BR instruction and its operation? the BR instruction uses the information to determine whether to depart from the usual sequential execution of instructions that we get as a result of incrementing the PC during the FETCH phase of each instruction

90. how does the above happen? during the EXECUTE phase of the BR instruction cycle, the processor examines the condition codes whose associated bits in the instruction bits 11:9 are 1. if bit 11 is 1 then condition code N is examined; if bit 10 is 1 then condition code Z is examined; similar action is taken for bit 9. if any of the bits 11:9 are 0 then the associated condition codes are not examined. if any of the condition codes examined are set, then the PC is loaded with the address obtained in the EVALUTE ADDRESS phase. if none of the condition codes that are examined are set, the incremented PC is left unchanged, and the next sequential instruction will be fetched at the start of the next instruction cycle.

91. how is the address obtained during the EVALUATE ADDRESS phase generated? using PC-relative addressing mode

92. Suppose the following instruction is located at x4027, and the last value loaded into a general purpose register was 0

15  14  13  12  11  10  9   8  7  6  5  4  3  2  1  0
0   0   0   0 | 0   1   0 | 0  1  1  0  1  1  0  0  1        
     BR         n   z   p            x0D9 

93. Figure 5.11 shows the data path elements that are required to execute this instruction. Note the logic required to determine whether the sequential instruc- tion ﬂow should be broken. Each of the three AND gates corresponds to one of the three condition codes. The output of the AND gate is 1 if the corresponding condition code is 1 and if the associated bit in the instruction directs the hardware to check that condition code. If any of the three AND gates have an output 1, the OR gate has an output 1, indicating that the sequential instruction ﬂow should be broken, and the PC should be loaded with the address evaluated during the EVALUATE ADDRESS phase of the instruction cycle.

94. In the case of the conditional branch instruction at x4027, the answer is yes, and the PC is loaded with x4101, replacing x4028, which had been loaded into the PC during the FETCH phase of the BR instruction.

95. why is the uconditonal branch named so? because all bits 11:9 are set to 1 ergo all conditions are examined based on the output of the previous instruction. In this case, since the last result stored into a register had to be either negative, zero, or positive (there are no other choices!), one of the three condition codes must be in state 1. Since all three are examined, the PC is loaded with the address obtained in the EVALUATE ADDRESS phase. We call this an unconditional branch since the instruction ﬂow is changed unconditionally, that is, independent of the data.

For example, if the following instruction, located at x507B, is executed, the PC is loaded with x5001.

15  14  13  12  11  10  9   8  7  6  5  4  3  2  1  0
0   0   0   0 | 1   1   1 | 1  1  0  0  0  0  1  0  1        
     BR         n   z   p            x185 

96. there are two methods of loop control, name them: loop control with a counter and loop control with a sentinel

97. what is the difference between the two? a counter will control the number of times a loop executes by being decremented in each cycle and then checked to see if it is zero (conditional branch instruction). if not, the loop body is executed again; otherwise next instruction to be executed is after the last instruction of the loop body. on the other hand, sentinels are used when we do not know beforehand how many iterations we will want to perform; each iteration will be based on processing a value and when the sentinel is encountered the loop is broken

98. Loop Control with a Counter: Suppose we know that the 12 locations x3100 to x310B contain integers, and we wish to compute the sum of these 12 integers. A ﬂowchart for an algorithm to solve the problem is shown in Figure 5.12. First, as in all algorithms, we must initialize our variables. There are three such variables: the address of the next integer to be added (assigned to R1), the running sum (assigned to R3), and the number of integers left to be added (assigned to R2). The three variables are initialized as follows: The address of the ﬁrst integer to be added is put in R1. R3, which will keep track of the running sum, is initialized to 0. R2, which will keep track of the number of integers left to be added, is initialized to 12. Then the process of adding begins.

99. The program repeats the process of loading into R4 one of the 12 integers and adding it to R3. Each time we perform the ADD, we increment R1 so it will point to (i.e., contain the address of) the next number to be added and decrement R2 so we will know how many numbers still need to be added. When R2 becomes zero, the Z condition code is set, and we can detect that we are done.

100. The 10-instruction program shown in Figure 5.13 accomplishes the task. The details of the program execution are as follows: The program starts with PC = x3000. The ﬁrst instruction (at location x3000) initializes R1 with the address x3100. (The incremented PC is x3001; the sign-extended PCoﬀset is x00FF.). The instruction at x3001 clears R3. R3 will keep track of the running sum, so it must start with the value 0. As we said previously, this is called initializing the SUM to zero. The instructions at x3002 and x3003 initialize R2 to 12, the number of integers to be added. R2 will keep track of how many numbers have already been added. This will be done (by the instruction in x3008) by decrementing R2 after each addition takes place.

101. The instruction at x3004 is a conditional branch instruction. Note that bit [10] is a 1. That means that the Z condition code will be examined. If it is set, we know R2 must have just been decremented to 0. That means there are no more numbers to be added, and we are done. If it is clear, we know we still have work to do, and we continue with another iteration of the loop body.

102. The instruction at x3005 loads the next integer into R4, and the instruction at x3006 adds it to R3. The instruction at x3007 increments R1, so R1 will point to the next location in memory containing an integer to be added. The instruction at x3008 decrements R2, which is keeping track of the number of integers still to be added, and sets the condition codes.

103. The instruction at x3009 is an unconditional branch, since bits [11:9] are all 1. It loads the PC with x3004. It also does not aﬀect the condition codes, so the next instruction to be executed (the conditional branch at x3004) will be based on the instruction executed at x3008. The conditional branch instruction at x3004 examines the Z condition code. As long as Z is clear, the PC will not be aﬀected, and the next iteration of the loop body will begin. That is, the next instruction cycle will start with an instruction fetch from x3005.

104. The conditional branch instruction causes the execution sequence to follow: x3000, x3001, x3002, x3003, x3004, x3005, x3006, x3007, x3008, x3009, x3004, x3005, x3006, x3007, x3008, x3009, x3004, x3005, and so on. The loop body consists of the instructions at x3005 to x3009. When the value in R2 becomes 0, the PC is loaded with x300A, and the program continues at x300A with its next activity.

105. Loop Control with a Sentinel: This method is particularly eﬀective if we do not know ahead of time how many iterations we will want to perform. Each iteration is usually based on processing a value. We append to our sequence of values to be processed a value that we know ahead of time can never occur (i.e., the sentinel). For example, if we are adding a sequence of numbers, a sentinel could be a letter A or a *, that is, something that is not a number. Our loop test is simply a test for the occurrence of the sentinel. When we ﬁnd it, we know we are done.

106. Suppose we know the values stored in locations x3100 to x310B are all pos- itive. Then we could use any negative number as a sentinel. Let’s say the sentinel stored at memory address x310C is −1. The resulting ﬂowchart for this solution is shown in Figure 5.14, and the resulting program is shown in Figure 5.15.

107. As before, the instruction at x3000 loads R1 with the address of the ﬁrst value to be added, and the instruction at x3001 initializes R3 (which keeps track of the sum) to 0. At x3002, we load the contents of the next memory location into R4. If the sentinel is loaded, the N condition code is set. The conditional branch at x3003 examines the N condition code. If N=1, PC is loaded with x3008 and onto the next task. If N=0, R4 must contain a valid number to be added. In this case, the number is added to R3 (x3004), R1 is incremented to point to the next memory location (x3005), R4 is loaded with the contents of the next memory location (x3006), and the PC is loaded with x3003 to begin the next iteration (x3007).

108. what is the limitation of the conditional branch instruction? the next instruction that it loads the PC with (computed from sign-extending bits 8:0 and adding them to the incremented PC) can be at most +256 or -255 locations from the currently executing branch instruction

109. what if you want to execute an instruction that is 2000 locations from the BR instruction? you cannot use the BR instruction since you cannot fit 2000 into the 9 bit field 

110. what instruction provided by the LC-3 can do the above? the jmp instruction

111. how does it work? the jmp instruction loads the PC with the contents of the register specified by bits 8:6

If the following JMP instruction is located at address x4000

15  14  13  12  11  10  9   8  7  6   5  4  3  2  1  0
1   1   0   0 | 0   0   0 | 0  1  0 | 0  0  0  0  0  0        
     JMP                     BaseR

R2 contains the value x6600, and the PC contains x4000, then the instruction at x4000 (the JMP instruction) will be executed, followed by the instruction located at x6600. Since registers contain 16 bits (the full address space of memory), the JMP instruction has no limitation on where the next instruction to be executed must reside.

112. how does the TRAP instruction work? it changes the PC to a memory address that is part of the operating system so that the OS will perform some task on behalf of the executing program. In the language of operating system jargon, we say the TRAP instruction invokes an operating system service call.

113. Bits [7:0] of the TRAP instruction form the trapvector, an eight-bit code that identiﬁes the ser- vice call that the program wishes the operating system to perform on its behalf.

15  14  13  12  11  10  9  8   7  6  5  4  3  2  1  0
1   1   1   1 | 0   0   0  0 |     trapvector        
    
114. what happens after an os finishes executing a service call? Once the operating system is ﬁnished performing the service call, the program counter is set to the address of the instruction following the TRAP instruction, and the program continues. In this way, a program can, during its execution, request services from the operating system and continue processing after each such service is performed. 

115. what are the services that will be used in the lc-3? 
* Input a character from the keyboard (trapvector = x23).
* Output a character to the monitor (trapvector = x21). 
* Halt the program (trapvector = x25).

116. Suppose we would like to be able to input a character from the keyboard, then count the number of occurrences of that character in a ﬁle, and ﬁnally display that count on the monitor. We will simplify the problem by assuming that the number of occurrences of any character that we would be interested in is small enough that it can be expressed with a single decimal digit. That is, there will be at most nine occurrences. This simpliﬁcation allows us to not have to worry about complex conversion routines between the binary count and the ASCII display on the monitor. Figure 5.16 is a ﬂowchart of the algorithm that solves this problem. Note that each step is expressed both in English and also (in parentheses) in terms of an LC-3 implementation.

117. The ﬁrst step is (as always) to initialize all the variables. This means pro- viding starting values (called initial values) for R0, R1, R2, and R3, the four registers the computer will use to execute the program that will solve the prob- lem. R2 will keep track of the number of occurrences; in Figure 5.16, it is referred to as Count. It is initialized to zero. R3 will point to the next character in the ﬁle that is being examined. We refer to it as a pointer since it points to (i.e., contains the address of) the location where the next character of the ﬁle that we wish to examine resides. The pointer is initialized with the address of the ﬁrst character in the ﬁle. R0 will hold the character that is being counted; we will input that character from the keyboard and put it in R0. R1 will hold, in turn, each character that we get from the ﬁle being examined.

118. We should also note that there is no requirement that the ﬁle we are examining be close to or far away from the program we are developing. For example, it is perfectly reasonable for the program we are developing to start at x3000 and the ﬁle we are examining to start at x9000. If that were the case, in the initialization process, R3 would be initialized to x9000.

119. The next step is to count the number of occurrences of the input character. This is done by processing, in turn, each character in the ﬁle being examined, until the ﬁle is exhausted. Processing each character requires one iteration of a loop. We will use the sentinel method, using the ASCII code for EOT (End of Transmission) (00000100) as the sentinel. A table of ASCII codes is in Appendix E.

120. In each iteration of the loop, the contents of R1 is ﬁrst compared to the ASCII code for EOT. If they are equal, the loop is exited, and the program moves on to the ﬁnal step, displaying on the screen the number of occurrences. If not, there is work to do. R1 (the current character under examination) is compared to R0 (the character input from the keyboard). If they match, R2 is incremented. In either case, we move on to getting the next character. The pointer R3 is incremented, the next character is loaded into R1, and the program returns to the test that checks for the sentinel at the end of the ﬁle.

121. When the end of the file is reached, all the characters have been examined, and the count is contained as a binary number in R2. In order to display the count on the monitor, it is first converted to an ASCII code. Since we have assumed the count is less than 10, we can do this by putting a leading 0011 in front of the four-bit binary representation of the count. Note in Figure E.2 the relationship between the binary value of each decimal digit between 0 and 9 and its corresponding ASCII code. Finally, the count is output to the monitor, and the program terminates. Figure 5.17 is a machine language program that implements the ﬂowchart of Figure 5.16.

122. First the initialization steps. The instruction at x3000 clears R2 by ANDing it with x0000. The instruction at x3001 loads the starting address of the ﬁle to be examined into R3. Again, we note that this ﬁle can be anywhere in memory. Prior to starting execution at x3000, some sequence of instructions must have stored the ﬁrst address of this ﬁle in x3012. Location x3002 contains the TRAP instruction, which requests the operating system to perform a service call on behalf of this program. The function requested, as identiﬁed by the eight-bit trapvector 00100011 (i.e., x23), is to load into R0 the ASCII code of the next character typed on the keyboard. The instruction at x3003 loads the character pointed to by R3 into R1.

123. Then the process of examining characters begins. We start (x3004) by subtracting 4 (the ASCII code for EOT) from R1 and storing it in R4. If the result is zero, the end of the ﬁle has been reached, and it is time to output the count. The instruction at x3005 conditionally branches to x300E, where the process of outputting the count begins.

124. If R4 is not equal to zero, the character in R1 is legitimate and must be examined. The sequence of instructions at locations x3006, x3007, and x3008 determines whether the contents of R1 and R0 are identical. Taken together, the three instructions compute R0 − R1 This produces all zeros only if the bit patterns of R1 and R0 are identical. If the bit patterns are not identical, the conditional branch at x3009 branches to x300B; that is, it skips the instruction at x300A, which increments the counter (R2).

125. The instruction at x300B increments R3, so it will point to the next character in the ﬁle being examined, the instruction at x300C loads that character into R1, and the instruction at x300D unconditionally takes us back to x3004 to start processing that character.

126. When the sentinel (EOT) is ﬁnally detected, the process of outputting the count begins (at x300E). The instruction at x300E loads 00110000 into R0, and the instruction at x300F adds the count to R0. This converts the binary representation of the count (in R2) to the ASCII representation of the count (in R0). The instruction at x3010 invokes a TRAP to the operating system to output the contents of R0 to the monitor. When that is done and the program resumes execution, the instruction at x3011 invokes a TRAP instruction to terminate the program.

127. Figure 5.18 shows a data path diagram of the many structures we have encountered so far. Note at the outset that there are two kinds of arrows in the data path, those with arrowheads ﬁlled in and those with arrowheads not ﬁlled in. Filled-in arrowheads designate information that is processed. Unﬁlled-in arrowheads designate control signals. Control signals emanate from the block labeled “Finite State Machine.” The connections from the ﬁnite state machine to most control signals have been left oﬀ Figure 5.18 to reduce unnecessary clutter in the diagram.

128. global bus: The most obvious item on the data path diagram is the heavy black structure with arrowheads at both ends. This represents the data path’s global bus. The LC-3 global bus consists of 16 wires and associated electronics. It allows one structure to transfer up to 16 bits of information to another structure by making the necessary electronic connections on the bus. Exactly one value can be transferred on the bus at one time.

129. Note that each structure that supplies values to the bus has a triangle just behind its input arrow to the bus. This triangle (called a tristate device) allows the computer’s control logic to enable exactly one supplier to provide information to the bus at any one time. The structure wishing to obtain the value being supplied can do so by asserting its LD.x (load enable) signal.Not all computers have a single global bus.

130. memory: One of the most important parts of any computer is the memory that contains both instructions and data. Memory is accessed by loading the memory address register (MAR) with the address of the location to be accessed. To perform a load, control signals then read the contents of that memory location, and the result of that read is delivered by the memory to the memory data register (MDR). On the other hand, to perform a store, what is to be stored is loaded into the MDR. Then the control signals assert a write enable (WE) signal in order to store the value contained in MDR in the memory location speciﬁed by MAR.

131. ALU and the Register File: The ALU is the processing element. It has two inputs, source 1 from a register and source 2 from either a register or the sign-extended immediate value provided by the instruction. The registers (R0 through R7) can provide two values: source 1, which is controlled by the three-bit register number SR1, and source 2, which is controlled by the three-bit register number SR2. SR1 and SR2 are ﬁelds in the LC-3 operate instructions. The selection of a second register operand or a sign-extended immediate operand is determined by bit [5] of the LC-3 instruction.
Note the mux that provides source 2 to the ALU. The select line of that mux is bit [5] of the LC-3 operate instruction.

132. The results of an ALU operation are (a) a result that is stored in one of the registers, and (b) the three single-bit condition codes. Note that the ALU can supply 16 bits to the bus, and that value can then be written into the register specified by the three-bit register number DR. Also, note that the 16 bits supplied to the bus are also input to logic that determines whether that 16-bit value is negative, zero, or positive. The three one-bit condition code registers N, Z, and P are set accordingly.

133. The PC and the PCMUX: At the start of each instruction cycle, the PC supplies to the MAR over the
global bus the address of the instruction to be fetched. In addition, the PC, in turn, is supplied via the three-to-one PCMUX. During the FETCH phase of the instruction cycle, the PC is incremented and written into the PC. That is shown as the rightmost input to the PCMUX.

134. If the current instruction is a control instruction, then the relevant source of the PCMUX depends on which control instruction is currently being processed. If the current instruction is a conditional branch and the branch is taken, then the PC is loaded with the incremented PC + PCoﬀset (the 16-bit value obtained by sign-extending IR [8:0]). Note that this addition takes place in the special adder and not in the ALU. The output of the adder is the middle input to PCMUX. The third input to PCMUX is obtained from the global bus.

135. The MARMUX: As you know, memory is accessed by supplying the address to the MAR. The MARMUX controls which of two sources will supply the MAR with the appropriate address during the execution of a load, a store, or a TRAP instruction. The right input to the MARMUX is obtained by adding either the incremented PC or a base register to zero or a literal value supplied by the IR. Whether the PC or a base register and what literal value depends on which opcode is being processed. The control signal ADDR1MUX speciﬁes the PC or base register. The control signal ADDR2MUX speciﬁes which of four values is to be added. The left input to MARMUX provides the zero-extended trapvector, which is needed to invoke service calls, and will be discussed in detail later.

136. Suppose the content of the PC is x3456 and the content of location x3456 is

15  14  13  12  11  10  9   8  7  6   5  4  3  2  1  0
0   1   1   0 | 0   1   1 | 0  1  0 | 0  0  0  1  0  0        
     LDR            R3         R2            4

Suppose the LC-3 has just completed processing the instruction at x3455, which happened to be an ADD instruction.

137. FETCH: In the ﬁrst cycle, the contents of the PC is loaded via the global bus into the MAR,
and the PC is incremented and loaded into the PC. At the end of this cycle, the PC contains x3457. In the next cycle (if memory can provide information in one cycle), the memory is read, and the instruction 0110011010000100 is loaded into the MDR. In the next cycle, the contents of the MDR is loaded into the instruction register (IR), completing the FETCH phase.

138. DECODE: In the next cycle, the contents of the IR is decoded, resulting in the control logic providing the correct control signals (unﬁlled arrowheads) to control the processing of the rest of this instruction. The opcode is 0110, identifying the LDR instruction. This means that the Base+oﬀset addressing mode is to be used to determine the address of data to be loaded into the destination register R3.

139. EVALUATE ADDRESS: In the next cycle, the contents of R2 (the base register) and the sign-extended
bits [5:0] of the IR are added and supplied via the MARMUX to the MAR. The SR1 ﬁeld speciﬁes 010, the register to be read to obtain the base address. ADDR1MUX selects SR1OUT, and ADDR2MUX selects the second from the right source.

140. OPERAND FETCH: In the next cycle (or more than one, if memory access takes more than one cycle),
the value at that address is loaded into the MDR.

141. EXECUTE: The LDR instruction does not require an EXECUTE phase, so this phase takes zero cycles.

142. STORE RESULT: In the last cycle, the contents of the MDR is gated onto the global bus, from which
it is loaded into R3 and supplied to the condition code logic in order to set the NZP condition codes.

chapter 6 (not needed)

chapter 7

1. mechanical languages are generally partitioned into two classes. what are they? high level and low level

2. describe high level languages? are more user friendly, almost resemble statements in natural languge such as english, and are ISA independent

3. what must happen before a program that is written in a high-level language can be executed? it must be translated into a program in the ISA of the computer on which it is expected to execute

4. It is often the case that each statement in the high-level language speciﬁes several instructions in the ISA of the computer.

5. what do you call the small step up from the ISA of a machine? the ISAs assembly language

6. what is assembly language? a low level language which cannot be confused with a statement in english language. it is ISA dependent i.e. each ISA has only one assembly language. 

7. does each assembly language instruction usually specify a single instruction in the ISA? yes

8. what is the purpose of assembly language? to make the programming process more user friendly than programming in machine language (i.e. in the ISA of the computer you are working on) while providing the programmer with detailed control over the instructions the computer can execute

9. what does assembly language do that help the programmer avoid minutae? let us use mnemonic devices for opcodes, such as ADD for 0001 and NOT for 1001, and give meaningful symbolic names to memory locations, such as SUM or PRODUCT, rather than use the memory locations’ 16-bit addresses. 

10. what do you lose when you use a high level language like C? whilst it is user friendly, you relinquish control over which ISA instruction are to be used to carry out the work specified by the high level statement

11. The program in Figure 7.1 multiplies the integer initially stored in NUMBER by 6 by adding the integer to itself six times. The program consists of 21 lines of code. line numbers were added to
each line of the program in order to be able to refer to individual lines easily. These line numbers are not part of the program. Ten lines start with a semicolon, designating that they are strictly for the beneﬁt of the human reader. Seven lines (06, 07, 08, 0C, 0D, 0E, and 10) specify assembly language instructions to be translated into machine language instructions of the LC-3, which will be executed when the program runs. The remaining four lines (05, 12, 13, and 15) contain pseudo-ops

12. what are pseudo ops (assembler directives)? message from the programmer to the translation program to help in the translation process 

13. what is the translation program that is used to translate assembly programs to machine language? assembler

14. what is the translation process called? assembly

15. instead of an instruction being 16 0's and 1's as is the case of the LC-3 ISA, an instruction in assembly language consists of four parts. what are they called? label, opcode, operands, comment

16. which two are optional? label and comment

17. Two of the parts (Opcode and Operands) are mandatory. For an assembly language instruction to correspond to an instruction in the LC-3 ISA, it must have an Opcode (the thing the instruction is to do), and the appropriate number of Operands (the things it is supposed to do it to). The Opcode is a symbolic name for the opcode of the corresponding LC-3 instruction. The idea is that it is easier to remember an operation by the symbolic name ADD, AND, or LDR than by the four-bit quantity 0001, 0101, or 0110. The number of operands depends on the operation being performed. For example, the ADD instruction (line 0C in the program of Figure 7.1) requires three operands (two sources to obtain the numbers to be added, and one destination to designate where the result is to be stored). All three operands must be explicitly identiﬁed in the instruction. We represent each of the registers 0
through 7 as R0, R1, R2, … , R7, rather than 000, 001, 010, … , 111.

18. in LC-3 assembly language, why are symbolic names, called labels, assigned to memory locations? so that we do not have to remember explicit 16 bit addresses. in Figure 7.1, the LD instruction requires two operands (the memory location from which the value is to be read and the destination register that is to contain the value after the instruction ﬁnishes execution). The location from which the value is to be read is given the label NUMBER. The destination (i.e., where the value is to be loaded) is register 2.

19. As discussed previously, operands can be obtained from registers, from memory, or they may be literal (i.e., immediate) values in the instruction. In the case of register operands, the registers are explicitly represented (such as R2 and R3 in line 0C). In the case of memory operands, the symbolic name of the memory location is explicitly represented (such as NUMBER in line 07 and SIX in line 06). In the case of immediate operands, the actual value is explicitly represented
(such as the value 0 in line 08).

20. for literal values in assembly language that are used as operands, how will know a number is a decimal, hex, or a binary? decimal numbers will be preceeded by #, binary by b, and hex by X

21. Labels are symbolic names that are used to identify memory locations that are referred to explicitly in the program. In LC-3 assembly language, a label consists of from 1 to 20 alphanumeric characters (i.e., each character is a capital or lower-case letter of the English alphabet, or a decimal digit), starting with a letter of the alphabet. However, not all sequences of characters that follow these rules can be used as labels. Character strings that have speciﬁc meanings in an
LC-3 program cannot be used as labels. Such not-allowed character strings are often referred to as reserved words.

22. what are the two reasons for explicitly referring to a memory location using a label? the location is a target of a branch instruction (e.g., AGAIN in line 0C) and the location contains a value that is loaded or stored (e.g., NUMBER in line 12, and SIX in line 13).

23. The LC-3 assembler is a program that takes as input a string of characters representing a computer program written in LC-3 assembly language and translates it into a program in the ISA of the LC-3. Pseudo-ops help the assembler perform that task. The more formal name for a pseudo-op is assembler directive. It is called a pseudo-op because, like its Greek root “pseudes” (which means “false”), it does not refer to an operation that will be performed by the program during execution. Rather, the pseudo-op is strictly a message from the assembly language programmer to the assembler to help the assembler in the assembly process. Once the assembler handles the message, the pseudo-op is discarded.

24. how many pseudo-ops does the LC-3 assembly language contain? 5; .ORIG, .FILL, .BLKW, .STRINGZ, and .END.

25. what does the .ORIG pseudo-op do? it tells the assembler where in memory to place the LC-3 program i.e. first instruction is placed in the memory addressed specified, whilst the rest of the instructions in the program are placed in subsequent sequential locations. In line 05, .ORIG x3050 says, place the ﬁrst LC-3 ISA instruction in location x3050. As a result, 0010001000001100 (the translated LD R1,SIX instruction) is put in location x3050, and the rest of the translated LC-3 program is placed in the subsequent sequential locations in memory.

26. what does the .FILL pseudo-op do? tells the assembler to set aside the next location in the program and initialise it with the value of the operand. the value can either be a number or a label. In line 13, the ninth location in the resulting LC-3 program is initialized to the value x0006.

27. what does the .BLKW pseudo op do? tells the assembler to set aside some number of sequential memory locations in the program. The actual number is the operand of the .BLKW pseudo op. In line 12, the pseudo-op instructs the assembler to set aside one location in memory (and, incidentally, to label it NUMBER).

28. what does the .STRINGZ pseudo op do? tells the assembler to initialise a sequence of n+1 memory locations. The argument is a sequence of n characters inside double quotation marks. The first n words of memory are initialised with zero extended ascii codes of the corresponding characters in the string. final word of memory is initialised to 0. The last word, containing x0000, provides a convenient sentinel for processing the string of ASCII codes.

For example, the code fragment
          .ORIG     x3010
HELLO     .STRINGZ  "Hello, World!"

would result in the assembler initializing locations x3010 through x301D to the following values:

x3010: x0048
x3011: x0065
x3012: x006C
x3013: x006C
x3014: x006F
x3015: x002C
x3016: x0020
x3017: x0057
x3018: x006F
x3019: x0072
x301A: x006C
x301B: x0064
x301C: x0021
x301D: x0000

29. what does the .END pseudo op do? tells the assembler it has reached the end of the program and need not look at anything after it. That is, any characters that come after .END will not be processed by the assembler. Note: .END does not stop the program during execution. In fact, .END does not even exist at the time of execution. It is simply a delimiter— it marks the end of the program. It is a message from the programmer, telling the assembler where the assembly language program ends.

30. Figure 7.2 is the assembly version of the character count program you encountered earlier. A few comments about this program: Three times during this program, assistance in the form of a service call is required of the operating system. In each case, a TRAP instruction is used. TRAP x23 causes a character to be input from the keyboard and placed in R0 (line 0D). TRAP x21 causes the ASCII code in R0 to be displayed on the monitor (line 28). TRAP x25 causes the machine to be halted (line 29).

31. The ASCII codes for the decimal digits 0 to 9 (0000 to 1001) are x30 to x39. The conversion from binary to ASCII is done simply by adding x30 to the binary value of the decimal digit. Line 2D shows the label ASCII used to identify the memory location containing x0030. The LD instruction in line 26 uses it to load x30 into R0, so it can convert the count that is in R2 from a binary value to an
ASCII code. That is done by the ADD instruction in line 27. TRAP x21 in line 28 prints the ASCII code to the monitor.

32. The ﬁle that is to be examined starts at address x4000 (see line 2E). Usually, this starting address would not be known to the programmer who is writing this program since we would want the program to work on many ﬁles, not just the one starting at x4000. To accomplish that, line 2E would be replaced with .BLKW 1 and be ﬁlled in by some other piece of code that knew the starting address of
the desired ﬁle before executing the program of Figure 7.2

33. If you have available an LC-3 assembler, you can cause it to translate your assembly language program into a machine language program by executing an appropriate command. In the LC-3 assembler that is generally available via the web, that command is assemble, and it requires as an argument the ﬁlename of your assembly language program.

34. how does the assembly process unfold? it is done in two complete passes (from beginning to .END) through the entire assembly language program. the objective of the first pass is to identify the actual binary addresses corresponding to the symbolic names (or labels). this is set of correspondences is known as the symbol table. In pass 1, we construct the symbol table. in pass 2, we translate the individual assembly language instructions into their corresponding machine language instructions.

35. Thus, when the assembler examines line 0C for the purpose of translating LD R3,PTR during the second pass, it already knows that PTR is the symbolic address of memory location x3013 (from the ﬁrst pass). Thus, it can easily translate line 0C to 

     x3001: 0010 011 000010001

The problem of not knowing the 16-bit address corresponding to PTR no longer exists.

36. the symbol table is simply a correspondence of symbolic names with their 16-bit memory addresses. We obtain these correspondences by passing through the assembly language program once, noting which instruction is assigned to which memory location, and identifying each label with the memory address of its assigned entry.

37. why are labels used in assembly language? to refer to memory locations either because it is a target of a branch instruction or because it contains data that must be loaded or stored. Consequently, if we have not made any programming mistakes, and if we identify all the labels, we will have identiﬁed all the symbolic addresses used in the program.

38. The ﬁrst pass starts, after discarding the comments on lines 01 to 09, by noting (line 0A) that the ﬁrst instruction will be assigned to address x3000. We keep track of the location assigned to each instruction by means of a location counter(LC).The LC is initialized to the address speciﬁed in .ORIG, that is, x3000. The assembler examines each instruction in sequence and increments the LC once for each assembly language instruction. If the instruction examined contains a label, a symbol table entry is made for that label, specifying the current contents of LC as its address. The ﬁrst pass terminates when the .END pseudo-op is reached.

39. The ﬁrst instruction that has a label is at line 13. Since it is the ﬁfth instruction in the program and since the LC at that point contains x3004, a symbol table entry is constructed thus:

Symbol    Address
TEST      x3004

The second instruction that has a label is at line 20. At this point, the LC has been incremented to x300B. Thus, a symbol table entry is constructed, as follows:

Symbol    Address
GETCHAR   x300B

At the conclusion of the ﬁrst pass, the symbol table has the following entries:

Symbol    Address
TEST      x3004
GETCHAR   x300B
OUTPUT    x300E
ASCII     x3012
PTR       x3013

40. The second pass consists of going through the assembly language program a second time, line by line, this time with the help of the symbol table. At each line, the assembly language instruction is translated into an LC-3 machine language instruction. Starting again at the top, the assembler again discards lines 01 through 09 because they contain only comments. Line 0A is the .ORIG pseudo-op, which
the assembler uses to initialize LC to x3000. The assembler moves on to line 0B and produces the machine language instruction 0101010010100000. Then the assembler moves on to line 0C.

41. This time, when the assembler gets to line 0C, it can completely assemble the instruction since it knows that PTR corresponds to x3013. The instruction is LD, which has an opcode encoding of 0010. The destination register (DR) is R3, that is, 011.

42. The only part of the LD instruction left to do is the PCoﬀset. It is computed as follows: The assembler knows that PTR is the label for address x3013 and that the incremented PC is LC+1, in this case x3002. Since PTR (x3013) must be the sum of the incremented PC (x3002) and the sign-extended PCoﬀset, PCoﬀset must be x0011. Putting this all together, the assembler sets x3001 to 0010011000010001
and increments the LC to x3002.

43. Note: In order to use the LD instruction, it is necessary that the source of the load, in this case the address whose label is PTR, is not more than +256 or −255 memory locations from the LD instruction itself. If the address of PTR had been greater than LC+1+255 or less than LC+1−256, then the oﬀset would not ﬁt in bits [8:0] of the instruction. In such a case, an assembly error would
have occurred, preventing the assembly process from ﬁnishing successfully. Fortunately, PTR is close enough to the LD instruction, so the instruction assembled correctly.

44. The second pass continues. At each step, the LC is incremented and the location speciﬁed by LC is assigned the translated LC-3 instruction or, in the case of .FILL, the value speciﬁed. When the second pass encounters the .END pseudo-op, assembly terminates. The resulting translated program is shown in Figure 7.3.

45. when a computer begins execution of a program, what is the entity being executed called? executable image

46. what is the executable image created from? from modules created independently by individual pogrammers where each module is translated separately into an object file or from library routines supplied by the OS

47. are all modules written by users? no, some are supplied as library routines by the operating system

48. what does each object file consist of? instructions in the ISA of the computer being used along with its associated data

49. what is normally the final step? combining (linking) all of the object modules together into one executable image

50. what happens during the execution of the program? the fetch, decode... instruction cycle is applied to instructions in the executable image

51. It is very common to form an executable image from more than one object ﬁle. In fact, in the real world, where most programs invoke libraries provided by the operating system as well as modules generated by other programmers, it is much more common to have multiple object ﬁles than a single one.

52. A case in point is our example character count program. The program counts the number of occurrences of a character in a ﬁle. A typical application could easily have the program as one module and the input data ﬁle as another. If this were the case, then the starting address of the ﬁle, shown as x4000 in line 2E of Figure 7.2, would not be known when the program was written. If we replace line
2E with

PTR  .FILL  STARTofFILE

then the program of Figure 7.2 will not assemble because there will be no symbol table entry for STARTofFILE. What can we do? In the LC-3 assembly language, we could use the pseudo-op .EXTERNAL. This would be done by the following line

.EXTERNAL STARTofFILE,

53. what does the pseudo-op .EXTERNAL do? identifies the symbolic name of an address that is not known at the time a program of Figure 7.2 is assembled. it sends a message to the LC-3 assembler that the absence of a symbolic label is not an error in the program i.e. the symbolic name is a label in another module that will be translated independently. the LC-3 assembler would be able to create a symbol table entry for STARTofFILE, and instead of assigning it an address, it would mark the symbol as belonging to another module. At link time, when all the modules are combined, the linker (the program that manages the “combining” process) would use the symbol table entry for STARTofFILE in another module to complete the translation of our revised line 2E. In this way, the .EXTERNAL pseudo-op allows references by one module to symbolic references in another module without a problem. The proper translations are resolved by the linker.

chapter 8

1. what do you call complex items of information? abstract data types or more colloquially data structures.

2. subroutines: Figure 8.1 provides a simple illustration of a part of a program—call it “piece- of-code-A”—containing fragments that must be executed multiple times within piece-of-code-A. Let’s ignore everything about it except the three-instruction sequences starting at symbolic addresses L1, L2, L3, and L4. Each of these four 3-instruction sequences does the following:

label       LDI     R3,DSR
            BRzp    label 
            STI     Reg,DDR

Each of the four instances uses a diﬀerent label (L1, L2, L3, L4), but that is not a problem since in each instance the only purpose of the label is to branch back from the BRzp instruction to the LDI instruction.

Two of the four program fragments store the contents of R0 and the other two store the contents of R2, but that is easy to take care of, as we will see. The main point is that, aside from the small nuisance of which register is being used for the source of the STI instruction, the four program fragments do exactly the same thing, and it is wasteful to require the programmer to write the code four times. The subroutine call/return mechanism enables the programmer to write the code only once.

3. The call/return mechanism allows us to execute this one three-instruction sequence multiple times by requiring us to include it as a subroutine in our program only once. Figure 8.2 shows the instruction execution ﬂow for a program with and without subroutines. Note in Figure 8.2 that without subroutines, the programmer has to provide the same code A after X, after Y, and after Z. With subroutines, the programmer has to provide the code A only once. The programmer uses the call/return mechanism to direct the computer each time via the call instruction to the code A, and after the computer has executed the code A, to the return instruction to the proper next instruction to be executed in the program. 

4. We refer to the program that contains the call as the caller, and the subroutine that contains the return as the callee.

5. how many instructions does the call/return mechanism consist of? two instructions

6. what is the first instruction? JSR(R) in the caller program

7. what does the JSR(R) instruction do? it loads the PC with the starting address of the subroutine and it loads R7 with the address immediately after the address of the JSR(R) instruction. the address immediately after the address of the JSR(R) instruction is the address to come back to after executing the subroutine

8. what name is given to the address we come back to immediately after execution of a subroutine? return linkage

9. what is the second instruction of the call/return mechanism? JMP R7; which happens to be the last instruction in the subroutine (i.e., in the callee program).

10. what does this instruction do? it loads the PC with the contents of R7, the address just after the address of the JSR instruction thereby completing the round trip flow of control from the caller to the callee and back

11. the LC-3 specifies one control instruction for calling subroutines; what is it called? JSR(R); its opcode is 0100. 

12. how many addressing modes does the JSR(R) control instruction have for computing the starting address of a subroutine? 2

13. what are the addressing modes? PC-relative addressing and base register addressing

14. how many mnemonic names for the opcode are provided by the lc-3 assembly language? JSR and JSR(R); which one is used depends on the addressing mode in question

15. what are the two things that the JSR(R) instruction does? loads the PC hence overwriting the incremented PC that was loaded during the fetch phase of the JSR(R) instruction. In this case the starting address of the subroutine is computed and loaded into the PC. The second thing the JSR(R) instruction does is it saves the return address in R7

16. what is the return address that is saved in R7? it is the incremented PC which is the address of the instruction following the JSR(R) instruction

17. how many parts does the JSR(R) instruction consist of? 3 parts

18. what are the 3 parts? bits 15:12 specify the opcode (0100); bit 11 specifies what addressing mode will be used to obtain the starting address of the subroutine (1 for PC-relative); bits 10:0 are the address evaluation bits

19. how does the JSR instruction compute the target address of a subroutine? by sign-extending the 11 bit offset (bits 10:0) of the instruction to 16 bits and adding it to the incremented PC. almost identical to the addressing mode of the BR instruction, except eleven bits of PCoﬀset are used, rather than nine bits as is the case for BR.

If the following JSR instruction is stored in location x4200, its execution will cause the PC to be loaded with x3E05 (i.e., xFC04 + x4201) and R7 to be loaded with x4201.

15   14   13   12    11    10   9    8    7    6    5    4    3    2    1    0
0     1   0    0  |  1  |  1    0    0    0    0    0    0    0    1    0    0
     JSRR            A                        PCoﬀset1

20. how does the JSRR instruction differ from the JSR instruction? the addressing mode used;  it obtains the starting address of a subroutine in exactly the same way that the JMP instruction  does i.e. bits 8:6 identify the base register that contains the address to be loaded into the PC

If the following JSRR instruction is stored in location x420A, and if R5 contains x3002, the execution of the JSRR will cause R7 to be loaded with x420B and the PC to be loaded with x3002.

15   14   13   12    11    10   9     8    7    6     5    4    3    2    1    0
0     1   0    0  |  0  |  0    0  |  1    0    1  |  0    0    0    0    0    0
     JSRR            A                   BaseR

What important feature does the JSRR instruction provide that the JSR instruction does not provide? allowing the subroutine (target) address to be anywhere in memory, as it specifies a register that holds the starting address of the subroutine

21. We have known for a long time that every time an instruction loads a value into a register, the value that was previously in that register is lost. Thus, we need to save the value in a register

if that value will be destroyed by some subsequent instruction, and
if we will need it after that subsequent instruction.

22. what problems do subroutines pose when it comes to registers? they overwrite the contents of a register and therefore if the contents that were overwritten are needed by the caller program then you have a major problem at hand

23. Let’s examine again the piece of code in Figure 8.1. Suppose this piece of code is a subroutine called by the instruction JSR START in some caller program, which we will call CALLER. Suppose before CALLER executes JSR START, it computes values that it loads into R1, R2, and R3. In our subroutine starting at START, the instruction on line 05 loads a value into R2, the instruction on line 06 loads a value into R3, and the instruction on line 0A loads a value into R1. What would happen if CALLER needed those values after returning from the subroutine that begins at START? Too bad! Since the subroutine destroyed the values in R1, R2, and R3 by executing the instructions in lines 05, 06, and 0A, those values are lost to CALLER when it resumes execution after the JMP R7 instruction on line 20 of the subroutine. Of course, this is unacceptable.

24. We prevent it from happening during the ﬁrst part of our subroutine, that is, during initialization. In lines 01, 02, and 03, the contents of R1, R2, and R3 are stored in memory locations SaveR1, SaveR2, and SaveR3. Three locations in the subroutine (lines 22, 23, and 24) have been set aside for the purpose of saving those register values. And, in lines 1D, 1E, and 1F (just before the JMP R7 instruction), the values stored there are put back into R1, R2, and R3. That is, before the subroutine uses R1, R2, and R3 for its own use, the subroutine saves the values put there by the calling program. And, before the subroutine returns to the calling program, those values are put back (i.e., restored) where the calling program has a right to expect them.

25. what do we call this technique? callee save because the subroutine (i.e., the callee) saves and restores the registers. It makes sense to have the subroutine save the registers because the subroutine knows which registers it needs to do the work of the subroutine. There really is no reason to burden the person writing the caller program to know which registers the subroutine needs.

26. how else could the above problem be avoided? by having have the caller program save the contents of the registers it is using before it invokes a subroutine (i.e. before JSR START) and restore the contents when the subroutine has finished executing. Some programs do that, and in fact, some ISAs have JSR instructions that do that as part of the execution of the JSR instruction.

27. of the two options, which is more efficient? having the callee program (the subroutine) save the contents of the registers is more efficient because it knows which registers it will overwrite. The caller program has no way of knowing this in advance.

28. We should also point out that since JMP START loads the return linkage in R7, whatever was in R7 is destroyed by the execution of the JMP START instruction. Therefore, if the calling program had stored a value in R7 before calling the subroutine at START, and it needed that value after returning from the subroutine, the caller program would have to save and restore R7. 

29. is the caller program or the callee program responsible for saving and restoring the contents of R7? the caller is responsible since it alone is capable of overwriting the value in R7 after the subroutine returns. We save a register value by storing it in memory; we restore it by loading it back into the register.

30. what do we call the above process? caller save

31. what are some of the uses of the call/return mechanism expanded on above? ability of a user program to call library routines that are part of the OS. Libraries are provided as a convenience to the user programmer. They are legitimately advertised as productivity enhancers since they allow the application programmer to use them without having to know or learn much of their inner details. Figure 8.6 illustrates the process of combining multiple modules at link time to produce an executable image

32. can the stack (abstract data type), be implemented in many different ways? yes

33. what makes a stack special? a stack has nothing to do with how it is implemented. The concept of a stack is the speciﬁcation of how it is to be accessed; LIFO i.e. the last thing that you stored in a stack is the first thing that you remove from it

34. the stack is an example of an abstract data type. what is the definition of an abstract data type? a storage mechanism that is defined by the operations performed on it and not by the specific manner in which it is implemented

35. There are special terms for the insertion and removal of elements from a stack. We say we push an element onto the stack when we insert it. We say we pop an element from the stack when we remove it.

36. how is a stack implemented in computer memory? the most common implementation of a stack in a computer is as shown in Figure 8.9. it consists of a sequence of memory locations along with a mechanism called a stack pointer which keeps track of the top of the stack. We use R6 to contain the address of the top of the stack. That is, in the LC-3, R6 is the stack pointer.

37. In Figure 8.9, ﬁve memory locations (x3FFF to x3FFB) are provided for the stack. The actual locations comprising the stack at any single instant of time are the consecutive locations from x3FFF to the location speciﬁed in R6, that is, the top of the stack. For example, in Figure 8.9c, the stack consists of the contents of locations x3FFF, x3FFE, x3FFD, and x3FFC.

38. Figure 8.9a shows an initially empty stack. Since there are no values on the stack, the stack pointer contains the address x4000, the address of the memory location just after the memory locations reserved for the stack. Why this makes sense will be clear after we show the actual code for pushing values onto and popping values off of the stack. Figure 8.9b shows the stack after pushing the value 18. Note that the stack pointer contains the address x3FFF, which is the new top of the stack.

39. Figure 8.9c shows the stack after pushing the values 31, 5, and 12, in that order. Note that the values inserted into the stack are stored in memory loca- tions having decreasing addresses. We say the stack grows toward zero. Finally, Figure 8.9d shows the stack after popping the top two elements oﬀ the stack. Note that those two elements (the values 5 and 12) that were popped are still present in memory locations x3FFD and x3FFC. However, as we will see momentarily, those values 5 and 12 cannot be accessed from memory, as long as every access to memory is controlled by the stack mechanism.

40. when values are pushed and popped to and from a stack implemented in sequential memory locations, the data already stored on the stack does not physically move.

41. how are values inserted into the stack stored? they are stored in memory locations having decreasing addresses i.e. the stack grows towards zero.

42. what operations are used to push a value onto the stack? We push a value onto the stack by executing the two-instruction sequence:

PUSH      ADD       R6,R6,#-1
          STR       R0,R6,#0

43. In Figure 8.9a, R6 contains x4000, indicating that the stack is empty. To push the value 18 onto the stack, we decrement R6, the stack pointer, so the address in R6 (i.e., address x3FFF) corresponds to the location where we want to store the value we are pushing onto the stack. The actual push is done by ﬁrst loading 18 into R0, and then executing STR R0,R6,#0. This stores the contents of R0 into memory location x3FFF.

44. summarise the process of pushing a value onto a stackin the LC-3: first load the value into R0, then decrement the value in R6 (which contained the previous top of the stack). Then we execute STR R0,R6,#0, which stores the contents of R0 into the memory location whose address is in R6.

45. what operations are used to pop a value from the stack? the value is read and the stack pointer is incremented. The following two-instruction sequence

POP       LDR       R0,R6,#0
          ADD       R6,R6,#1

pops the value contained in the top of the stack and loads it into R0. The stack pointer (R6) is incremented to indicate that the old value at the top of the stack has been popped and is no longer on the stack, and we have a new value at the top of the stack.

46. If the stack were as shown in Figure 8.9c and we executed the sequence twice, we would pop two values from the stack. In this case, we would ﬁrst remove the 12, and then the 5. Assuming the purpose of popping two values is to use those two values, we would, of course, have to move the 12 from R0 to some other location before calling POP a second time.

47. Note that after 12 and 5 are popped, R6 contains x3FFE, indicating that 12 and 5 are no longer on the stack and that the top of the stack is 31. Figure 8.9d shows the stack after that sequence of operations. Note that the values 12 and 5 are still stored in memory locations x3FFD and x3FFC, respectively. However, since the stack requires that we push by executing the PUSH sequence and pop by executing the POP sequence, we cannot read the values 12 and 5 if we obey the rules. The fancy name for “the rules” is the stack protocol.

48. what is the fancy name given to the rules that the stack follows? stack protocol

49. What happens if we now attempt to pop three values from the stack? Since only two values remain on the stack, we would have a problem. Attempting to pop items that have not been previously pushed results in an underﬂow situation.

50. In our example, we can test for underﬂow by comparing the stack pointer with x4000, which would be the contents of R6 if there were nothing left on the stack to pop. If UNDERFLOW is the label of a routine that handles the underﬂow condition, our resulting POP sequence would be

POP     LD     R1,EMPTY
        ADD    R2,R6,R1   ;  Compare  stack
        BRz    UNDERFLOW  ; pointer with x4000
;
        LDR    R0,R6,#0
        ADD    R6,R6,#1
;
        RET
EMPTY   .FILL  xC000      ;  EMPTY  <--  negative  of  x4000

51. Rather than have the POP routine immediately jump to the UNDERFLOW routine if the POP is unsuccessful, it is often useful to have the POP routine return to the calling program with the underﬂow information contained in a register. We will use R5 to provide success/failure information. Figure 8.10 is a ﬂowchart showing how the POP routine could be augmented, using R5 to report this success/failure information.

52. Upon return from the POP routine, the calling program would examine R5 to determine whether the POP completed successfully (R5 = 0), or not (R5 = 1).

53. Note that since the POP routine reports success or failure in R5, whatever was stored in R5 before the POP routine was called is lost. Thus, it is the job of the calling program to save the contents of R5 before the JSR instruction is executed if the value stored there will be needed later. This is an example of a caller-save situation.

54. The resulting POP routine is shown in the following instruction sequence.

POP      AND    R5,R5,#0
         LD     R1,EMPTY
         ADD    R2,R6,R1
         BRz    Failure
         LDR    R0,R6,#0
         ADD    R6,R6,#1
         RET
Failure  ADD    R5,R5,#1
         RET
EMPTY    .FILL  xC000            ;  EMPTY  <--- x4000

55. What happens when we run out of available space and we try to push a value onto the stack? Since we cannot store values where there is no space, we have an overﬂow situation. We can test for overﬂow by comparing the stack pointer with (in the example of Figure 8.9) x3FFB. If they are equal, we have no place to push another value onto the stack. If OVERFLOW is the label of a routine that handles the overﬂow condition, our resulting PUSH sequence would be

PUSH      LD      R1,MAX
          ADD     R2,R6,R1
          BRz     OVERFLOW
;
          ADD     R6,R6,#-1
          STR     R0,R6,#0
;
          RET
MAX       .FILL   xC005        ; MAX  <-- negative of x3FFB

56. In the same way that it is useful to have the POP routine return to the calling program with success/failure information, rather than immediately jumping to the UNDERFLOW routine, it is useful to have the PUSH routine act similarly. We augment the PUSH routine with instructions to store 0 (success) or 1 (failure) in R5, depending on whether or not the push completed success- fully. Upon return from the PUSH routine, the calling program would examine R5 to determine whether the PUSH completed successfully (R5 = 0) or not (R5 = 1).

57. Note again that since the PUSH routine reports success or failure in R5, we have another example of a caller-save situation. That is, since whatever was stored in R5 before the PUSH routine was called is lost, it is the job of the calling program to save the contents of R5 before the JSR instruction is executed if the value stored in R5 will be needed later.

58. The resulting PUSH routine is shown in the following instruction sequence

PUSH      AND     R5,R5,#0
          LD      R1,MAX
          ADD     R2,R6,R1
          BRz     Failure
          ADD     R6,R6,#-1
          STR     R0,R6,#0
          RET
Failure   ADD     R5,R5,#1
          RET
MAX       .FILL   xC005      ;  MAX  <--- x3FFB

59. The POP and PUSH routines allow us to use memory locations x3FFF through x3FFB as a ﬁve-entry stack. If we wish to push a value onto the stack, we simply load that value into R0 and execute JSR PUSH. To pop a value from the stack into R0, we simply execute JSR POP. If we wish to change the location or the size of the stack, we adjust BASE and MAX accordingly

60. The subroutines PUSH and POP make use of R1 and R2, and there is no reason why the calling program would know that. Therefore, it is the job of the subroutine (callee save) to save R1 and R2 before using them, and to restore them before returning to the calling program. The PUSH and POP routines also write to R5. But, as we have already pointed out, the calling program knows that the subroutine will report success or failure in R5, so it is the job of the calling program to save R5 before executing the JSR instruction if the value stored in R5 will be needed later. The ﬁnal code for our PUSH and POP operations is shown in Figure 8.11.

61. what is recursion? a mechanism for expressing a function in terms of itself. when used appropriately, the expressive power of recursion is going to save a lot of headaches. when used whimsically, recursion is going to require unnecessary inactivity, resulting in longer execution time and wasted energy.

62. bad example of using factorial: The simplest example to illustrate recursion is the function factorial. n! = n * (n-1)! Assume the subroutine FACT (Factorial) is supplied with a positive integer n in R0 and returns with the value n! in R0. Figure 8.12 shows a pictorial view of the recursive subroutine. We represent the subroutine FACT as a hexagon, and inside the hexagon is another instance of the hexagon! We call the subroutine recursive because inside the FACT subroutine is an instruction JSR FACT. If we assume the LC-3 has a MUL instruction, the basic structure of the FACT subroutine takes the form shown in figure 8.12

63. The subroutine ﬁrst tests to see if n = 1. If so, we are done, since (1)! = 1. It is important to emphasize that every recursive subroutine must have such an initial test to see if we should execute the recursive call. Without this test, the subroutine would call itself (JSR FACT) an inﬁnite number of times! Clearly, that cannot be correct. The answer is to provide a test before the recursive JSR instruction. In the case of the subroutine FACT, if R0 is 1, we are done, since 1! = 1.

64. If n does not equal 1, we save the value in R1, so we can store n in R1, load R0 with n-1 and JSR FACT. When FACT returns with (n-1)! in R0, we multiply it by n (which was stored in R1), producing n!, which we load into R0, restore R1 to the value expected by the calling program, and RET.

FACT      ST       R1, Save1       ; Callee  save  R1
          ADD      R1,R0,#-1       ; Test  if  R0=1
          BRz      DONE            ; If  R0=1, R0 also contains (1)!, so we are done
          ADD      R1,R0,#0        ; Save n in R1, to be used after we compute (n-1)!
          ADD      R0,R1,#-1       ; Set R0 to n-1, and then call FACT
B         JSR      FACT            ; On RET, R0 will contain (n-1)!
          MUL      R0,R0,R1        ; Multiply n times (n-1)!, yielding n! in R0
DONE      LD       R1, Save1       ; Callee restore R1
          RET
Save1     .BLKW    1

65. Since the LC-3 does not have a MUL instruction, this will require another subroutine call, but we are ignoring that here in order to focus on the essence of recursion.

66. why will the above code not work? Figure 8.13 shows the ﬂow of instruction execution as we would like it to be. The main program calls the subroutine with a JSR instruction at address A. This causes the code labeled #1 to execute. At address B, the subroutine FACT calls itself with the instruction JSR FACT. This causes the code labeled #2 to execute, and so forth. When the main program executes the instruction JSR FACT, the return linkage A+1 is saved in R7. In the block of code labeled #1, the instruction at address B (JSR FACT) stores its return linkage B+1 in R7, destroying A+1, so there is no way to get back to the main program.

67. how can we solve this problem? by pushing the address A+1 onto a stack before executing JSR FACT at address B. After we subsequently return to address B+1, we can then pop the stack and load the address A+1 into R7 before we execute the instruction RET back to the main program.

68. what else is wrong with the assembly program in number 64? instruction ADD R1,R0,#0 in #1 loads the value n into R1, and in #2, the instruction ADD R1,R0,#0 loads the value n-1 into R1, thereby wiping out the value n that had been put there by the code in #1. Thus, when the instruction ﬂow gets back to #1, where the value n is needed by the instruction MUL R0,R0,R1, it is no longer there. It was previously wiped out. Again, very, very bad!

69. how can we solve this problem? instead of moving the value n to R1 before loading n-1 into R0, we push n onto the stack and then pop it when we need it after returning from the subroutine with (n-1)! in R0.

70. Finally, we note that the ﬁrst instruction in our subroutine saves R1 in Save1 and the last instruction before the RET restores it to R1. We do this so that from the standpoint of the calling program, the value in R1 before the subroutine is the same as the value in R1 after the subroutine, even though the subroutine used R1 in performing its job.

71. However, since our subroutine is recursive, when FACT is called by the JSR instruction at address B, R1 does not contain the value it had in the main program, but instead it has the value last stored in R1 by the ADD R1,R0,#0 instruction. Thus after the JSR FACT instruction is executed, the ﬁrst instruction of the recursively called subroutine FACT will save that value, wiping out the value that the main program had stored in R1 when it called FACT.

72. how can we solve this problem? using the stack; replace the ST R1,Save1 with a push and LD R1,Save1 with a pop. If we make these changes (and if the LC-3 had a MUL opcode), the recursive subroutine works as we would like it to. The resulting subroutine is shown in Figure 8.14

73. The main program calls FACT with R0 = n. The code in #1 executes, with JSR FACT being called with R0 = n-1. At this point, the stack contains the three entries pushed, as shown in Figure 8.15a. When the JSR FACT instruction in #3 executes, with R0 = n-3, the stack contains the nine entries as shown in Figure 8.15b.

74. The obvious question you should ask at this point is, “Why is this such a bad use of recursion, particularly when its representation n! =n*(n-1)! is so elegant?” To answer this question, we ﬁrst note how many instructions are executed and how much time is wasted pushing and popping elements oﬀ the stack. AND, the second question you should ask is, “Is there a better way to compute n!?”

75. Consider the alternative shown in Figure 8.16 (using iteration to compute factorial)

76. Fibonacci (an even worse example of when recursion is used): Another bad use of recursion is to evaluate the Fibonacci number FIB(n). The Fibonacci numbers are deﬁned for all non-negative integers as follows: FIB(0)=0, FIB(1)=1, and if n > 1, FIB(n) = FIB(n-1) + FIB(n-2). The expression is beautifully elegant, but the execution time is horrendous.
Figure 8.17 shows a pictorial view of the recursive subroutine FIB. Note that the subroutine FIB is represented as a “capital F,” and inside the capital F there are two more instances of the capital F.

77. The recursive subroutine in Figure 8.18 computes FIB(n). As with all recursive subroutines, we ﬁrst need to test for the base cases. In this case, we AND n with xFFFE, which produces a non-zero result for all n except n = 1 and n = 0. If n = 0 or 1, we are eﬀectively done. We move n into R1, restore R2, R0, and R7 (actually, only R2 needs to be restored), and return. If n is not 0 or 1, we need to recursively call FIB twice, once with argument n-1 and once with argument n-2. Finally we add FIB(n-1) to FIB(n-2), put the result in R1, restore R2, R0, and R7, and return.

78. Note that the recursive subroutine FIB(n) calls FIB twice: once for FIB(n-1) and once for FIB(n-2). FIB(n-1) must call FIB(n-2) and FIB(n-3), and FIB(n-2) must call FIB(n-3) and FIB(n-4). That means FIB(n-2) must be evaluated twice and FIB(n-3) will have to be evaluated three times.

79. Suppose n = 10. How many times must this recursive algorithm compute the same function FIB(5)?

80. Compare the recursive algorithm for Fibonacci (Figure 8.18) with a non-recursive algorithm, as shown in Figure 8.19. Much, much faster execution time!

81. what is the reason for shying away from using recursion to compute factorial or Fibonacci? the iterative algorithms are simple enough to understand without the horrendous execution time penalty of recursion.

82. However, it is important to point out that there are times when the expressive beauty of recursion is useful to attack a complicated problem. Such is the case with the following problem, involving a maze: Given a maze and a starting position within the maze, write a program that determines whether or not there is a way out of the maze from your starting position. A maze can be any size, n by m. For example, Figure 8.20 illustrates a 6x6 maze.

83. Each of the 36 cells of the maze can be characterized by whether there is a door to the north, east, south, or west, and whether there is a door from the cell to the outside world. Each cell is represented by one word of memory (Figure 8.21). The words are stored in what we call row major order; that is, row 1 is stored, then row 2, then row 3, etc. The complete speciﬁcation of the 6 by 6 maze is shown in Figure 8.22.

84. Our job is to develop an algorithm to determine whether we can exit a maze from a given starting position within the maze. With all the intricate paths that our attempts can take, keeping track of all that bookkeeping looks daunting. Recursion allows us to not have to keep track of the paths at all! Figure 8.23 shows a pictorial view of a recursive sub- routine FIND EXIT, an algorithm for determining whether or not we can exit the maze. Note that the subroutine FIND EXIT is shown as an octagon, and inside the octagon there are four more instances of octagons, indicating recursive calls to FIND EXIT. If we can exit the maze, we will return from the subroutine with R1=1; if not, we will return with R1=0.

85. The algorithm works as follows: In each cell, we ﬁrst ask if there is an exit from this cell to the outside world. If yes, we return the value 1 and return. If not, we ask whether we should try the cell to the north, the east, the south, or the west. In order to try a cell in any direction, clearly there must be a door to the cell in that direction. Furthermore, we want to be sure we do not end up in an inﬁnite loop where for example, there are doors that allow us to go north one cell, and from there east one cell, and from there south one cell, and from there west one cell, putting us right back where we started. To prevent situations like that from happening, we put a “breadcrumb” in each cell we visit, and we only go to a cell and JSR FIND EXIT if we have not visited that cell before.

86. Thus, our algorithm:

From our cell, we ask if we can exit. If yes, we are done. We exit with R1=1.

If not, we put a breadcrumb in our cell. Our breadcrumb is bit [15] of the word corresponding to our current cell. We set it to 1.

We ask two questions: Is there a door to the north, and have we never visited the cell to the north before? If the answer to both is yes, we set the address to the cell to the north, and invoke JSR FIND EXIT. We set the address to the cell to the north by simply subtracting 6 from the address of the current cell. Why 6? Because the cells are stored in row major order, and the number of columns in the maze is 6.

If the answer to either question is no, or if going north resulted in failure, we ask: Is there a door to the east, and have we never visited that cell before? If the answer to both is yes, we set the address to the address of the cell to the east (by adding 1 to the address) and invoke JSR FIND EXIT.

If going east does not get us out, we repeat the question for south, and if that does not work, then for west.

If we end up with no door to the west to a cell we have not visited, or if there is a door and we haven’t visited, but it results in failure, we are done. We cannot exit the maze from our starting position. We set R1=0 and return.

Figure 8.24 shows a recursive algorithm that determines if we can exit the maze, given our starting address.

87. what is the defining property of the abstract data type queue? FIFO which stands for first in, first out

88. what implications does this have in the context of the data structure? we need to keep track of two ends of the storage structure; a front pointer for removing elements from the front of the queue and a rear pointer for inserting into the rear of the queue.

89. Figure 8.25 shows a block of six sequential memory locations that have been allocated for storing elements in the queue. The queue grows from x8000 to x8005. We arbitrarily assign the FRONT pointer to the location just before the ﬁrst element of the queue. We assign the REAR pointer to the location containing the most recent element that was added to the queue. Let’s use R3 as our FRONT pointer and R4 as our REAR pointer.

90. Figure 8.25a shows a queue in which ﬁve values were entered into the queue. Since FRONT = x8001, the values 45 in memory location x8000 and 17 in x8001 must have been removed, and the front element of the queue is 23, the value contained in x8002.

91. Note that the values 45 and 17 are still contained in memory locations x8000 and x8001, even though they have been removed. Like the stack, studied already, that is the nature of load instructions. When a value is removed by means of a load instruction, what is stored in the memory location is not erased. The contents of the memory location is simply copied into the destination register. However, since FRONT contains the address x8001, there is no way to load from locations x8000 and x8001 as long as locations x8000 to x8005 behave like a queue—i.e., as long as the accesses are FIFO.

92. how do we remove an item of data from the front of a queue? since FRONT points to the location just in front of the ﬁrst element in the queue, we remove a value by ﬁrst incrementing FRONT and then loading the value stored at that incremented address. 

93. in our example, what is the next value to be removed? 23 which is at the front of the queue, in memory location x8002. 

94. what is the assembly code responsible for achieving this? 

ADD R3,R3,#1
LDR R0,R3,#0

yielding the structure in Figure 8.25b. Since REAR = x8004, the last value to enter the queue is 74. The values in the queue in Figure 8.25b are 2 and 74.

95. what assembly code is used to insert data into the queue? 

ADD       R4,R4,#1
STR       R0,R4,#0

resulting in Figure 8.25c.

96. what is wrap around? where we allow the available storage locations in a queue to wrap around. For example, suppose we want to add 20 to the queue. Since there is nothing stored in x8000 (recall 45 had been previously removed), we can store 20 in x8000. The result is shown in Figure 8.25d.

97. how does wrap around work? by having the removal and insertion algorithms test the contents of FRONT and REAR for the value x8005. If we wish to insert, and REAR contains x8005, we know we have reached the end of our available storage and we must see if x8000 is available. If we wish to remove, we must ﬁrst see if FRONT contains the address x8005. If it does, the front of the queue is in x8000.

98. what implication does this have on the code to remove or insert data in the queue? both routines must include a test for wrap around. the code for remove is shown below

          LD       R2, LAST
          ADD      R2, R3, R2
          BRnp     SKIP_1
          LD       R3,FIRST
          BR       SKIP_2
SKIP_1    ADD      R3,R3,#1
SKIP_2    LDR      R0,R3,#0  ; R0 gets the front of the queue
          RET
LAST      .FILL    x7FFB     ; LAST contains the negative of 8005
FIRST     .FILL    x8000

99. The code for insert is similar. If REAR contains x8005, we need to set R4 to x8000 before we can insert an element at the rear of the queue. The code to insert is as follows:

          LD       R2, LAST
          ADD      R2,R4,R2
          BRnp     SKIP_1
          LD       R4,FIRST
          BR       SKIP_2
SKIP_1    ADD      R4,R4,#1
SKIP_2    STR      R0,R4,#0  ; R0 gets the front of the queue
          RET
LAST      .FILL    x7FFB     ; LAST contains the negative of 8005
FIRST     .FILL    x8000

100. How Many Elements Can We Store in a Queue? Let’s look again at Figure 8.25d. There are four values in the queue: 2, 74, 10, and 20. Suppose we insert 30 and 40 at the rear of the queue, producing Figure 8.25e. Both R3 and R4 contain the same address (x8002), and the queue is full. Now suppose we start removing elements from the front of the queue. If we remove 2, which is at the front of the queue, R3 will contain the address x8003. If we remove the remaining ﬁve elements in the queue, we will have what is shown in Figure 8.25f. Note that the FRONT and REAR pointers for e and f are identi- cal, yet Figure 8.25e describes a full queue and Figure 8.25f describes an empty queue! Clearly that is not acceptable.

101. how do we prevent this from happening? allow a queue to store only n-1 elements if space for n ele- ments has been allocated. That is, if inserting an nth element into the queue would cause FRONT to equal REAR, we do not allow that insertion. We declare the queue full when there are n-1 elements in the queue.

102. Let’s look again at the queue in Figure 8.25d. There are four elements in the queue, from front to rear: 2, 74, 10, and 20, and two empty slots, x8001 and x8002. We can insert 30 in x8001, producing Figure 8.26a. That is, 30 is the ﬁfth element inserted in the queue. Since six words have been allocated for the queue, and we now have ﬁve elements in the queue, we declare the queue full and do not allow a sixth element to be inserted. 

103. Suppose we now start removing elements from the queue until the queue is empty, as shown in Figure 8.26b. Now there is no ambiguity between a full and an empty queue since if the queue is empty, FRONT = REAR.

104. testing for underflow and overflow in queues: As was the case with the stack, we can only remove an element from a queue if there are elements in the queue. Likewise, we can only insert elements in the queue if it is not full. If the queue is empty and we try to remove an element, we have an underﬂow condition. If the queue is full and we try to insert an element, we have an overﬂow condition. In both cases, if we are using a subroutine to manage the queue, we need to report success or failure to the calling program. As with the stack, we will use R5 for this purpose.

105. The test for underﬂow is straightforward. We saw from Figure 8.26 b that if FRONT = REAR, the queue is empty. Our code to test for underﬂow is therefore

               AND       R5,R5,#0    ;  Initialize  R5  to  0
               NOT       R2,R3
               ADD       R2,R2,#1    ;  R2 contains negative of R3
               ADD       R2,R2,R4
               BRz       UNDERFLOW
               ; code to remove the front of the queue and return success.
UNDERFLOW      ADD       R5,R5,#1
               RET

That is, we ﬁrst check to see if the queue is empty, that is, if R3 = R4. If so, we branch to UNDERFLOW, where we set R5 to failure, restore R1, and return. If not, carry out the code to remove the front of the queue.

106. The test for overﬂow is similar. To insert an element to the back of the queue, we ﬁrst increment the REAR pointer. If that causes FRONT = REAR, then the queue already contains n-1 elements, which means it is full so we can- not insert any more elements. We decrement the REAR pointer, set R5 to 1, and return.

107. We conclude our attention to queues with a subroutine that allows elements to be removed from the front or inserted into the rear of the queue, wraps around when one of the pointers reaches the last element, and returns with a report of success (R5 = 0) or failure (R5 = 1) depending on whether the access succeeds or the access fails due to an underﬂow or overﬂow condition. To make this concrete, we will tie this subroutine to the queue of Figure 8.25, where we have allocated locations x8000 to x8005 for our queue, x8000 being the FIRST location and x8005 being the LAST location.

108. To insert, we ﬁrst have to make sure the queue is not full. To do that, we increment the REAR pointer (R4) and then test REAR=FRONT. If the REAR pointer was initially x8005, we increment REAR by setting it to x8000; that is, we need to wrap around. If the queue is full, we need to set REAR back to its original value, and return, reporting failure (R5 = 1). If the queue is not full, we store the item we wish to insert (which is in R0) in REAR, and return, reporting success (R5 = 0).

109. To remove, we ﬁrst make sure the queue is not empty by testing whether REAR=FRONT. If REAR=FRONT, the queue is empty, so we return, reporting failure. If REAR is not the same as FRONT, the queue is not empty, so we can remove the front element. To do this, we ﬁrst test to see if FRONT=x8005. If it is, we set FRONT=x8000. If it isn’t, we increment FRONT. In both cases, we then load the value from that memory location into R0, and return, reporting success.

110. Figure 8.27 shows the complete subroutine.

111. ﬁnal data structure: the character string. It is a sequence of keyboard characters (letters, digits, and other symbols) is organized as a one-dimensional array of ASCII codes, usually representing a person’s name, address, or some other alphanumeric string. Figure 8.28 shows a character string representing the name of the famous late Stanford professor Bill Linvill, stored in 13 consecutive words of memory, starting at location x5000. The ASCII code for each letter of his name is stored in a separate word of memory. Since an ASCII code consists of one byte of memory, we add a leading x00 to each location. For example, x5000 contains x0042 since the ASCII code for a capital B is x42. We need 13 memory locations, one word for each of the 11 letters in his name, one word for the ASCII code x20 representing the space between his ﬁrst and last names, and ﬁnally the null character x0000 to indicate that we have reached the end of the character string. Diﬀerent alphanumeric strings require character strings of diﬀerent lengths, but that is no problem since we allocate as many words of memory as are needed, followed by the null character x0000 to indicate the end of the character string.

112. Figure 8.30 is a subroutine that compares two character strings to see if they are identical.

113. Another Example: A Character String Representing an “Integer.” We can also represent arbitrarily long integers by means of character strings. For example, Figure 8.31 is a character string representing the integer 79,245. Figure 8.32 is a subroutine that examines such a character string to be sure that in fact all ASCII codes represent decimal digits. If all the entries in the character string are ASCII codes of decimal digits (between x30 and x39), the subroutine returns success (R = 0). If not, the subroutine returns failure (R5 = 1).

chapter 9

1. up to now, we have completely ignored the details of input and output, that is how the computer actually gets information from the keyboard, and how the computer actually delivers information to the monitor. 

2. what have we relied on to accomplish both tasks? the TRAP instruction (e.g., TRAP x23 for input and TRAP x21 for output) to accomplish these tasks. The TRAP instruction enables us to tell the operating system what we need done by means of a trap vector, and we trust the operating system to do it for us.

3. what is the more generic term for the TRAP instruction? system call because the TRAP instruction is calling on the operating system to do something for us while allowing us to remain completely clueless as to how it gets done.

4. what is this chapter going to examine? how input and output actually work in the LC-3, what happens when the user program makes a system call by invoking the TRAP instruction, and how it all works under the control of the operating system. We will start with the actual physical structures that are required to cause input and output to occur.

5. But before we do that, it is useful to say a few words about the operating system and understand a few basic concepts that have not been important so far but become very important when considering what the operating system needs to do its job.

6. All OS's have the same goal: to optimize the use of all the resources of the computer system while making sure that no software does harmful things to any program or data that it has no right to mess with. To better understand their job, we need to understand the notions of privilege and priority and the layout of the memory address space (i.e., the regions of memory and the purpose of each).

7. what is privilege all about? all about the right to do something, such as execute a particular instruction or access a particular memory location. Not all computer programs have the right to execute all instructions. For example, if a computer system is shared among many users and the ISA contains a HALT instruction, we would not want any random program to execute that HALT instruction and stop the computer. If we did, we would have some pretty disgruntled users on our hands.

8. Similarly, some memory locations are only available to the operating system. We would not want some random program to interfere with the data structures or code that is part of the operating system, which would in all likelihood cause the entire system to crash. 

9. what can we do to make sure neither of these two events occur? designate every computer program as either privileged or unprivileged. We often say supervisor privilege to indicate privileged. We say a program is executing in Supervisor mode to indicate privileged, or User mode to indicate unprivileged. If a program is executing in Supervisor mode, it can execute all instructions and access all of memory. If a program is executing in User mode, it cannot. If a program executing in User mode tries to execute an instruction or access a memory location that requires being in Supervisor mode, the computer will not allow it.

10. what is priority all about? about the urgency of a program to execute. Every program is assigned a priority, specifying its urgency as compared to all other programs. This allows programs of greater urgency to interrupt programs of lesser urgency.

11. why are privilege and priority said to be orthogonal? they have nothing to do with each other

12. a computer program can have supervisor privilege but low priority because it has lower urgency than other programs that need access to the computer system immediately. likewise, a computer program can have user privilege and higher priority due to its pressing need to use computer resources to execute a task.

13. each program executing on the computer has associated with it two very important registers. what are they? the program counter (PC), which you are already familiar with, and the processor status register (PSR) which is shown in figure 9.1

14. what does the PSR contain? the privilege and priority assigned to a program; Bit [15] speciﬁes the privilege, where PSR[15]=0 means supervisor privilege, and PSR[15]=1 means unprivileged. Bits [10:8] specify the priority level (PL) of the program. The highest priority level is 7 (PL7), the lowest is PL0.

15. what else does the PSR contain? the current values of the condition codes

16. Figure 9.2 shows the layout of the LC-3 memory. You know that the LC-3 has a 16-bit address space; ergo, memory locations from x0000 to xFFFF. Locations x0000 to x2FFF are privileged memory locations. They contain the various data structures and code of the operating system. They require supervisor privilege to access. what are they referred to as? system space.

18. Locations x3000 to xFDFF are unprivileged memory locations. Supervisor privilege is not required to access these memory locations. All user programs and data use this region of memory. What is this region referred to as? user space

19. Addresses xFE00 to xFFFF do not correspond to memory locations at all. what does this mean for the last address of memory location? the last address of a memory location is xFDFF. 

20. what are addresses xFE00 to xFFFF used for? to identify registers that take part in input and output functions and some special registers associated with the processor. For example, the PSR is assigned address xFFFC, and the processor’s Master Control Register (MCR) is assigned address xFFFE. 

21. what are the set of addresses from xFE00 to xFFFF is usually referred to as? I/O page since most of the addresses are used for identifying registers that take part in input or output functions. Access to those registers requires supervisor privilege.

22. Finally, note that Figure 9.2 shows two stacks, a supervisor stack in system space and a user stack in user space. The supervisor stack is controlled by the operating system and requires supervisor privilege to access. The user stack is controlled by the user program and does not require privilege to access.

23. Each has a stack pointer, Supervisor Stack Pointer (SSP) and User Stack Pointer (USP), to indicate the top of the stack. Since a program can only execute in Supervisor mode or User mode at any one time, only one of the two stacks is active at any one time. Register 6 is generally used as the stack pointer (SP) for the active stack. Two registers, Saved SSP and Saved USP, are provided to save the SP not in use. When privilege changes, for example, from Supervisor mode to User mode, the SP is stored in Saved SSP, and the SP is loaded from Saved USP.

24. Input and output devices (keyboards, monitors, disks, or kiosks at the shopping mall) all handle input or output data using registers that are tailored to the needs of each particular input or output device. Even the simplest I/O devices usually need at least two registers: one to hold the data being transferred between the device and the computer, and one to indicate status information about the device.

25. what is an example of status information? is whether the device is available or is it still busy processing the most recent I/O task.

26. An instruction that interacts with an input or output device register must identify the particular input or output device register with which it is interacting. 

27. Two schemes have been used in the past to facilitate input and output functionality. what are they? some computers use special input and output instructions. Most computers prefer to use the same data movement instructions that are used to move data in and out of memory.

28. The very old PDP-8 (from Digital Equipment Corporation, more than 50 years ago—1965) is an example of a computer that used special input and output instructions. The 12-bit PDP-8 instruction contained a three-bit opcode. If the opcode was 110, an I/O instruction was indicated. The remaining nine bits of the PDP-8 instruction identiﬁed which I/O device register and what operation was to be performed.

29. Most computer designers prefer not to specify an additional set of instructions for dealing with input and output. They use the same data movement instructions that are used for loading and storing data between memory and the general purpose registers. For example, a load instruction (LD, LDI, or LDR), in which the source address is that of an input device register, is an input instruction. Similarly, a store instruction (ST, STI, or STR) in which the destination address is that of an output device register is an output instruction.

30. what implication does this have in the way input or output device registers are specified in the data movement instructions? since programmers use the same data movement instructions that are used for memory, every input device register and every output device register must be uniquely identiﬁed in the same way that memory locations are uniquely identiﬁed. Therefore, each device register is assigned an address from the memory address space of the ISA. That is, the I/O device registers are mapped to a set of addresses that are allocated to I/O device registers rather than to memory locations.

31. what is this described as? memory-mapped I/O.

32. The original PDP-11 ISA had a 16-bit address space. All addresses wherein bits [15:13] = 111 were allocated to I/O device registers. That is, of the 2^(16) addresses, only 57,344 corresponded to memory locations. The remaining 2^(13) were memory-mapped I/O addresses.

33. The LC-3 uses memory-mapped I/O. As discussed prior, Addresses xFE00 to xFFFF are reserved for input/output device registers. Table A.3 lists the memory-mapped addresses of the LC-3 device registers that have been assigned so far.

34. Most I/O is carried out at speeds very much slower than the speed of the processor. A typist, typing on a keyboard, loads an input device register with one ASCII code every time he/she types a character. A cpu can read the contents of that device register every time it executes a load instruction, where the operand address is the memory-mapped address of that input device register.

35. Many of today’s microprocessors execute instructions under the control of a clock that operates well in excess of 2 GHz. Even for a microprocessor operating at only 2 GHz, a clock cycle lasts only 0.5 nanoseconds. Suppose a processor executed one instruction at a time, and it took the processor ten clock cycles to execute the instruction that reads the input device register and stores its contents. At that rate, the processor could read the contents of the input device register once every 5 nanoseconds. Unfortunately, people do not type fast enough to keep this processor busy full-time reading characters.

36. How fast would a person have to type to supply input characters to the processor at the maximum rate the processor can receive them? 2 hundred million characters (keystrokes) per second 

37. how could this speed disparity be mitigated? For example, we could design a piece of hardware that accepts one character every 200 million cycles. This would require a typing speed of 100 words/minute, assuming words on average consisted of ﬁve letters, which is certainly doable. 

38. what is the draw back of this method? it would require that the typist work in lockstep with the computer’s clock. That is not acceptable since the typing speed (even of the same typist) varies from moment to moment.

39. the discussion immediately above is to highlight that I/O devices usually operate at speeds very different from that of a micro processor, and not in lock step. what do we call this characteristic? asynchronous

40. Most interaction between a processor and I/O is asynchronous. To control processing in an asynchronous world requires some protocol or handshaking mechanism. So it is with our keyboard and monitor. In the case of the keyboard, we will need a one-bit status register, called a ﬂag, to indicate if someone has or has not typed a character. In the case of the monitor, we will need a one-bit status register to indicate whether or not the most recent character sent to the monitor has been displayed, and so the monitor can be given another character to display.

41. These ﬂags are the simplest form of synchronization. A single ﬂag, called the ready bit, is enough to synchronize the output of the typist who can type characters at the rate of 100 words/minute with the input to a processor that can accept these characters at the rate of 200 million characters/second. Each time the typist types a character, the ready bit is set to 1. Each time the computer reads a character, it clears the ready bit. By examining the ready bit before reading a character, the computer can tell whether it has already read the last character typed. If the ready bit is clear, no characters have been typed since the last time the computer read a character, and so no additional read would take place. When the computer detects that the ready bit is set, it could only have been caused by a new character being typed, so the computer would know to again read a character.

42. The single ready bit provides enough handshaking to ensure that the asynchronous transfer of information between the typist and the microprocessor can be carried out accurately.

43. If the typist could type at a constant speed, and we did have a piece of hardware that would accept typed characters at precise intervals (e.g., one character every 200 million cycles), then we would not need the ready bit. The computer would simply know, after 200 million cycles of doing other stuﬀ, that the typist had typed exactly one more character, and the computer would read that character. In this hypothetical situation, the typist would be typing in lockstep with the processor, and no additional synchronization would be needed. We would say the computer and typist were operating synchronously. That is, the input activity was synchronous.

44. describe the difference between interrupt-driven vs. polling architectures: this is about who controls the interaction between the processor, which is computing, and the typist, who is typing. The two are separate entities; where each is doing their own activity. However, they need to interact i.e. the data that is typed has to be transimitted to the cpu. Does the processor do its own thing until being interrupted by an announcement from the keyboard, “Hey, a key has been struck. The ASCII code is in the input device register. You need to read it.” This is called interrupt-driven I/O, where the keyboard controls the interaction. Or, does the processor control the interaction, specifically by interrogating (usually, again and again) the ready bit until it (the processor) detects that the ready bit is set. At that point, the processor knows it is time to read the device register. This second type of interaction when the processor is in charge is called polling, since the ready bit is polled by the processor, asking if any key has been struck.

45. what two things do we need in order to handle input character from the keyboard? a data register that contains the character to be input and a synchronisation mechanism to let the processor know that input has occurred. the synchronisation mechanism is contained in the status register associated with the keyboard.

46. what are these two registers called? keyboard data register (KBDR) and the keyboard status register (KBSR). They are assigned addresses from the memory address space. As shown in Table A.3, address xFE02 is assigned to the KBDR; address xFE00 is assigned to the KBSR.

49. Figure 9.3 shows the two device registers needed by the keyboard. Even though a character needs only 8 bits and the synchronization mechanism needs only 1 bit, it is easier to assign 16 bits (like all memory addresses in the LC-3) to each. In the case of KBDR, bits [7:0] are used for the data, and bits [15:8] contain x00. In the case of KBSR, bit [15] contains the synchronization mechanism, that is, the ready bit.

50. how does the input service routine for the keyboard work? KBSR[15] controls the synchronization of the slow keyboard and the fast processor. When a key on the keyboard is struck, the ASCII code for that key is loaded into KBDR[7:0], and the electronic circuits associated with the keyboard automatically set KBSR[15] to 1. When the LC-3 reads KBDR, the electronic circuits associated with the keyboard automatically clear KBSR[15], allowing another key to be struck. 

51. If KBSR[15] = 1, the ASCII code corresponding to the last key struck has not yet been read, and so the keyboard is disabled; that is, no key can be struck until the last key is read.

52. what happens if input/output from the keyboard is controlled by the processor via polling? then a program can repeatedly test KBSR[15] until it notes that the bit is set. At that point, the processor can load the ASCII code contained in KBDR into one of the LC-3 registers. Since the processor only loads the ASCII code if KBSR[15] is 1, there is no danger of reading a single typed character multiple times. Furthermore, since the keyboard is disabled until the previous code is read, there is no danger of the processor missing characters that were typed. In this way, KBSR[15] provides the mechanism to guarantee that each key typed will be loaded exactly once.

53. The following input routine loads R0 with the ASCII code that has been entered through the keyboard and then moves on to the NEXT TASK in the program.

START     LDI      R1, A           ; Test for bit indicating input has occurred
          BRzp     START           ; if negative value i.e. bit 15 is on, then proceed otherwise repeat check
          LDI      R0, B
          BRnzp    NEXT_TASK       
A         .FILL    xFE00           ; Address of KBSR
B         .FILL    xFE02           ; Address of KBDR

54. As long as KBSR[15] is 0, no key has been struck since the last time the processor read the data register. Lines 01 and 02 comprise a loop that tests bit [15] of KBSR. Note the use of the LDI instruction, which loads R1 with the contents of xFE00, the memory-mapped address of KBSR. If the ready bit, bit [15], is clear, BRzp will branch to START and another iteration of the loop. When someone strikes a key, KBDR will be loaded with the ASCII code of that key, and the ready bit of KBSR will be set. This will cause the branch to fall through, and the instruction at line 03 will be executed. Again, note the use of the LDI instruction, which this time loads R0 with the contents of xFE02, the memory-mapped address of KBDR. The input routine is now done, so the program branches unconditionally to its NEXT TASK.

55. Figure 9.4 shows the additional data path required to implement memory-mapped input. You are already familiar, from Chapter 5, with the data path required to carry out the EXECUTE phase of the load instructions. Essentially three steps are required:

a. The MAR is loaded with the address of the memory location to be read.
b. Memory is read, resulting in MDR being loaded with the contents at the speciﬁed memory location.
c. The destination register (DR) is loaded with the contents of MDR.

56. what steps are required for memory-mapped input to occur? the same steps are carried out, except instead of MAR being loaded with the address of a memory location, MAR is loaded with the address of a device register. Instead of the address control logic enabling memory to read, the address control logic selects the corresponding device register to provide input to the MDR.

57. what of output to the monitor, how does it work? in a way very similar to input, with DDR and DSR replacing the roles of KBDR and KBSR, respectively. DDR stands for Display Data Register, which drives the monitor display. DSR stands for Display Status Register. In the LC-3, DDR is assigned address xFE06. DSR is assigned address xFE04.

58. Figure 9.5 shows the two device registers needed by the monitor. As is the case with input, even though an output character needs only 8 bits and the synchronization mechanism needs only one bit, it is easier to assign 16 bits (like all memory addresses in the LC-3) to each output device register. In the case of DDR, bits [7:0] are used for data, and bits [15:8] contain x00. In the case of DSR, bit [15] contains the synchronization mechanism, that is, the ready bit. 

59. DSR[15] controls the synchronization of the fast processor and the slow monitor display. When the LC-3 transfers an ASCII code to DDR[7:0] for outputting, the electronics of the monitor automatically clear DSR[15] as the processing of the contents of DDR[7:0] begins. When the monitor ﬁnishes processing the character on the screen, it (the monitor) automatically sets DSR[15]. This is a signal to the processor that it (the processor) can transfer another ASCII code to DDR for outputting. As long as DSR[15] is clear, the monitor is still processing the previous character, so the monitor is disabled as far as additional output from the processor is concerned.

60. how would things work if output is controlled by the processor via polling? a program can repeatedly test DSR[15] until it notes that the bit is set, indicating that it is OK to write a character to the screen. At that point, the processor can store the ASCII code for the character it wishes to write into DDR[7:0], setting up the transfer of that character to the monitor’s display.

61. Basic Output Service Routine: the following routine causes the ASCII code contained in R0 to be displayed on the monitor:

START     LDI      R1, A           ; Test for bit indicating output has occurred successfully
          BRzp     START           ; if negative value i.e. bit 15 is on, then proceed otherwise repeat check
          STI      R0, B
          BRnzp    NEXT_TASK       
A         .FILL    xFE04           ; Address of DSR
B         .FILL    xFE06           ; Address of DDR

62. lines 01 and 02 repeatedly poll DSR[15] to see if the monitor electronics is ﬁnished with the last character shipped by the processor. Note the use of LDI and the indirect access to xFE04, the memory-mapped address of DSR. As long as DSR[15] is clear, the monitor electronics is still processing a character, and BRzp branches to START for another iteration of the loop. When the monitor electronics ﬁnishes with the last character shipped by the processor, it automatically sets DSR[15] to 1, which causes the branch to fall through and the instruction at line 03 to be executed. Note the use of the STI instruction, which stores R0 into xFE06, the memory-mapped address of DDR. The write to DDR also clears DSR[15], disabling for the moment DDR from further output. The monitor electronics takes over and writes the character to the screen. Since the output routine is now done, the program unconditionally branches (line 04) to its NEXT TASK.

63. Figure 9.6 shows the additional data path required to implement memory-mapped output. As we discussed previously with respect to memory-mapped input, the mechanisms for handling the device registers provide very little additional complexity to what already exists for handling memory accesses.

64. In Chapter 5, you became familiar with the process of carrying out the EXECUTE phase of the store instructions. what was it?

a. The MAR is loaded with the address of the memory location to be written.
b. The MDR is loaded with the data to be written to memory.
c. Memory is written, resulting in the contents of MDR being stored in the speciﬁed memory location.

65. In the case of memory-mapped output, the same steps are carried out, except instead of MAR being loaded with the address of a memory location, MAR is loaded with the address of a device register. Instead of the address control logic enabling memory to write, the address control logic asserts the load enable signal of DDR.

66. Memory-mapped output also requires the ability to read output device registers. Before the DDR could be loaded, the ready bit had to be in state 1, indicating that the previous character had already ﬁnished being written to the screen. The LDI and BRzp instructions on lines 01 and 02 perform that test. To do this, the LDI reads the output device register DSR, and BRzp tests bit [15]. If the MAR is loaded with xFE04 (the memory-mapped address of the DSR), the address control logic selects DSR as the input to the MDR, where it is subsequently loaded into R1, and the condition codes are set.

67. When we type at the keyboard, it is helpful to know exactly what characters we have typed. We can get this echo capability easily (without any sophisticated electronics) by simply combining the two routines we have discussed. The result: The key typed at the keyboard is displayed on the monitor.

START     LDI     R1, KBSR     ; Test for character input
          BRzp    START
          LDI     R0, KBDR
ECHO      LDI     R1, DSR      ; Test output register ready
          BRzp    ECHO
          STI     R0, DDR
          BRnzp   NEXT_TASK
KBSR      .FILL   xFE00        ; Address of KBSR
KBDR      .FILL   xFE02        ; Address of KBDR
DSR       .FILL   xFE04        ; Address of DSR
DDR       .FILL   xFE06        ; Address of DDR

68. what does the computer do to let a person sitting at the keyboard know that the program is waiting for input from the keyboard? prints a message on the monitor known as a prompt. The symbols that are displayed by your operating system (e.g., % or C:) or by your editor (e.g., :) are examples of prompts.

69. The program fragment shown in Figure 9.7 obtains keyboard input via polling. It also includes a prompt to let the person sitting at the keyboard know when it is time to type a key. You are already familiar with lines 13 through 19 and lines 25 through 28 which correspond to the code for inputting a character via the keyboard and echoing it on the monitor. You are also familiar with the need to save and restore registers if those reg- isters are needed by instructions in the input routine. This leaves lines 05 through 08, 0A through 11, 1A through 1C, 29 and 2A. These lines serve to alert the person sitting at the keyboard that it is time to type a character. Lines 05 through 08 write the ASCII code x0A to the monitor. This is the ASCII code for a new line.

70. Do most ASCII codes correspond to characters that are visible on the screen? yes

71.  A few, like x0A, are control characters. why are they given this name? because they cause an action to occur. Speciﬁcally, the ASCII code x0A causes the cursor to move to the far left of the next line on the screen. Thus, the name Newline.

72. Before attempting to write x0A, however, as is always the case, DSR[15] is tested (line 6) to see if DDR can accept a character. If DSR[15] is clear, the monitor is busy, and the loop (lines 06 and 07) is repeated. When DSR[15] is 1, the conditional branch (line 7) is not taken, and (line 8) x0A is written to DDR for outputting.

73. Lines 0A through 11 cause the prompt Input a character> to be written to the screen. The prompt is specified by the .STRINGZ pseudo-op on line 2A and is stored in 19 memory locations—18 ASCII codes, one per memory location, corresponding to the 18 characters in the prompt, and the terminating sentinel x0000.

74. Line 0C iteratively tests to see if the end of the string has been reached (by detecting x0000), and if not, once DDR is free, line 0F writes the next character in the input prompt into DDR. When x0000 is detected, the entire input prompt has been written to the screen, and the program branches to the code that handles the actual keyboard input (starting at line 13).

75. After the person at the keyboard types a character and it has been echoed (lines 13 to 19), the program writes one more new line (lines 1A through 1C) before branching to its NEXT TASK.

76. We showed in Figures 9.4 and 9.6 partial implementations of the data path to handle (separately) memory-mapped input and memory-mapped output. We have also learned that in order to support interrupt-driven I/O, the two status registers must be writeable as well as readable.

77. Figure 9.8 shows the data path necessary to support the full range of features we have discussed for the I/O device registers. The Address Control Logic Block controls the input or output operation. Note that there are three inputs to this block. MIO.EN indicates whether a data movement from/to memory or I/O is to take place this clock cycle. MAR contains the address of the memory location or the memory-mapped address of an I/O device register. R.W indicates whether a load or a store is to take place. Depending on the values of these three inputs, the address control logic does nothing (MIO.EN = 0), or it provides the control signals to direct the transfer of data between the MDR and the memory or between the MDR and one of the I/O registers.

78. If R.W indicates a load, the transfer is from memory or I/O device to the MDR. The Address Control Logic Block provides the select lines to INMUX to source the appropriate I/O device register or memory (depending on MAR) and also enables the memory if MAR contains the address of a memory location.

79. If R.W indicates a store, the contents of the MDR is written either to memory or to one of the device registers. The address control logic either enables a write to memory or asserts the load enable line of the device register speciﬁed by the contents of the MAR.

80. in order for the program to successfully obtain input from the keyboard and display it to the monitor, what does the programmer need to know?

a. The hardware data registers for both the monitor and the keyboard
b. the monitor so a prompt could be displayed, and the keyboard so the program would know where to get the input character.
c. The hardware status registers for both the monitor and the keyboard
d. the monitor so the program would know when it was OK to display the next character in the input prompt, and the keyboard so the program would know when someone had struck a key.
e. The asynchronous nature of keyboard input relative to the executing program.

81. This is beyond the knowledge of most application programmers. In fact, in the real world, if application programmers had to understand I/O at this level, there would be much less I/O and far fewer programmers in the business.

82. There is another problem with allowing user programs to perform I/O activity by directly accessing KBDR and KBSR. I/O activity involves the use of device registers that are shared by many programs. This means that if a user programmer were allowed to access the hardware registers, and he/she messed up, it could create havoc for other user programs. Thus, in general it is ill-advised to give user programmers access to these registers. That is why the addresses of hardware registers are part of the privileged memory address space and accessible only to programs that have supervisor privilege.

83. what is the solution? simpler solution as well as the safer solution to the problem of user programs requiring I/O, involves the TRAP instruction and the operating system, which of course has supervisor privilege.

84. A great beneﬁt of the TRAP instruction is that it allows the user programmer to not have to know the gory details of I/O. In addition, it protects user programs from the consequences of other inept user programmers. Figure 9.9 shows a user program that, upon reaching location x4000, needs an I/O task performed. The user program uses the TRAP instruction to request the operating system to perform the task on behalf of the user program. The operating system takes control of the computer, handles the request speciﬁed by the TRAP instruction, and then returns control back to the user program at location x4001.

85. The trap mechanism involves several elements. what are they?

a. A set of service routines executed on behalf of user programs by the operating system. These are part of the operating system and start at arbitrary addresses in system space. The LC-3 was designed so that up to 256 service routines can be speciﬁed. Table A.2 in Appendix A contains the LC-3’s current complete list of operating system service routines.

b. A table of the starting addresses of these 256 service routines. This table is stored in memory locations x0000 to x00FF. The table is referred to by various names by various companies. One company calls this table the System Control Block. Another company calls it the Trap Vector Table. Figure 9.10 shows the Trap Vector Table of the LC-3, with speciﬁc starting addresses highlighted. Among the starting addresses are the one for the character output service routine (memory location x0420), which is stored in memory location x0021, the one for the keyboard input service routine (location x04A0), stored in location x0023, and the one for the machine halt service routine (location x0520), stored in location x0025.

c. The TRAP instruction. When a user program wishes to have the operating system execute a speciﬁc service routine on behalf of the user program, and then return control to the user program, the user program uses the TRAP instruction

d. A linkage back to the user program. The service routine must have a mechanism for returning control to the user program.

86. how does the trap instruction work? causes the service routine to execute by (1) changing the PC to the starting address of the relevant service routine on the basis of its trap vector, and (2) providing a way to get back to the program that executed the TRAP instruction. 

87. what is "the way back" referred to? as linkage

88. The TRAP instruction is made up of two parts: the TRAP opcode 1111 and the trap vector (bits [7:0]), which identiﬁes the service routine the user program wants the operating system to execute on its behalf. Bits [11:8] must be zero.

15   14   13   12    11   10   9    8     7    6    5    4    3    2    1    0
1    1    1    1  |  0    0    0    0  |  0    0    1    0    0    0    1    1 
  TRAP                                                trap vector

89. what three things occur during the EXECUTE phase of the TRAP instruction’s instruction cycle?

a. The PSR and PC are both pushed onto the system stack. Since the PC was incremented during the FETCH phase of the TRAP instruction’s instruction cycle, the return linkage is automatically saved in the PC. When control returns to the user program, the PC will automatically be pointing to the instruction following the TRAP instruction.

Note that the program requesting the trap service routine can be running either in Supervisor mode or in User mode. If in User mode, R6, the stack pointer, is pointing to the user stack. Before the PSR and PC can be pushed onto the system stack, the current contents of R6 must be stored in Saved USP, and the contents of Saved SSP loaded into R6.

b. PSR[15] is set to 0, since the service routine is going to require supervisor privilege to execute. PSR[10:8] are left unchanged since the priority of the TRAP routine is the same as the priority of the program that requested it.

c. The 8-bit trap vector is zero-extended to 16 bits to form an address that corresponds to a location in the Trap Vector Table. For the trap vector x23, that address is x0023. Memory location x0023 contains x04A0, the starting address of the TRAP x23 service routine. The PC is loaded with x04A0, completing the instruction cycle.

90. Since the PC contains x04A0, processing continues at memory address x04A0. Location x04A0 is the starting address of the operating system service routine to input a character from the keyboard. We say the trap vector “points” to the starting address of the TRAP routine. Thus, TRAP x23 causes the operating system to start executing the keyboard input service routine.

91. The RTI Instruction: To Return Control to the Calling Program is accomplished by the Return from Trap or Interrupt (RTI) instruction

15   14   13   12    11   10   9    8     7    6    5    4    3    2    1    0
1    0    0    0  |  0    0    0    0     0    0    0    0    0    0    0    0
    RTI

92. what does it do? pops the top two values on the system stack into the PC and PSR. Since the PC contains the address following the address of the TRAP instruction, control returns to the user program at the correct address.

93. what is the final step? once the PSR has been popped oﬀ the system stack, PSR[15] must be examined to see whether the processor was running in User mode or Supervisor mode when the TRAP instruction was executed. If in User mode, the stack pointers need to be adjusted to reﬂect that now back in User mode, the relevant stack in use is the user stack. This is done by loading the Saved SSP with the current contents of R6, and loading R6 with the contents of Saved USP.

94. Figure 9.11 shows the LC-3 using the TRAP instruction and the RTI instruction to implement the example of Figure 9.9. The ﬂow of control goes from (A) within a user program that needs a character input from the keyboard, to (B) the operating system service routine that performs that task on behalf of the user program, back to the user program (C) that presumably uses the information contained in the input character.

95. As we know, the computer continually executes its instruction cycle (FETCH, DECODE, etc.) on sequentially located instructions until the flow of control is changed by changing the contents of the PC during the EXECUTE phase of the current instruction. In that way, the next FETCH will be at a redirected address.

96. The TRAP instruction with trap vector x23 in our user program does exactly that. Execution of TRAP x23 causes the PSR and incremented PC to be pushed onto the system stack and the contents of memory location x0023 (which, in this case, contains x04A0) to be loaded into the PC. The dashed line on Figure 9.11 shows the use of the trap vector x23 to obtain the starting address of the trap service routine from the Trap Vector Table.

97. The next instruction cycle starts with the FETCH of the contents of x04A0, which is the ﬁrst instruction of the relevant operating system service routine. The trap service routine executes to completion, ending with the RTI instruction, which loads the PC and PSR with the top two elements on the system stack, that is, the PSR and incremented PC that were pushed during execution of the TRAP instruction. Since the PC was incremented prior to being pushed onto the system stack, it contains the address of the instruction following the TRAP instruction in the calling program, and the user program resumes execution by fetching the instruction following the TRAP instruction.

98. see example91a and example91b The correct operation of the program in this example assumes that the person sitting at the keyboard only types capital letters and the value 7. What if the person types a $? A better solution to Example 9.1 would be a program that tests the character typed to be sure it really is a capital letter from among the 26 capital letters in the alphabet or the single digit 7, and if it is not, takes corrective action. Question: Augment this program to add the test for bad data. That is, write a program that will type the lowercase representation of any capital letter typed and will terminate if anything other than a capital letter is typed. See Exercise 9.20.

99. The input routine described in Figure 9.7 can be slightly modiﬁed to be the input service routine shown in Figure 9.12. Two changes are needed: (1) We add the appropriate .ORIG and .END pseudo-ops. .ORIG speciﬁes the starting address of the input service routine—the address found at location x0023 in the Trap Vector Table. And (2) we terminate the input service routine with the RTI instruction rather than the BR NEXT TASK, as is done on line 20 in Figure 9.7. We use RTI because the service routine is invoked by TRAP x23. It is not part of the user program, as was the case in Figure 9.7.

100. The output routine in 61 can be modiﬁed in a similar way, as shown in Figure 9.13. The results are input (Figure 9.12) and output (Figure 9.13) service routines that can be invoked simply and safely by the TRAP instruction with the appropriate trap vector. In the case of input, upon completion of TRAP x23, R0 contains the ASCII code of the keyboard character typed. In the case of output, the initiating program must load R0 with the ASCII code of the character it wishes displayed on the monitor and then invoke TRAP x21.

101. Recall you learned earlier that the RUN latch is ANDed with the crystal oscillator to produce the clock that controls the operation of the computer. We noted that if that one-bit latch was cleared, the output of the AND gate would be 0, stopping the clock. Years ago, most ISAs had a HALT instruction for stopping the clock. Given how infrequently that instruction is executed, it seems wasteful to devote an opcode to it. In many modern computers, the RUN latch is cleared by a TRAP routine. In the LC-3, the RUN latch is bit [15] of the Master Control Register (MCR), which is memory-mapped to location xFFFE. Figure 9.14 shows the trap service routine for halting the processor, that is, for stopping the clock.

102. First (lines 02 and 03), registers R1 and R0 are saved. R1 and R0 are saved because they are needed by the service routine. Then (lines 07 through 0C), the banner Halting the machine is displayed on the monitor. Finally (lines 10 through 13), the RUN latch (MCR[15]) is cleared by ANDing the MCR with 0111111111111111. That is, MCR[14:0] remains unchanged, but MCR[15] is cleared. Question: What instruction (or trap service routine) can be used to start the clock? Hint: This is a trick question! :-)

103. Looking again at the keyboard input service routine of Figure 9.12., is there a way to remove the duplication in the three-line sequence that occurs at symbolic addresses L1, L2, L3, and L4? yes.

104. how? the JSR/RET mechanism enables us to almost replace these four occurrences of the same sequence with a single subroutine Figure 9.15, our “improved” keyboard input service routine, contains JSR WriteChar at lines 04, 0A, 10, and 13, and the four-instruction subroutine (at lines 1A through 1D). Note the RET instruction (a.k.a. JMP R7) that is needed to terminate the subroutine.

WriteChar      LDI    R3,DSR  
               BRzp   WriteChar
               STI    R2,DDR
               RET

105. Note the hedging: almost. In the original sequences starting at L2 and L3, the STI instruction forwards the contents of R0 (not R2) to the DDR. We can ﬁx that easily enough, as follows: In line 08 of Figure 9.15, we use

LDR    R2,R1,#0

instead of

LDR    R0,R1,#0

This causes each character in the prompt to be loaded into R2. The subroutine Writechar forwards each character from R2 to the DDR. In line 0F of Figure 9.15, we insert the instruction

ADD    R2,R0,#0

in order to move the keyboard input (which is in R0) into R2. The subroutine Writechar forwards it from R2 to the DDR. Note that R0 still contains the keyboard input. Furthermore, since no subsequent instruction in the service routine loads R0, R0 still contains the keyboard input after control returns to the user program. 

106. In line 12 of Figure 9.15, we insert the instruction

LD   R2,Newline

in order to move the “newline” character into R2. The subroutine Writechar forwards it from R2 to the DDR.

107. PUTS: Writing a Character String to the Monitor; note the code on lines 08 through 0C. This fragment of the service routine is used to write the sequence of characters Input a character to the monitor. A sequence of characters is often referred to as a string of characters or a character string. This fragment is also present in Figure 9.14, with the result that Halting the machine is written to the monitor. In fact, it is so often the case that a user program needs to write a string of characters to the monitor that this function is given its own trap service routine in the LC-3 operating system. Thus, if a user program requires a character string to be written to the monitor, it need only provide (in R0) the starting address of the character string, and then invoke TRAP x22. In LC-3 assembly language this TRAP is called PUTS.

108. PUTS (or TRAP x22) causes control to be passed to the operating system, and the trap routine shown in Figure 9.16 is executed. Note that PUTS is the code of lines 08 through 0C of Figure 9.15, with a few minor adjustments.

109. what are the two ways that the processor and I/O can interact? can be controlled by the processor (i.e. polling) or it can be controlled by the I/O device (interrupt driven). We have studied several examples of polling. In each case, the processor tested the ready bit of the status register again and again, and when the ready bit was ﬁnally 1, the processor branched to the instruction that did the input or output operation.

110. what is interrupt driven I/O? the notion that an I/O device that may or may not have anything to do with the program that is running can (1) force the running program to stop, (2) have the processor execute a program that carries out the needs of the I/O device, and then (3) have the stopped program resume execution as if nothing had happened. These three stages of the instruction execution ﬂow are shown in Figure 9.17.

111. Why choose Interrupt-Driven I/O? polling requires the processor to waste a lot of time spinning its wheels, re-executing again and again the LDI and BR instructions until the ready bit is set. With interrupt-driven I/O, none of that testing and branching has to go on. Interrupt-driven I/O allows the processor to spend its time doing what is hopefully useful work, executing some other program perhaps, until it is notiﬁed that some I/O device needs attention. see example92

112. what are the two Parts to the interrupt-driven I/O Process? the mechanism that enables an I/O device to interrupt the processor, and the mechanism that handles the interrupt request.

113. Part I: Causing the Interrupt to Occur; what are several things that must be true for an I/O device to actually interrupt the program that is running?

a. The I/O device must want service.
b. The device must have the right to request the service.
c. The device request mustbemoreurgentthan what the processor is currently doing.

If all three elements are present, the processor stops executing the program that is running and takes care of the interrupt.

114. The Device Must Want Service: We have discussed that already in the study of polling. It is the ready bit of the KBSR or the DSR. That is, if the I/O device is the keyboard, it wants service if someone has typed a character. If the I/O device is the monitor, it wants service (i.e., the next character to output) if the associated electronic circuits have successfully completed the display of the last character. In both cases, the I/O device wants service when the corresponding ready bit is set.

115. The Device Must Have the Right to Request That Service: This is the interrupt enable bit, which can be set or cleared by the processor (usually by the operating system), depending on whether or not the processor wants to give the I/O device the right to request service. In most I/O devices, this interrupt enable (IE) bit is part of the device status register. In the KBSR and DSR shown in Figure 9.18, the IE bit is bit [14]. The interrupt request signal from the I/O device is the logical AND of the IE bit and the ready bit, as is also shown in Figure 9.18.

116. If the interrupt enable bit (bit [14]) is clear, it does not matter whether the ready bit is set; the I/O device will not be able to interrupt the processor because it (the I/O device) has not been given the right to interrupt the processor. In that case, the program will have to poll the I/O device to determine if it is ready.

117. If bit [14] is set, then interrupt-driven I/O is enabled. In that case, as soon as someone types a key (or as soon as the monitor has ﬁnished processing the last character), bit [15] is set. In this case, the device wants service, and it has been given the right to request service. The AND gate is asserted, causing an interrupt request to be generated from the I/O device.

118. The Urgency of the Request: The third element in the list of things that must be true for an I/O device to actually interrupt the processor is that the request must be more urgent than the program that is currently executing. Recall that each program runs at a speciﬁed level of urgency called its priority level. To interrupt the running program, the device must have a higher priority than the program that is currently running. Actually, there may be many devices that want to interrupt the processor at a speciﬁc time. To succeed, the device must have a higher priority level than all other demands for use of the processor.

119. Almost all computers have a set of priority levels that programs can run at. As we have already noted, the LC-3 has eight priority levels, PL0 to PL7. The higher the number, the more urgent the program. The PL of a program is usually the same as the PL (i.e., urgency) of the request to run that program. If a program is running at one PL, and a higher-level PL request wants the computer, the lower-priority program suspends processing until the higher-PL program executes and satisﬁes its more urgent request.

120. For example, a computer’s payroll program may run overnight, and at PL0. It has all night to ﬁnish—not terribly urgent. A program that corrects for a nuclear plant current surge may run at PL6. We are perfectly happy to let the payroll wait while the nuclear power correction keeps us from being blown to bits.

121. For our I/O device to successfully stop the processor and start an interrupt-driven I/O request, the priority of the request must be higher than the priority of the program it wishes to interrupt. 

122. The INT Signal: To stop the processor from continuing execution of its currently running program and service an interrupt request, the INT signal must be asserted. Figure 9.19 shows what is required to assert the INT signal. Figure 9.19 shows the status registers of several devices operating at various priority levels (PL). Any device that has bits [14] and [15] both set asserts its interrupt request signal. The interrupt request signals are input to a priority encoder, a combinational logic structure that selects the highest priority request from all those asserted. If the PL of that request is higher than the PL of the currently executing program, the INT signal is asserted.

123. The Test for INT: Recall from Chapter 4 that the instruction cycle continually sequences through the phases of the instruction cycle (FETCH, DECODE, EVALUATE ADDRESS, FETCH OPERAND, EXECUTE, and STORE RESULT). Each instruction changes the state of the computer, and that change is completed at the end of the instruction cycle for that instruction. That is, in the last clock cycle before the computer returns to the FETCH phase for the next instruction, the computer is put in the state caused by the complete execution of the current instruction.

124. Interrupts can happen at any time. They are asynchronous to the synchronous ﬁnite state machine controlling the computer. For example, the interrupt signal could occur when the instruction cycle is in its FETCH OPERAND phase. If we stopped the currently executing program when the instruction cycle was in its FETCH OPERAND phase, we would have to keep track of what part of the current instruction has executed and what part of the current instruction still has work to do. It makes much more sense to ignore interrupt signals except when we are at an instruction boundary; that is, the current instruction has completed, and the next instruction has not yet started. Doing that means we do not have to worry about partially executed instructions, since the state of the computer is the state created by the completion of the current instruction, period!

125. The additional logic to test for the interrupt signal is to augment the last state of the instruction cycle for each instruction with a test. Instead of always going from the last state of one instruction cycle to the ﬁrst state of the FETCH phase of the next instruction, the next state depends on the INT signal. If INT is not asserted, then it is business as usual, with the control unit returning to the FETCH phase to start processing the next instruction. If INT is asserted, then the next state is the ﬁrst state of Part II, handling the interrupt request.

126. Part II: Handling the Interrupt Request: handling the interrupt request goes through three stages , as shown in Figure 9.17:

a. Initiate the interrupt (three lines numbered 1 in Figure 9.17).
b. Service the interrupt (four lines numbered 2 in Figure 9.17).
c. Return from the interrupt (one line numbered 3 in Figure 9.17).

127. Initiate the Interrupt: Since the INT signal was asserted, the processor does not return to the ﬁrst state of the FETCH phase of the next instruction cycle, but rather begins a sequence of actions to initiate the interrupt. The processor must do two things: (1) save the state of the interrupted program so it can pick up where it left oﬀ after the require- ments of the interrupt have been completed, and (2) load the state of the higher priority interrupting program so it can start satisfying its request.

128. Save the State of the Interrupted Program: The state of a program is a snapshot of the contents of all the program’s resources. It includes the contents of the memory locations that are part of the program and the contents of all the general purpose registers. It also includes the PC and PSR. Recall from Figure 9.1 that a program’s PSR speciﬁes the privilege level and priority level of that program. PSR[15] indicates whether the program is running in privileged (Supervisor) or unprivileged (User) mode. PSR[10:8] speciﬁes the program’s priority level (PL), from PL0 (lowest) to PL7 (highest). Also, PSR[2:0] is used to store the condition codes. PSR[2] is the N bit, PSR[1] is the Z bit, and PSR[0] is the P bit.

129. The ﬁrst step in initiating the interrupt is to save enough of the state of the program that is running so that it can continue where it left oﬀ after the I/O device request has been satisﬁed. That means, in the case of the LC-3, saving the PC and the PSR. The PC must be saved since it knows which instruction should be executed next when the interrupted program resumes execution. The condition codes (the N, Z, and P ﬂags) must be saved since they may be needed by a subsequent conditional branch instruction after the program resumes execution. The priority level of the interrupted program must be saved because it speciﬁes the urgency of the interrupted program with respect to all other programs. When the interrupted program resumes execution, it is important to know what priority level programs can interrupt it and which ones cannot. Finally, the privilege level of the program must be saved since it speciﬁes what processor resources the interrupted program can and cannot access.

130. Although many computers save the contents of the general purpose registers, we will not since we will assume that the service routine will always save the contents of any general purpose register that it needs before using it, and then restore it before returning to the interrupted program. The only state information the LC-3 saves are the PC and PSR.

131. The LC-3 saves this state information on the supervisor stack in the same way the PC and PSR are saved when a TRAP instruction is executed. That is, before the interrupt service routine starts, if the interrupted program is in User mode, the User Stack Pointer (USP) is stored in Saved USP, and R6 is loaded with the Supervisor Stack Pointer (SSP) from Saved SSP. Then the PSR and PC of the interrupted program are pushed onto the supervisor stack, where they remain unmolested while the service routine executes.

132. Load the State of the Interrupt Service Routine: Once the state of the interrupted program has been safely saved on the supervisor stack, the second step is to load the PC and PSR of the interrupt service routine. Interrupt service rou- tines are similar to the trap service routines we have already discussed. They are program fragments stored in system space. They service interrupt requests.

133. Most processors use the mechanism of vectored interrupts. You are familiar with this notion from your study of the trap vector contained in the TRAP instruction. In the case of interrupts, the eight-bit vector is provided by the device that is requesting the processor be interrupted. That is, the I/O device transmits to the processor an eight-bit interrupt vector along with its interrupt request signal and its priority level. The interrupt vector corresponding to the highest priority interrupt request is the one supplied to the processor. It is designated INTV.

134. If the interrupt is taken, the processor expands the 8-bit interrupt vector (INTV) to form a 16-bit address, which is an entry into the Interrupt Vector Table. You know that the Trap Vector Table consists of memory locations x0000 to x00FF, each containing the starting address of a trap service routine. The Interrupt Vector Table consists of memory locations x0100 to x01FF, each containing the starting address of an interrupt service routine. The processor loads the PC with the contents of the location in the Interrupt Vector Table corresponding to the address formed by expanding the interrupt vector INTV.

135. For example, the LC-3 keyboard could interrupt the processor every time a key is pressed by someone sitting at the keyboard. The keyboard interrupt vector would indicate the location in the interrupt vector table that contains the starting address of the keyboard interrupt service routine.

136. The PSR is loaded as follows: Since no instructions in the service routine have yet executed, PSR[2:0] contains no meaningful information. We arbitrarily load it initially with 010. Since the interrupt service routine runs in privileged mode, PSR[15] is set to 0. PSR[10:8] is set to the priority level associated with the interrupt request. This completes the initiation phase, and the interrupt service routine is ready to execute.

137. Service the Interrupt: Since the PC contains the starting address of the interrupt service routine, the service routine will execute, and the requirements of the I/O device will be serviced.

138. Return from the Interrupt: The last instruction in every interrupt service routine is RTI, return from trap or interrupt. When the processor ﬁnally accesses the RTI instruction, all the requirements of the I/O device have been taken care of.

139. Like the return from a trap routine discussed in Section 9.3.4, execution of the RTI instruction (opcode = 1000) for an interrupt service routine consists simply of popping the PC and the PSR from the supervisor stack (where they have been resting peacefully) and restoring them to their rightful places in the processor. The condition codes are now restored to what they were when the program was interrupted, in case they are needed by a subsequent BR instruction in the interrupted program. PSR[15] and PSR[10:8] now reﬂect the privilege level and priority level of the about-to-be-resumed program. If the privilege level of the interrupted program is unprivileged, the stack pointers must be adjusted, that is, the Supervisor Stack Pointer saved, and the User Stack Pointer loaded into R6. The PC is restored to the address of the instruction that would have been executed next if the program had not been interrupted. With all these things as they were before the interrupt occurred, the program can resume as if nothing had happened.

140. An Example: Suppose program A is executing when I/O device B, having a PL higher than that of A, requests service. During the execution of the service routine for I/O device B, a still more urgent device C requests service. Figure 9.20 shows the execution ﬂow that must take place.

141. Program A consists of instructions in locations x3000 to x3010 and was in the middle of executing the ADD instruction at x3006 when device B sent its interrupt request signal and accompanying interrupt vector xF1, causing INT to be asserted. Note that the interrupt service routine for device B is stored in locations x6200 to x6210; x6210 contains the RTI instruction. Note that the service routine for B was in the middle of executing the AND instruction at x6202 when device C sent its interrupt request signal and accompanying interrupt vector xF2. Since the request associated with device C is of a higher priority than that of device B, INT is again asserted. Note that the interrupt service routine for device C is stored in locations x6300 to x6315; x6315 contains the RTI instruction.

142. Figure 9.21 shows several snapshots of the contents of the supervisor stack and the PC during the execution of this example. The processor executes as follows: Figure 9.21a shows the supervisor stack and the PC before program A fetches the instruction at x3006. Note that the stack pointer is shown as Saved SSP, not R6. Since the interrupt has not yet occurred, R6 is pointing to the current contents of the user stack, which are not shown! The INT signal (caused by an interrupt from device B) is detected at the end of execution of the instruction in x3006. Since the state of program A must be saved on the supervisor stack, the ﬁrst step is to start using the supervisor stack. This is done by saving R6 in the Saved.USP register and loading R6 with the contents of the Saved SSP register. The PSR of program A, which includes the condition codes produced by the ADD instruction, is pushed on the supervisor stack. Then the address x3007, the PC for the next instruction to be executed in program A is pushed on the stack. The interrupt vector associated with device B is expanded to 16 bits x01F1, and the contents of x01F1 (x6200) is loaded into the PC. Figure 9.21b shows the stack and PC at this point.

143. The service routine for device B executes until a higher priority interrupt is detected at the end of execution of the instruction at x6202. The PSR of the service routine for B, which includes the condition codes produced by the AND instruction at x6202, and the address x6203 are pushed on the stack. The interrupt vector associated with device C is expanded to 16 bits (x01F2), and the contents of x01F2 (x6300) is loaded into the PC. Figure 9.21c shows the supervisor stack and PC at this point.

144. Assume the interrupt service routine for device C executes to completion, ﬁnishing with the RTI instruction in x6315. The supervisor stack is popped twice, restoring the PC to x6203 and the PSR of the service routine for device B, including the condition codes produced by the AND instruction in x6202. Figure 9.21d shows the stack and PC at this point.
The interrupt service routine for device B resumes execution at x6203 and runs to completion, ﬁnishing with the RTI instruction in x6210. The supervisor stack is popped twice, restoring the PC to x3007 and the PSR of program A, including the condition codes produced by the ADD instruction in x3006. Finally, since program A is in User mode, the contents of R6 is stored in Saved SSP and R6 is loaded with the contents of Saved USP. Figure 9.21e shows the supervisor stack and PC at this point. Program A resumes execution with the instruction at x3007.

145. Not Just I/O Devices: so far we have discussed the processing of interrupts in the context of I/O devices that have higher priority than the program that is running and therefore can stop that program to enable its interrupt service routine to execute. Not all interrupts deal with I/O devices. Any event that has a higher priority and is external to the program that is running can interrupt the computer. It does so by supplying its INT signal, its INTV vector, and its pri- ority level. If it is the highest priority event that wishes to interrupt the computer, it does so in the same way that I/O devices do as described above.

146. There are many examples of such events that have nothing to do with I/O devices. For example, a timer interrupt interrupts the program that is running in order to note the passage of a unit of time. The machine check interrupt calls attention to the fact that some part of the computer system is not functioning properly. The power failure interrupt notiﬁes the computer that, for example, someone has yanked the power cord out of its receptacle. 

147. Polling Revisited, Now That We Know About Interrupts: We continually test the ready bit in the relevant status register, and if it is not set, we branch back to again test the ready bit. For example, suppose we are writing a character string to the monitor, and we are using polling to determine when the monitor has successfully written the current character so we can dispatch the next character. We take it for granted that the three-instruction sequence LDI (to load the ready bit of the DSR), BRzp (to test it and fall through if the device is ready), and STI (to store the next character in the DDR) acts as an atomic unit. 

148. But what if we had interrupts enabled at the same time? That is, if an interrupt occurred within that LDI, BRzp, STI sequence (say, just before the STI instruction), it could easily be the case that the LDI instruction indicated the DDR was ready, the BRzp instruction did not branch back, but by the time the interrupt service routine completed so the STI could write to the DDR, the DDR may no longer be ready. The computer would execute the STI, but the write would not happen.

149. A simple, but somewhat contrived example :-), will illustrate the problem. Suppose you are executing a “for” loop ten times, where each time the loop body prints to the monitor a particular character. Polling is used to determine that the monitor is ready before writing the next character to the DDR. Since the loop body executes ten times, this should result in the character being printed on the monitor ten times. Suppose you also have keyboard interrupts enabled, and the keyboard service routine echoes the character typed.

150. Suppose the loop body executes as follows: LDI loads the ready bit, BRzp falls through since the monitor is ready, and STI stores the character in DDR. In the middle of this sequence, before the STI can execute, someone types a key. The keyboard interrupt occurs, the character typed is echoed, i.e., written to the DDR, and the keyboard interrupt service routine completes.

151. The interrupted loop body then takes over and “knows” the monitor is ready, so it executes the STI. ... except the monitor is not ready because it has not com-pleted the write of the keyboard service routine! The STI of the loop body writes, but since DDR is not ready, the write does not occur. The ﬁnal result: Only nine characters get written, not ten. The problem becomes more serious if the string written is in code, and the missing write prevents the code from being deciphered.

152. A simple way to handle this would be to disable all interrupts while polling was going on. But consider the consequences. Suppose the polling was required for a long time. If we disable interrupts while polling is going on, interrupts would be disabled for that very long time, unacceptable in an environment where one is concerned about the time between a higher priority interrupt occurring and the interrupt getting service.

153. A better solution is shown in Figure 9.22. The sequence we want to make noninterruptable is shown on lines 0F to 11. We accomplish this by ﬁrst loading R1 with the PSR in line 09 and R2 with the PSR having interrupts disabled in line 0A. PSR[14] is the interrupt enable bit for all interrupts associated with this program. Note that PSR is memory mapped to xFFFC. We enable interrupts by storing R1 in PSR (line 0D), followed immediately by disabling interrupts by storing R2 in PSR (line 0E). With interrupts disabled, we execute the three-instruction sequence LDI, BRzp, and LDI (lines 0F, 10, and 11) if the status register indicates that the device is ready. If the device is not ready, BRzp (line 10) takes the computer back to line 0D where interrupts are again enabled.

154. In this way, interrupts are disabled again and again, but each time only long enough to execute the three-instruction sequence LDI, BRzp, STI (in lines 0F, 10, 0D), after which interrupts are enabled again. The result: An interrupt would have to wait for the three-instruction sequence LDI, BRzp, STI to execute, rather than for the entire polling process to complete.

chapter 10

1. this chapter is about demonstrating the use of many of the concepts discussed so far as well as to show an example of well documented clearly written code.

2. the program discussed simulates the actions of a calculator that a person can use to add, subtract, and multiply 2's complement integers. the person will enter numbers into the calculator-simulator by typing keys on the keyboard. result of a computation will be displayed on the monitor.

3. the calculator simulation consists of a main program and eleven separate subroutines

4. two topics have not been discussed that are needed to understand the workings of the calculator simulator. what are they? the conversion of integers between ASCII strings and 2s complement numbers; and arithmentic using a stack (the method most calculators use)

5. what is the reason for the two data types and conversion between them? we need one data type for input/output and another for doing arithmetic. numbers entered via the keyboard and displayed on the monitor use ascii codes to represent the numbers. arithmetic uses 2's complement integers

6. we will need to convert the number the person types from ASCII codes to a 2’s complement integer, and we will need to convert the result of the computation from a 2’s complement integer to ASCII codes in order to display it on the monitor.

7. With respect to the way calculators perform arithmetic, the mechanism used by most calculators is very diﬀerent from the way most desktop and laptop computers perform arithmetic. The ISAs of most desktops and laptops are like the LC-3, where arithmetic instructions get their source operands from general purpose registers and store the results of the arithmetic operations in general purpose registers. 

8. Our simulation of a calculator, like most calculators, does not use general purpose registers. Instead it uses a stack. Source operands are popped from the stack, and the result of the operation is pushed back onto the stack.

9. I have already been exposed to several data types: unsigned integers for address arithmetic, 2’s complement integers for integer arithmetic, 16-bit binary strings for logical operations, ﬂoating point numbers for scientiﬁc computation, and ASCII codes for interaction with input and output devices. 

10. It is important that every instruction be provided with source operands of the data type that the instruction requires. For example, an ALU requires operands that are 2’s complement integers to perform an ADD. If the ALU were supplied with ﬂoating point operands, the ALU would produce garbage results.

11. It is not uncommon in high-level language programs to ﬁnd an instruction of the form A = R + I where R (ﬂoating point) and I (2’s complement integer) are represented in diﬀerent data types. If the operation is to be performed by a ﬂoating point adder, then we have a problem with I. To handle the problem, one must ﬁrst convert the value I from its original data type (2’s complement integer) to the data type required by the functional unit performing the operation (ﬂoating point). 

12. For those programming in some high-level language, the compiler generally produces the code to do that conversion so the programmer does not even have to think about it.

13. Even in our “character count problem” way back in Chapter 5, we had to deal with data type conversion. Our program entered a character from the keyboard, scanned a ﬁle counting the number of occurrences of that character, and then displayed the count on the monitor. Recall that before we could display our ﬁnal count on the monitor, we had to convert our 2’s complement integer to an ASCII code. Why? Because when we were counting, we were performing arithmetic on 2’s complement integers. But when we were displaying, we needed to represent our count as an ASCII code. 

14. we restricted our program to work only on ﬁles where the total count was not greater than 9, so our conversion from a 2’s complement integer to an ASCII code could be obtained by simply adding x30 to the 2’s complement integer to get the ASCII code. For example, the 2’s complement representation for 6 (in one byte) is 00000110, or x06. The ASCII code for 6, on the other hand, is 00110110, or x36.

15. That was a severe limitation to put on our count, restricting it to a single decimal digit. If our number is represented by more than one decimal digit, simply adding x30 does not work. For example, consider the two decimal digit number 25. If we enter 25 via the keyboard, we input the ASCII code x32, followed by the ASCII code x35. The bit stream is 0011001000110101. To perform arithmetic on this integer, we must ﬁrst convert it to 0000000000011001, the 2’s complement integer representation of 25. Displaying the result of some arithmetic computation on the monitor causes a similar problem. To do that, we must ﬁrst convert the result of the arithmetic (a 2’s complement integer) to an ASCII string.

16. Figure 10.1 shows how we can get into trouble if we do not pay attention to the data types that we are working with. Suppose we want to enter two single-digit integers from the keyboard, add them, and display the result on the monitor. At ﬁrst blush, we write the simple program of Figure 10.1.

17. What happens? Suppose the ﬁrst digit entered via the keyboard is a 2 and the second digit entered via the keyboard is a 3. What will be displayed on the monitor before the program terminates? The value loaded into R0 as a result of entering a 2 is the ASCII code for 2, which is x0032. When the 3 is entered, the ASCII code for 3, which is x0033, is loaded into R0 (after the ASCII code for 2 is moved to R1, of course). Thus, the ADD instruction adds the two binary strings x0032 and x0033, producing x0065. When that value is displayed on the monitor, it is treated as an ASCII code. Since x0065 is the ASCII code for a lowercase e, a lowercase e is displayed on the monitor.

18. why did we not get 5? (a) we didn’t convert the two input characters from ASCII to 2’s complement integers before performing the addition and (b) we didn’t convert the result back to ASCII before displaying it on the monitor.

19. Exercise: Correct Figure 10.1 so that it will add two single-digit positive integers and produce the correct single-digit positive sum. Assume that the two digits being added do in fact produce a single-digit sum.

20. Input Data (ASCII to Binary): Figure 10.2 shows the ASCII representation of the three-decimal-digit integer 295, stored as an ASCII string in three consecutive LC-3 memory locations, starting at ASCIIBUFF. R1 contains the number of decimal digits in the positive integer. Our ASCII to binary subroutine restricts integers to the range 0 to 999.

21. ASCIIBUFF is the address of the ﬁrst memory location of a sequence of four memory locations that we have allocated (a) to store the ASCII codes of decimal digits entered from the keyboard, and (b) to store the ASCII codes corresponding to the result of arithmetic operations in preparation for writing it (the result) to the monitor.

22. why is it done this way? in Figure 10.2, we used a whole 16-bit word to store the ASCII code of each decimal digit when a byte would have been enough. In fact, typically, one does store each ASCII code in a single byte of memory. In this example, we decided to give each ASCII character its own word of memory in order to simplify the algorithm.

23. why we are allocating four words of memory to ASCIIBUFF since we are restricting input to positive integers consisting of at most three decimal digits (Wouldn’t three words be enough)? For input yes, but in preparation for output, we will need one more word for the sign (positive or negative) of the result, since the result of the arithmetic could be negative.

24. Figure 10.3 shows the ﬂowchart for a subroutine that converts the ASCII representation of an integer, stored in Figure 10.2, into a binary integer.

25. how does it work? systematically takes each digit, converts it from its ASCII code to its binary code by stripping away all but the last four bits, and then uses those four bits to index into a table of ten binary values.

26. Since we are restricting conversion to integers consisting of at most three decimal digits, only two tables are needed, one for the tens digit and one for the hundreds digit. Each entry in each table corresponds to the value of one of the ten digits. For example, the entry for index 6 in the hundreds table is the value #600, which is in binary 0000001001011000. That value is then added to R0. R0 is used to accumulate the contributions of all the digits. The result is returned in R0.

27. Question: If we wanted to be able to convert four decimal-digit integers, would we need a table of thousands digits? Or, is there a way to convert larger numbers represented as larger decimal strings into their binary form without requiring a table of thousands digits, ten-thousands digits, etc.?

28. Figure 10.4 shows the LC-3 code that implements this subroutine. There are two points that we need to make about the subroutines in this chapter, which are all part of our calculator simulation. First, they cannot be assembled individually, and second (because of that) we need to be sure that no label is used more than once.

29. Why can't the subroutine of Figure 10.4 be assembled by itself? Answer: Line 33 speciﬁes a .FILL having the value ASCIIBUFF, but there is no location in the subroutine labeled ASCIIBUFF. Therefore, trying to assemble the subroutine by itself will fail. 

30. We could have used .EXTERNAL, discussed brieﬂy in Chapter 7, to enable the subroutines to be assembled individually, but we chose to not do that, preferring to assemble the entire calculator-simulator program including its eleven subroutines as a single entity. As you would expect, line 42 in the code of Figure 10.15 contains the label ASCIIBUFF.

31. Second, if we are to assemble the main program and all the subroutines as a single unit, we need to be sure to not use the same label in more than one subroutine. Note that in Figure 10.4, most labels start with “AtoB .” As expected, the same pattern of labeling is used in the rest of the subroutines.

32. Display Result (Binary to ASCII): To display the result of a computation on the monitor, we must ﬁrst convert the 2’s complement integer result into an ASCII string. Figure 10.5 shows the subroutine for converting a 2’s complement integer stored in R0 into an ASCII string stored in the four consecutive memory locations starting at ASCIIBUFF. The value ini- tially in R0 is restricted to the range −999 to +999. After the subroutine completes execution, ASCIIBUFF contains the sign (+ or −) of the value initially stored in R0, followed by three locations that contain the ASCII codes corresponding to the decimal digits representing its magnitude.

33. The subroutine works as follows: First, the sign of the result to be displayed is determined, and the ASCII code for + or − is stored in ASCIIBUFF. The result (in R0) is replaced by its absolute value. The algorithm determines the hundreds-place digit by repeatedly subtracting #100 from R0 until the result goes negative. This is next repeated for the tens-place digit. The value left is the ones digit.

34. The Stack as Temporary Storage: You know that the LC-3 ADD instruction takes two source operands that are stored in registers, performs an addition, and stores the result into one of the LC-3’s eight general purpose registers.

35. what do we call the register where the result is stored? destination register

36. The eight general purpose registers R0 to R7 comprise the temporary storage that allows operate instructions like ADD to access both source registers and the destination register much more quickly than if the computer had to access memory for the operands.

37. Because the three locations are speciﬁed explicitly [ADD  R0,R1,R2] we call the LC-3 a three-address machine. 

38. Most desktop and laptop computers are either three-address machines like the LC-3 or two-address machines like the x86 ISA that is implemented in many of your laptop and desktop computers. In a two-address machine, two locations are speciﬁed explicitly. An example of an x86 ADD instruction is [ADD   EAX,EBX] where EAX and EBX are two of the eight general purpose registers in the x86 ISA. In this case, EAX serves as both the location of one of the source operands and the location of the destination operand. With a two-address machine, one of the source registers is overwritten with the result of the operation.

39. There are also ISAs that do not use general purpose registers at all to store either source operands or the results of operate instructions. The most common of these are called stack machines because a stack is used for temporary storage.
Most calculators, including the one we will simulate, use a stack for temporary storage rather than a set of general purpose registers.

40. how are source operands obtained? by popping the top two elements from the stack. 

41. where is the result stored? pushed onto the stack.

42. Since the computer always pops and pushes operands from the stack, no addresses need to be speciﬁed explicitly. Therefore, stack machines are sometimes referred to as zero-address machines.

43. The instruction would simply be [ADD] and the computer would know where to ﬁnd the operands. Note that the pop, push, and add are not part of the ISA of the computer, and therefore they are available to the programmer. They are control signals that the hardware uses to make the actual pop, push, and add occur. The control signals are part of the microarchitecture, similar to the load enable signals and mux select signals we discussed earlier. As is the case with LC-3 instructions LD and ST, and control signals PCMUX and LD.MDR, the programmer simply instructs the computer to ADD, and the microarchitecture does the rest. 

44. An Example: Suppose we want to evaluate (A + B) ⋅ (C + D), where A contains 25, B contains 17, C contains 3, and D contains 2, and store the result in E. If the LC-3 had a multiply instruction (we would probably call it MUL), we could use the following program:

LD   R0,A
LD   R1,B
ADD  R0,R0,R1
LD   R2,C
LD   R3,D
ADD  R2,R2,R3
MUL  R0,R0,R2
ST   R0,E

45. With a calculator, we would execute the following eight operations:

push      25
push      17
add
push      3
push      2
add 
multiply 
pop       E

with the ﬁnal result popped (i.e., 210) being the result of the computation.

46. Figure 10.6 shows a snapshot of the stack after each of the eight operations. Note that in this example we have allocated memory locations x3FFB to x3FFF for our stack, and the stack pointer is initially at x4000, indicating that there is nothing initially on the stack.

47. The program we write to simulate a calculator will need three subroutines to be able to perform addition, subtraction, and multiplication. what are they? 

a. OpAdd, which will pop two values from the stack, add them, and push the result onto the stack.
b. OpMult, which will pop two values from the stack, multiply them, and push the result onto the stack.
c. OpNeg, which will pop the top value, form its 2’s complement negative value, and push the result onto the stack. This will allow us to subtract two numbers A minus B by ﬁrst forming −B and then adding the result to A.

48. The OpAdd Subroutine: Figure 10.7 shows the ﬂowchart of the OpAdd subroutine. Basically, it attempts to pop two values oﬀ the stack and, if successful, add them. If the result is within the range of acceptable values (i.e., an integer between −999 and +999), then the result is pushed onto the stack.

50. what are two things that could prevent OpAdd from completing successfully? fewer than two values are available on the stack for source operands, or the result is out of range.

51. In both cases, the stack is put back to the way it was at the start of the OpAdd subroutine. If the ﬁrst pop is unsuccessful, the stack is not changed since the POP routine leaves the stack as it was. If the second of the two pops reports back unsuccessfully, the stack pointer is decremented, which eﬀectively returns the ﬁrst value popped to the top of the stack. If the result is outside the range of acceptable values, then the stack pointer is decremented twice, returning both values to the top of the stack.

52. The OpAdd subroutine is shown in Figure 10.8. Note that the OpAdd subroutine calls the RangeCheck subroutine. This is a simple test to be sure the result of the computation is within what can successfully be stored in a single stack location. For our purposes, we restrict values to integers in the range −999 to +999. The ﬂowchart for the RangeCheck subroutine is shown in Figure 10.9. The LC-3 program that implements this subroutine is shown in Figure 10.10.

53. The OpMult Subroutine Figure 10.11 shows the flowchart of the OpMult subroutine, and Figure 10.12 shows the LC-3 program that implements it. Similar to the OpAdd subroutine, the OpMult subroutine attempts to pop two values off the stack and, if successful, multiplies them. Since the LC-3 does not have a multiply instruction, multiplication is performed as we have done in the past as a sequence of adds. Lines 17 to 19 of Figure 10.12 contain the crux of the actual multiply. If the result is within the range of acceptable values, then the result is pushed onto the stack.

54. If the second of the two pops reports back unsuccessfully, the stack pointer is decremented, which eﬀectively returns the ﬁrst value popped to the top of the stack. If the result is outside the range of acceptable values, which as before will be indicated by a 1 in R5, then the stack pointer is decremented twice, returning both values to the top of the stack.

55. The OpNeg Subroutine: To perform subtraction with the top two elements on the stack, we ﬁrst replace the top element on the stack with its negative and then use OpADD. That is, if the top of the stack contains A, and the second element on the stack contains B, we can push B−A on the stack by ﬁrst negating the top of the stack and then performing OpAdd. The subroutine OpNeg for computing the negative of the element on the top of the stack is shown in Figure 10.13.

56. The Calculator functionality: our calculator will allow a user to enter positive integers consisting of not more than three decimal digits, perform basic arithmetic (addition, subtraction, and multiplication) on these integers, and display the decimal result (which will also be limited to at most three decimal digits). We will use the keyboard to tell the calculator what to do. We can enter positive integers having up to three decimal digits, the arithmetic operators + (for ADD), * (for MUL), and − (for negative), and three additional commands D (to display the result of the calculation on the monitor), C (to erase all values entered), and X (to turn oﬀ the calculator).

57. The calculator algorithm works as follows: We use the keyboard to input commands and decimal values. We use the monitor to display results. We use a stack to hold source operands for performing arithmetic operations and the results of those arithmetic operations. Values entered and displayed are restricted to three decimal digits, that is, only values between −999 and +999, inclusive.

58. Figure 10.14 is a ﬂowchart that provides an overview of our algorithm that simulates a calculator. Simulation of the calculator starts with initialization, which includes setting R6, the stack pointer, to an empty stack. Then the user sitting at the keyboard is prompted with: “Enter a Command.”

59. The following commands are available to the user.

X Exit the simulation.
D Display the value at the top of the stack.
C Clear all values from the stack.
+ Pop the top two elements A,B oﬀ the stack and push A+B.
* Pop the top two elements A,B oﬀ the stack and push A*B.
− Pop the top element A oﬀ the stack and push “minus” A.
Enter or LF Push the value typed on the keyboard onto the top of the stack.

60. If the user wants to enter a number, he/she types the number (up to three decimal digits) followed by <Enter> or <Line Feed (LF)>.

61. Input is echoed, and the calculator simulation systematically tests the character to identify the user’s command. Depending on the user’s command, the calculator calls the appropriate subroutine to carry out the work speciﬁed. After the work is carried out, the subroutine returns, followed by a prompt for another command. The calculator simulation continues in this way until the user presses X, signaling that the user is ﬁnished with the calculator.

62. For example, to calculate

(51  -  49)  *  (172  +  205)  -  (17  *  2)

and display the result 720 on the monitor, one types the following sequence of keys on the keyboard:

5,1,LF,4,9,LF,−,+,1,7,2,LF,2,0,5,LF,+,*,1,7,LF,2,LF,*,−,+,D.

63. Code: Twelve routines comprise the calculator simulation. Figure 10.15 is the main algorithm, supported by eleven subroutines. Note the three global labels, StackMax, StackBase, and ASCIIBUFF, are all part of the main algorithm, shown in Figure 10.15. They provide the symbol table entries needed by the subroutines that reference those locations. Note also that the stack has been allocated ten entries in the main algorithm, and R6, the stack pointer, is initialized to an empty stack in line 05.

64. Figure 10.16 takes an ASCII string of characters terminating by a LF, checks to be sure it corresponds to a string of not more than three decimal digits, and if so, converts it to a binary number, then pushes the binary number onto the top of the stack. 

65. Figure 10.4 provides the ASCII-to-binary conversion routine. Figure 10.19 pops the entry on the top of the stack, converts it to an ASCII character string, and displays the ASCII string on the monitor. Figure 10.5 provides the binary- to-ASCII conversion routine. Figures 10.8 (OpAdd), 10.12 (OpMult), and 10.13 (OpNeg) supply the basic arithmetic algorithms using a stack. Figures 10.17 and 10.18 contain the basic POP and PUSH routines Finally, Figure 10.20 clears
the stack.

chapter 11

1. We’ve just completed an introduction to the basic underlying structure of modern computing devices. Be it on a smartphone or in a smart car, the underlying mechanisms for processing digital data are very much the same. With these foundational concepts solidly in place, we are now well prepared to explore programming in a high-level programming language.

2. this chapter will cover high-level programming concepts in the context of the C and C++ programming languages. At every step, with every new high-level concept, we will be able to make a connection to the lower levels of the digital system.

3. In the ﬁrst ten chapters, we described the LC-3, a simple computing architecture that has all the important characteristics of a more complex, real system. A basic idea behind the LC-3 (and indeed, behind all modern digital systems) is that simple elements are systematically interconnected to form elements with more complex capabilities. MOS transistors are connected to build logic gates. Logic gates are used to build memory and data path elements. Memory and data path elements are interconnected to build the LC-3. 

4.  This systematic connection of simple elements to create something more sophisticated is an important concept that is pervasive throughout computing, not only in hardware design but also in software design. 

5. After describing the hardware of the LC-3, we programmed it in the 1s and 0s of its native machine language. Having gotten a taste of the error-prone and unnatural process of programming in machine language, we quickly moved to the more user-friendly LC-3 assembly language.

6. We examined how low-level TRAP subroutines perform commonly needed tasks, such as input and output, on behalf of the programmer. Systematic decomposition and subroutines are prevalent design paradigms for software. 

7. In this half of the book, our primary objectives are to introduce fundamental high-level programming constructs—variables, control structures, functions, arrays, pointers, recursion, simple data structures—and to teach a good problem solving methodology for attacking programming problems. Our primary vehicles for doing so are the C and C++ programming languages.

8. complete coverage of C or C++ will not be provided as both are vast programming languages (particularly C++). Some of the most widely used apps, cloud services, and devices are built using C or C++. 

9. It is almost always the software that enables a digital system to do its thing. In devices we might not consider to be software-driven, such as a smart speaker or Bluetooth headphones, there is a large body of software embedded in the device to implement its features. It’s the software that animates the device.

10. Enabling these sophisticated capabilities requires larger and more complex bodies of software. A typical smartphone app might consist of hundreds of thousands of lines of code, a web browser several million, and the code to power a modern automobile (nonautonomous) might range in the hundreds of millions of lines. Over time, from generation to generation, the software needed to power these devices has grown in complexity. As the underlying hardware becomes faster and our demand for additional capabilities grows, we expect the amount of software needed to continue to grow as well. 

11. Figure 11.1. provides a graphical view of the sizes of software systems for various applications.

12. Programming languages such as C and C++ were created for one primary purpose: to increase programmer productivity. The most commonly used languages enable teams of programmers to more rapidly and maintainably develop correctly working code. Without eﬀective programming languages and corresponding development environments, our ability to create these incredible devices would be severely diminished.

13. Clearly, LC-3 assembly language isn’t going to be the language of choice for developing most real-world software (nor are the assembly languages for x86 or ARM, which are the two most widespread instruction set architectures today, powering nearly all of our PCs, servers, and mobile devices). But it is the case that whatever the development language, C or C++ or Java or Python, the code is ultimately, and automatically, translated into the instruction set of the under- lying hardware (be it ARM or x86 or LC-3).

14. So the conceptual process here is that the programming language enables us humans to express code in a much more human-friendly way and in a manner that can be automatically, and unambiguously, translated into a machine-executable form.

15. As we made the transition from LC-3 machine language in Chapters 5 and 6 to LC-3 assembly language in Chapter 7, you no doubt noticed and appreciated how assembly language simplified programming the LC-3. The 1s and 0s became mnemonics, and memory addresses became symbolic labels. Both instructions and memory addresses took on a form more comfortable for the human than for the machinery. The assembler filled some of the gap between the algorithm level and the ISA level in the levels of transformation (see Figure 1.6). We would like the language level to fill more of that gap. High-level languages do just that. They help make the job of programming easier. 

16. High-level languages help manage the values upon which we are computing: When programming in machine language, if we want to keep track of the iteration count of a loop, we need to set aside a memory location or a register in which to store the counter value. To update the counter, we need to remem- ber the spot where we last stored it, load it, operate, and store it back in that location. The process is easier in assembly language because we can assign a meaningful label to the counter’s memory location. In a higher-level language such as C, the programmer simply gives the value a meaningful symbolic name and the programming language takes care of allocating storage for it and perform- ing the appropriate data movement operations whenever we refer to it in our code. Since most programs contain lots of values, having such a convenient way to handle these values is critical to enhancing programmer productivity.

17. High-level languages provide a human-friendly way to express computation: Most humans are more comfortable describing the interaction of objects in the real world than describing the interaction of objects such as integers, characters, and ﬂoating point numbers in the digital world. Because of their human-friendly orientation, high-level languages enable the programmer to be more expressive. In a high-level language, the programmer can express complex tasks with a smaller amount of code, with the code itself looking more like a human language. 

18. High-level languages provide an abstraction of the underlying hardware: High-level languages provide a uniform programmer interface independent of underlying hardware. And this provides two distinct advantages. First, our code becomes portable. C or C++ or Java code can be easily and eﬃciently targeted for a variety of diﬀerent devices, independent of their hardware. Code written directly in assembly language takes advantage of the speciﬁcs of a particular hardware system and isn’t as easy to run on diﬀerent hardware. It’s easy to understand why portability is important: An app developer who has written an app for Android will want to quickly port the app to iOS to take advantage of the large base of Apple devices.

19. The second advantage is that we use operations that aren’t natively supported by the hardware. For example, in the LC-3, there is no single instruction that performs an integer multiplication. Instead, an LC-3 assembly language programmer must write a small piece of code to perform multiplication. The set of operations supported by a high-level language is usually larger than the set supported by the ISA. The language will generate the necessary code to carry out the operation whenever the programmer uses it. The programmer can concentrate on the actual programming task knowing that these high-level operations will be performed correctly and without having to deal with the low-level implementation.

20. High-level languages enhance maintainability: Since common control structures are expressed using simple, English-like statements, the program itself becomes easier to read and therefore easier for others to modify and ﬁx. One can look at a program in a high-level language, notice loops and decision constructs, and understand the code with less eﬀort than with a program written in assembly language. No doubt you’ve had to get reacquainted with your own LC-3 assem- bly code after spending even a couple of hours away from it. It’s no fun! Often as programmers, we are given the task of debugging or building upon someone else’s code. If the organization of the language is human-friendly to begin with, then understanding code in that language is a much simpler task.

21. Many high-level languages provide safeguards against bugs: By making the programmer adhere to a stricter set of rules, the language can make checks as the program is translated or as it is executed. If certain rules or conditions are violated, an error message will direct the programmer to the spot in the code where the bug is likely to exist. In this manner, the language helps programmers to get their programs working more quickly.

22. All high level languages must be translated into machine code. How is this translation done? depends on the design of the particular high-level language.

23. One translation technique is called interpretation. With interpretation, a translation program called an interpreter reads in the high-level language program and performs the operations indicated by the programmer. The high-level language program does not directly execute but rather is executed by the interpreter program.

24. The other technique is called compilation, and the translator is a compiler. The compilation process completely translates the high-level language program into machine language, or a form very close to machine language. An executable image is an output of the compilation process. It can directly execute on the hardware. Keep in mind that both interpreters and compilers are themselves pieces of software running on some device.

25. interpretation: with interpretation, a high-level language program is a set of “commands” for the interpreter program. The interpreter reads in the commands and carries them out as deﬁned by the language. The high-level language program is not directly executed by the hardware but is in fact just input data for the interpreter. The interpreter is a virtual machine that executes the program in an isolated sandbox.

26. Many interpreters translate the high-level language program section by section, one line, command, or subroutine at a time. For example, the interpreter might read a single line of the high-level language program and directly carry out the eﬀects of that line on the underlying hardware. If the line said, “Take the square root of B and store it into C,” the interpreter will carry out the square root by issuing the correct stream of instructions in the ISA of the computer to perform square root. Once the current line is processed, the interpreter moves on to the next line and executes it. This process continues until the entire high-level language program is done.

27. Compilation: with compilation, on the other hand, a high-level language program is translated into machine code that can be directly executed on the hardware. To do this eﬀectively, the compiler must analyze the source program as a larger unit (usually, the entire source ﬁle) before producing the translated version. A program need only be compiled once, and it can be executed many times. A compiler processes the ﬁle (or ﬁles) containing the high-level language program and pro- duces an executable image. The compiler does not execute the program (although some sophisticated compilers do execute the program in order to better optimize its performance), but instead only transforms it from the high-level language into the computer’s native machine language.

28. Pros and Cons: With interpretation, developing and debugging a program are usually easier. Interpreters often permit the execution of a program one section (a single line, for example) at a time. This allows the programmer to examine intermediate results and make code modiﬁcations on the ﬂy. Often the debugging is easier with interpretation. Interpreted code is more easily portable across diﬀerent computing systems. However, with interpretation, programs take longer to execute because there is an intermediary, the interpreter, which is actually doing the work. With compilation, the programmer can produce code that executes more quickly and uses memory more eﬃciently. Since compilation produces more eﬃcient code, most production software tends to be programmed in compiled languages.

29. Because of their popularity and close-to-the-metal, low-level approach, C and C++ are the ideal languages for our bottom-up exploration. We’ll spend the bulk of our time with the C language in Chapters 11 through 19, and we will intro- duce some core C++ concepts in Chapter 20. Because C++ is based on C, the C-speciﬁc material we cover will help in our understanding of C++.

30. Both C and C++ are highly developed, heavily evolved languages that support large-scale programming. We will not be covering all aspects of C or C++ in this textbook; instead, we will cover the common core subset that will enable you to write code on the order of hundreds of lines by yourself in a single source code ﬁle.

31. Our objective is to give you a grounding in digital systems, hardware, and software. This grounding will be useful in your subsequent courses in data structures and software engineering for more complex software projects.

32. All of the examples and speciﬁc details of C presented in this text are based on a standard version of C called ANSI C, or C18.

33. As with many programming languages, several variants of C have been introduced throughout the years. The American National Standards Institute (ANSI) approves “an unambiguous and machine-independent deﬁnition of the language C” in order to standardize the language, promoting portability of C code across diﬀerent systems and compilers. The most recently adopted version of ANSI C is from 2018 and is thus referred to as C18. Likewise, we’ll use ISO C++, often called Standard C++, in our examples involving C++ code.

34. Many of the new C and C++ concepts we present will be coupled with LC-3 code generated by a hypothetical LC-3 C compiler. In some cases, we will describe what actually happens when this code is executed. Keep in mind that you are not likely to be using an LC-3–based computer but rather one based on a real ISA such as the x86 or ARM. For example, if you are using a Windows-based PC, then it is likely that your compiler will generate x86 code, not LC-3 code. Many of the examples we provide are complete programs that you can compile and execute. 

35. For the sake of clearer illustration, some of the examples we provide are not quite complete programs and need to be completed before they can be compiled. In order to keep things straight, we’ll refer to these partial code examples as code segments.

36. The Compilation Process: The C or C++ compiler follows the typical mode of translation from a source program to an executable image.

37. what is an executable image? is a machine language representation of a program that is ready to be loaded into memory and executed. 

38. The compilation mechanism involves several distinct components, notably the preprocessor, the compiler itself, and the linker. Figure 11.2 shows the overall compilation process for C. 

39. The Preprocessor: The preprocessor scans through the source ﬁles (the source ﬁles contain the actual C program) looking for and acting upon prepro- cessor directives. These directives are similar to pseudo-ops in LC-3 assembly language. They instruct the preprocessor to transform the source ﬁle in some controlled manner. For example, we can direct the preprocessor to substitute the character string DAYS_THIS_MONTH with the string 30 or direct it to insert the contents of ﬁle stdio.h into the source ﬁle at the current line. All preprocessor directives begin with a pound sign, #, as the ﬁrst character. 

40. The Compiler: After the preprocessor transforms the input source ﬁle, the program is ready to be handed over to the compiler. The compiler transforms the preprocessed program into an object module.

41. what is an object module? is the machine code for one section of the entire program. 

42. what are the two major phases of compilation? analysis, in which the source program is broken down or parsed into its constituent parts, and synthesis, in which a machine code version of the program is generated. It is the job of the analysis phase to read in, parse, and build an internal representation of the original program. The synthesis phase generates machine code and, if directed, tries to optimize this code to execute more quickly and eﬃciently on the computer on which it will be run. 

43. Each of these two phases is typically divided into subphases where speciﬁc tasks, such as parsing, register allocation, or instruction scheduling, are accomplished. Some compilers generate assembly code and use an assembler to complete the translation to machine code.

44. One of the most important internal bookkeeping mechanisms the compiler uses in translating a program is the symbol table. A symbol table is the compiler’s internal bookkeeping method for keeping track of all the symbolic names the programmer has used in the program. The compiler’s symbol table is very similar to the symbol table maintained by the LC-3 assembler

45. The Linker: The linker takes over after the compiler has translated the source ﬁle into object code. It is the linker’s job to link together all object modules to form an executable image of the program. The executable image is a version of the program that can be loaded into memory and executed by the underlying hardware. 

46. When you click on the icon for the web browser or launch an app on your phone, for example, you are instructing the operating system to load the app’s executable image into memory and start executing it.

47. Often, C programs rely upon library routines. Library routines perform common and useful tasks (such as I/O) and are prepared for general use by the developers of the system software (the operating system and compiler, for example). If a program uses a library routine, then the linker will ﬁnd the object code corresponding to the routine and link it within the ﬁnal executable image. Usually, library ﬁles are stored in a particular place, depending on the computer system.

48. Note that in ANSI C, main must be declared to return an integer value, and therefore the keyword
int precedes the name of the function main.

49. Variables are a useful and elementary feature provided by all high-level programming languages. They give us a way to symbolically name the values within a program rather than referring to them by the memory location or register in which they are stored.

50. C is a free-format language. That is, white space (spaces and tabs and line breaks) between words and between lines within a program does not change the meaning of the program.

51. the #include directive instructs the preprocessor literally to insert another source ﬁle into the code at the point where the #include appears. Essentially, the #include directive itself is replaced by
the contents of another ﬁle.

52. All C programs that perform typical input and output must include C’s input/output library’s header ﬁle stdio.h. This ﬁle deﬁnes some relevant information about the I/O functions in the library. The preprocessor directive #include <stdio.h> is used to insert the header ﬁle before compilation begins.

53. if a specified header file includes < >, it tells the preprocessor that the header ﬁle can be found in a predeﬁned system directory. This is usually determined by the conﬁguration of the system, and it contains many common system-related header ﬁles, such as stdio.h.

54. if a header file includes double quotes (" ") around the ﬁlename, it tells the preprocessor that the header ﬁle can be found in the same directory as the C source ﬁle or in some other directory known to the compiler.

chapter 12

1. Variables hold the values upon which a program acts, and operators are the language constructs for manipulating these values.

2. High-level languages enable the programmer to refer to values symbolically, by a name rather than the storage location where the value resides. To operate on the value, referring to the symbolic name suﬃces, and the actual storage location is abstracted away.

3. The compiler generates the full set of data movement operations to access the value from wherever it resides in memory. The programmer can focus on writing the logic of the program without concern about where values are currently stored. In high-level languages, these symbolically named values are called variables.

4. Variables are the most basic type of memory object. An object is a named unit of data stored in memory with certain characteristics and behaviors.

5. In order to properly track the variables in a program, the C or C++ compiler needs to know several characteristics about each variable, which are ultimately provided by the programmer. The compiler needs to know the symbolic name of the variable. It needs to know what type of information the variable will contain. It needs to know where in the code the variable will be accessible. In C and C++, this information is provided by the variable’s declaration.

6. The meaning of a particular bit pattern depends on the data type imposed on the pattern. For example, the binary pattern 0110 0110 might represent the lowercase f or it might represent the decimal number 102, depending on whether we treat the pattern as an ASCII data type or as a 2’s complement integer data type.

7. A variable’s declaration informs the compiler about the variable’s type. The compiler uses a variable’s type information to allocate a proper amount of storage for the variable. Also, type indicates how operations on the variable are to be performed at the machine level. For instance, performing an addition on two integer variables can be done on the LC-3 with one ADD instruction. If the two variables are of ﬂoating point type, the LC-3 compiler would generate a sequence of instructions to perform the addition because no single LC-3 instruction performs a ﬂoating point addition.

8. C supports four basic data types: integers, characters, ﬂoating point numbers, and boolean values. Variables of these types can be created with the type speciﬁers int, char, ﬂoat (or double), and _Bool (or bool).

9. The internal representation and range of values of an int depend on the ISA of the underlying hardware. In the LC-3, for example, an int is a 16-bit 2’s complement integer that can represent values between −32,768 and +32,767. On an x86-based system, an int is likely to be a 32-bit 2’s complement number that can represent values between −2,147,483,648 and +2,147,483,647. In most cases, an int is a 2’s complement integer in the word length of the underlying ISA.

10. Floating point literals are represented containing either a decimal point or an exponent, or both, as demonstrated in the example code that follows. The exponent is signiﬁed by the character e or E and can be positive or negative. It represents the power of ten by which the fractional part (the part that precedes the e or E) is multiplied. Note that the exponent must be an integer value.

double twoPointOne = 2.1;               // This is 2.1
double twoHundredTen = 2.1E2;           // This is 210.0
double twoHundred = 2E2;                // This is 200.0
double twoTenths = 2E-1;                // This is 0.2
double minusTwoTenths = -2E-1;          // This is -0.2
double extTemp = -0.2;                  // This is -0.2

11. The precision of a ﬂoating point number depends on the number of bits of the representation allocated to the fraction. In C, depending on the compiler and the ISA, a double may have more bits allocated for the fraction than a ﬂoat, but never fewer. The size of the double is dependent upon the ISA and the compiler. Usually, a double is 64 bits long and a ﬂoat is 32 bits in compliance with the IEEE 754 ﬂoating point standard.

12. The _Bool type is a more recent addition to the C language and is now part of the ANSI standard. A variable of the _Bool type takes on the values 0 or 1, representing a value that can be false or true. This type was supported natively by C++, and later supported by C, and it provides a representation for a commonly occurring value in our code.

13. The C type speciﬁer for a boolean type is _Bool. A more convenient way to accomplish the same is to use the bool speciﬁer. To do so, we need to include the stdbool.h header ﬁle. This header ﬁle also deﬁnes true to symbolically map to 1, and false to map to 0.

_Bool flag = 1;         // Initialized to 1 or true
bool test = false;      // Initialized to false, which is symbolically defined to 0. Requires stdbool.h

14. Choosing Identiﬁers: Variables beginning with an underscore (e.g., _index_) conventionally are used only in special library code. Variables are almost never declared in all uppercase letters. The convention of all uppercase is used solely for symbolic values created using the preprocessor directive #deﬁne.

15. a variable’s declaration assists the compiler in managing the storage of that variable. In C, a variable’s declaration conveys three pieces of information to the compiler: the variable’s identiﬁer, its type, and its scope. The ﬁrst two of these, identiﬁer and type, the C compiler gets explicitly from the variable’s declaration. The third piece, scope, the compiler infers from the position of the declaration within the code. The scope of a variable is the region of the program in which the variable is “alive” and accessible. The good news is that in C, there are only two basic types of scope for a variable. Either the variable is global to the entire program, or it is local, or private, to a particular block of code.

16. If a variable is declared within a block, it is visible up through the end of the block. In C, a block is any subsection of a program beginning with the open brace character, {, and ending with the closing brace character, }. These variables are local to the block in which they are declared.

17. In contrast to local variables, which can only be accessed within the block in which they are declared, global variables can be accessed throughout the program. They retain their storage and values throughout the duration of the program.

18. What initial value will a variable have if it has no initializer? In C, by default, local variables start with an undeﬁned value. That is, local variables have garbage values in them, unless we explicitly initialize them in our code. Global variables, in contrast, are initialized to 0.

19. Operator Precedence and Associativity in C; see table125

20. our C compiler keeps track of variables in a program with a symbol table. Whenever the compiler reads a variable declaration, it creates a new entry in its symbol table corresponding to the variable being declared. The entry contains enough information for the compiler to manage the storage allocation for the variable and generation of the proper sequence of machine code whenever the variable is used in the program. For now, we’ll consider that each symbol table entry for a variable contains (1) its identifier, (2) its type, (3) the place in memory the variable has been allocated storage, and (4) the scope of the variable, which for our purposes will be the line numbers in the code corresponding to where the variable is in scope. Figure 12.5 shows the symbol table entries corresponding to the variables declared in the network rate calculation program in Figure 12.4. 

21. Since this program contains six variable declarations, the compiler ends up with six entries in its symbol table, one for each. Notice that the compiler records a variable’s location in memory as an oﬀset, with most oﬀsets being negative. This oﬀset indicates the relative position of the variable within the region of memory in which it is allocated. Important concept. 

22. Allocating Space for Variables: There are two regions of memory in which declared variables in C are allocated storage: the global data section and the run-time stack. Variables that are global are allocated storage in the global data section. Local variables are allocated storage on the run-time stack. The oﬀset ﬁeld in the symbol table enables the compiler to precisely locate those variables in either of those two regions. The oﬀset ﬁeld indicates how many locations from the base of the section a variable is allocated storage.

23. For instance, if a global variable earth has an oﬀset of 4 and the global data section starts at memory location 0x5000, then earth is stored in location 0x5004. If R4 contained the address of the beginning of the global data section, then loading the variable earth into R3 can be accomplished with the following LC-3 instruction

LDR R3, R4, #4

24. If earth is instead a local variable, say for example in the function main,the variable is on the run-time stack, in units of allocation called activation records or stack frames. Whenever a function starts to execute, its stack frame is added to the run-time stack. A stack frame is a region of contiguous memory locations that contains all the local variables for a given function.

25. Whenever a particular function is executing, the highest numbered memory address of its stack frame will be stored in R5—which is called the frame pointer. For example, the stack frame for the function main from the code in Figure 12.4 is shown in Figure 12.6. The variables are allocated in the record in the reverse of the order in which they are declared. Since the variable amount is declared ﬁrst, it appears closest to the frame pointer R5.

26. If we make a reference to a particular local variable, the compiler will use the variable’s symbol table entry to generate the proper code to access it. The oﬀset in the variable’s symbol table entry indicates where in the stack the variable has been allocated storage. To access the variable seconds, the compiler would generate the instruction

LDR R0, R5, #-5

27. Whenever we call a function in C (functions are C’s notion of subroutines), the stack frame for the function is pushed onto the run-time stack. That is, the function’s stack frame is allocated on top of the stack. R5 is appropriately adjusted to point to the base of the record—therefore, any code within the function that accesses local variables will now work correctly using the oﬀsets as recorded in the symbol table. Whenever the function completes and control is about to return to the caller, the activation record is popped oﬀ the stack. R5 is adjusted to point to the caller’s activation record. Throughout all of this, R6 always contains the address of the top of the run-time stack—it is called the stack pointer.

28. Figure 12.7 shows the organization of the LC-3’s memory when a program is running. The program itself occupies a region of memory (labeled Program text in the diagram); so does the run-time stack and the global data section. There is another region reserved for dynamically allocated data called the heap. Both the run-time stack and the heap can change size as the program executes. For example, whenever one function calls another, the run-time stack grows because we push another activation record onto the stack—in fact, it grows toward memory address x0000. In contrast, the heap grows toward 0xFFFF. Since the stack grows toward x0000, the organization of an activation record appears to be “upside-down”; that is, the ﬁrst local variable appears at the memory location pointed to by R5, the next one at R5 - 1,the subsequent one at R5-2, and so forth (as opposed to R5,R5+1,R5+2, etc).

29. During execution, the PC points to a location in the program text, R4 points to the beginning of the global data section, R5 points within the run-time stack, and R6 points to the very top of the run-time stack. There are certain regions of memory, marked System space in Figure 12.7, that are reserved for the operating system, for things such as TRAP routines, vector tables, I/O registers, and boot code.

30. Figure 12.8 is the source code for a complete C program that performs some simple operations on integer variables and then outputs the results of these operations. The program contains one global variable, inGlobal, and three local variables, inLocal, outLocalA, and outLocalB, which are local to the function main. The program starts oﬀ by assigning initial values to inLocal (which is initialized in the declaration) and inGlobal. After the initialization step, the variables outLocalA and outLocalB are updated based on two calculations performed using inLocal and inGlobal. After the calculation step, the values of outLocalA and outLocalB are output using the printf library function. Notice that because we are using printf, we must include the standard I/O library header ﬁle, stdio.h.

31. When analyzing this code, the LC-3 C compiler will assign the global variable inGlobal the ﬁrst available spot in the global data section, which is at oﬀset 0. When analyzing the function main, it will assign inLocalA to oﬀset 0, outLocalA to oﬀset −1, and outLocalB to oﬀset −2 within main’s stack frame.

32. A snapshot of the compiler’s symbol table corresponding to this program along with the activation record of main is shown in Figure 12.9. The resulting assembly code generated by the LC-3 C compiler is listed in Figure 12.10. Execution starts at the instruction labeled main.

33. C gives the programmer the ability to specify larger or smaller versions of the basic types int, char, ﬂoat, and double. The modiﬁers long and short can be attached to int with the intent of extending or shortening the default size. For example, a long int can declare an integer that has twice the number of bits of a regular int, thereby allowing us to represent a larger range of integers in a C program. Similarly, the speciﬁer long can be attached to the double type to create a larger ﬂoating point type (if supported by the particular system) with greater range and precision.

34. The modiﬁer short can be used to create variables that are smaller than the default size, which can be useful when trying to conserve on memory space when handling data that does not require the full range of the default data type.

35. Because the size of the three basic C types is closely tied to the types supported by the underlying ISA, many compilers only support these modiﬁers long and short if the device’s ISA supports these size variations. Even though a variable can be declared as a long int, it may be equivalent to a regular int if the underlying ISA has no support for longer versions of the integer data type.

36. Another useful variation of the basic int data type is the unsigned integer. We can declare an unsigned integer using the unsigned type modiﬁer. With unsigned integers, all bits are used to represent nonnegative integers (i.e., posi- tive numbers and zero). 

37. In C, variables can also be declared as constants by adding the const qualiﬁer before the type speciﬁer. These constants are types whose values cannot be modiﬁed during the execution of a program; they are read-only. 

38. In C, we can represent literal constants in hexadecimal by prepending a 0x in front of them, for example 0x1DB. ASCII literals require single quotes around them, as for example 'R', which is the ASCII value of the character R. Floating point literals can be the exponential notation described earlier.

39. The third type of constant value is created using the preprocessor directive #deﬁne

40. The distinction between constants declared using const and symbolic values deﬁned using #deﬁne might seem a little subtle to you. Using one vs. another is really a matter of programming style rather than function.

chapter 13

1. Conditional constructs allow a programmer to select an action based on some condition. This is a very common programming idiom, and every useful programming language provides a convenient way of expressing it. C provides two types of basic conditional constructs: if and if-else.

2. The if statement is quite simple. It performs an action if a condition is true. The action is a C statement, and it is executed only if the condition, which is a C expression, evaluates to a non-zero (logically true) value. 

3. if (x == 2) y=5; Let’s look at the LC-3 code that is generated for this code, assuming that x and y are integers that are locally declared. This means that R5 will point to the variable x and R5 - 1 will point to y.

LDR R0, R5, #0  ; load x into R0
ADD R0, R0, #-2 ; subtract 2 from x
BRnp NOT_TRUE   ; If condition is not true, then skip the assignment
AND R0, R0, #0  ; R0<-0
ADD R0, R0, #5  ; R0<-5
STR R0, R5, #-1 ; y=5;
NOT_TRUE        ; the rest of the program

4. Notice that it is most straightforward for the LC-3 C compiler to generate code that tests for the opposite of the original condition (x not equal to 2) and to branch based on its outcome.

5. The ﬂow for the if-else is shown below 

if (condition) 
     action_if;
else
     action_else;

If the variable x is non-zero, the if’s condition is true, y is incremented, and z is decremented. Otherwise, y is decremented and z incremented. The LC-3 code generated by our LC-3 C compiler is listed in Figure 13.3. The three variables x, y, and z are locally declared integers.

6. An else is associated with the closest unassociated if. 

7. A while loop executes a statement repeatedly while a condition is true. Before each iteration of the statement, the condition is checked. If the condition evaluates to a logical true (non-zero) value, the statement is executed again. In the following example program, the loop keeps iterating while the value of variable x is less than 10. 

#include <stdio.h> 
int main(void)
{
     int x = 0;
     while (x < 10) { 
          printf("%d ", x); 
          x=x+1;
     } 
}

The LC-3 code generated by our compiler for the above while example that counts from 0 to 9 is listed in Figure 13.7.

8. The while statement is useful for coding loops where the iteration process involves testing for a sentinel condition. That is, we don’t know the number of iterations beforehand, but we wish to keep looping until some event (i.e., the sentinel) occurs. 

9. the for loop is a special case of the while loop that happens to work well when the number of iterations is known ahead of time. The syntax for the C for statement 

for (init; test; update)
     loop_body;

10. The init component is an expression (and optionally also a declaration) that is evaluated before the ﬁrst iteration. It is typically used to declare and initialize variables in preparation for executing the loop. The test is an expression that gets evaluated before every iteration to determine if another iteration should be executed. 

11. If the test expression evaluates to zero, the for terminates, and the control ﬂow passes to the statement immediately following the for. If the expression is non-zero, another iteration of the loop_body is performed. The update component is an expression that is evaluated at the end of every iteration. It is used to update things in preparation for the next iteration. 

12. Let’s take a look at the LC-3 translation of a simple for loop. The program is a simple one: It calculates the sum of all integers between 0 and 9.

#include <stdio.h>
int main(void)
{
     int x;
     int sum = 0;
     for (x = 0; x < 10; x++)
          sum = sum + x;
}

The LC-3 code generated by the compiler is shown in Figure 13.10. 

13. The break statement causes the compiler to gen- erate code that will immediately exit a loop or a switch statement. When used within a loop body, break causes the loop to terminate by jumping out to the end of the loop statement. No more iterations are executed. The continue statement, on the other hand, causes the current iteration to end. The next iteration might then execute, depending on the looping conditions. 

14. Essentially, the break and continue statements cause the compiler to generate an unconditional branch instruction that leaves the loop or loop iteration from somewhere in the loop body. 


chapter 14

1. Functions are such a necessary and important concept that we build support for them directly in the hardware at the instruction set architecture level.

2. Why are they so important? Functions (or procedures, or subroutines, or methods—all of which are variations of the same theme) enable abstraction. That is, they increase our ability to separate the operation performed by a component from the details of how it performs that operation.

3. The C programming language is heavily oriented around functions. A C program is essentially a collection of functions.

4. From every place in the program where a function is called, the actual arguments appearing in each call should match the type and ordering of the formal parameter list.

5. In C, the arguments of the caller are passed as values to the callee. 

6. What about the function main? Its return type is int (as required by the ANSI standard), yet it does not contain a return. Strictly speaking, we should include a return 0 at the end of main. In C, if a non-void function does not explicitly return a value, the value of the last statement is returned to the caller.

7. A function declaration informs the compiler about the function, indicating its name, the number and types of parameters the function expects from a caller, and the type of value the function returns. A function deﬁnition is the actual source code for the function. The deﬁnition includes a formal parameter list, which indicates the names of the function’s parameters and the order in which they will be expected from the caller. A function is invoked via a function call. Input values, or arguments, for the function are listed within the parentheses of the function call. Literally, the value of each argument listed in the function call is assigned to the corresponding parameter in the parameter list, the ﬁrst argument assigned to the ﬁrst parameter, the second argument to the second parameter, and so forth. The return value is the output of the function, and it is passed back to the caller function.

8. Functions in C are the high-level equivalent of subroutines at the LC-3 machine level. Functions in C are implemented using a similar set of mechanisms as assembly level subroutines. 

9. There are four basic phases in the execution of a function call: (1) Argument values from the caller are passed to the callee, (2) control is transferred to the callee, (3) the callee executes its task, and (4) control is passed back to the caller, along with a return value. In C, each function is required to be caller-independent. That is, a function should be callable from any function. With this requirement, functions become composable building blocks that we can use from anywhere in our code.

10. Run-Time Stack: At the assembly level, a function is just a sequence of instructions that is called using a JSR instruction. The RET instruction returns control back to the caller. We need a way to “activate” a function when it is called. That is, when a function starts executing, its local variables must be allocated somewhere in memory. There are many possible solutions, and here we’ll explore two options.

11. Option 1: The compiler could systematically assign places in memory for each function to place its local variables. Function A might be assigned the memory chunk starting at X for its local values, function B might be assigned the memory chunk starting at location Y, and so forth, provided, of course, that these memory chunks do not overlap. While this seems like the most straightforward way to manage the allocation, it has some limitations. What happens if function A calls itself? We call this recursion. If function A calls itself, then the callee version of function A will overwrite the local values of the caller version of function A, and the program will not behave as we expect it to. For the C programming language, which allows recursive functions, option 1 will not work. Also it’s a wasteful allocation of memory because a function will require storage (potentially a lot of storage) even if it isn’t executing.

12. Option 2: What if instead of allocating the space for local variables statically (i.e., in a ﬁxed place in memory), the space is allocated once the function starts executing? And when the function returns to the caller, its space is reclaimed to be assigned later to another function. And if the function is called from itself, the new invocation of the function will get its own space that is distinct from its other currently active invocations. This solves the issues raised with Option 1.

13. How should this allocation be done? We can utilize the idea that the calling pattern of functions can easily be tracked with a stack data structure. Each function has a memory template where it stores its local variables, some bookkeeping information, and its parameter variables. This template is called its stack frame or activation record. Whenever a function is called, its stack frame will be allocated somewhere in memory. And because the calling pattern of functions naturally follows a stack-like pattern, this allocation and deallocation will follow the pushes and pops of a stack.

14. The code in Figure 14.4 contains three functions, main, Watt, and Volt. What each function does is not important for this example, so we’ve omitted some of their details but provided enough so that the calling pattern between them is apparent. The function main calls Watt, and Watt calls Volt. Eventually, control returns to main, which then calls Volt.

15. This is illustrated in the diagrams of Figure 14.5. Each of the shaded regions represents the activation record or stack frame of a particular function call. The sequence of ﬁgures shows how the run-time stack grows and shrinks as the various functions are called and return to their caller. Keep in mind that, as we push items onto the stack, the top of the stack moves, or “grows,” toward lower-numbered memory locations.

16. Figure 14.5a is a picture of the run-time stack when the program starts execu- tion. Since the execution of a C program starts in main, the stack frame for main is the ﬁrst to be allocated on the stack. Figure 14.5b shows the run-time stack immediately after Watt is called by main. Notice that the stack frames are allocated in a stack-like fashion. That is, whenever a function is called, its stack frame is pushed onto the stack. Whenever the function returns, its frame is popped oﬀ the stack. Figure 14.5 parts (c) through (f) show the state of the run-time stack at various points during the execution of this code.

17. We ultimately want to map this process into LC-3 assembly code, so we’ll need some easy way to access the data in each function’s stack frame and also to manage the pushing and popping of stack frames. For this, we will use R5 and R6. Notice that R5 points to some internal location within the stack frame at the top of the stack—it points to the base of the local variables for the currently executing function. We call it the frame pointer. Also notice how R6 always points to the very top of the stack. We call it the stack pointer. Both of these registers have a key role to play in the implementation of the run-time stack and of functions in C in general.

18. It is clear that there is a lot of work going on at the machine level when a function is called. Arguments must be passed, stack frames pushed and popped, control moved from one function to another. As involved as it may seem, the implementation of this is rather straightforward, the next section will go through the details of the C run-time stack protocol on the LC-3.

19. We’ll partition this protocol into four steps. Step 1: The caller function copies arguments for the callee onto the run-time stack and passes control to the callee. Step 2: The callee function pushes space for local variables and other information onto the run-time stack, essentially creating its stack frame on top of the stack. Step 3: The callee executes. Step 4: Once it is ready to return, the callee removes, or pops, its stack frame oﬀ the run-time stack and returns the return value and control to the caller.

20. We’ll examine the LC-3 implementation of each of these steps in detail by looking at the code generated to accomplish the following line of code:

w = Volt(w, 10);

which is line 16 from the code in Figure 14.4.

21. The Call: In the statement w = Volt(w, 10);, the function Volt is called with two arguments. The value returned by Volt is then assigned to the local integer variable w. In translating this function call, the compiler generates LC-3 code that does the following:

a. Transmits the value of the two arguments to the function Volt by pushing them directly onto the top of the run-time stack. Recall that R6 points to the top of the run-time stack. It is the stack pointer. That is, it contains the address of the memory location that is actively holding the topmost data item on the stack. To push an item onto the stack, we ﬁrst decrement R6 and then store the data value using R6 as a base address. In our stack protocol, the arguments of a C function call are pushed onto the stack from right to left in the order in which they appear in the function call. In the case of Watt, we will ﬁrst push the value 10 (rightmost argument) and then the value of w.

b. Transfers control to Volt via the JSR instruction.

The following LC-3 code performs the call to Volt from Watt. Instructions 1 through 4 perform the push of the argument 10, and instructions 6 through 8 push the argument w. Notice that w itself is a local variable in Watt and must be loaded from Watt’s stack frame. More on this soon.

1  AND R0, R0, #0 ;R0<-0
2  ADD R0, R0, #10 ;R0<-10
3  ADD R6, R6, #-1 ;
4  STR R0, R6, #0 ; Push 10 onto stack
5
6  LDR R0, R5, #0 ; Load w
7  ADD R6, R6, #-1 ;
8  STR R0, R6, #0 ; Push w
9  JSR Volt

22. Figure 14.6 illustrates the modiﬁcations made to the run-time stack by these instructions. Notice that the argument values are pushed immediately on top of the stack frame of the caller (Watt). The stack frame for the callee (Volt) will be constructed on the stack directly on top of the stack frame of the caller.

23. Starting the Callee Function: The instruction executed immediately after the JSR in the function Watt is the ﬁrst instruction in the callee function Volt. Before we begin to execute the actual work in Volt described by the C code, we need to set the stage for Volt to execute. We need to properly allocate the stack frame for Volt and properly set the stack pointer R6 and the frame pointer R5 so that the code of Volt can execute correctly. At this point, the stack contains the two arguments for Volt at the top. 

24. The purpose of the preamble code of Volt is to prepare the stack such that it also contains a spot for the return value of Volt, the return address of Watt, Watt’s frame pointer, and all of the local variables of Volt. This will be accomplished in four steps, which we describe next, each as a single action:

a. Save space on the stack for callee’s return value. The return value is located immediately on top of the parameters for the callee. Later, when the callee is ready to pass control back to the caller, the return value is written into this location.

b. Push a copy of the return address in R7 onto the stack. Recall that R7 will hold the return address whenever a JSR is used to initiate a subroutine call. This will ensure that we can return to the caller even if the callee calls another function.

c. Push a copy of the caller’s frame pointer in R5 onto the stack. By saving a copy of R5, we will be able to restore the stack frame of the caller in such a way that the caller can easily resume execution after the function call
is complete. If either the caller’s return address or the frame pointer is destroyed, then we will have trouble restarting the caller correctly when the callee ﬁnishes. Therefore, it is important that we make copies of both in memory.

d. Allocate space on the stack for the callee’s local variables, and adjust R5 to point to the base of the local variables and R6 to point to the top of the stack.

25. The preamble code to accomplish this for Volt is provided below. This code appears ﬁrst before any of the code for statements in Volt.

1 Volt: ADD R6, R6, #-1   ; Allocate spot for the return value
2  
3       ADD R6, R6, #-1   ;
4       STR R7, R6, #0    ; Push R7 (Return address)
5
6       ADD R6, R6, #-1   ;
7       STR R5, R6, #0    ; Push R5 (Caller's frame pointer)
8
9       ADD R5, R6, #-1   ; Set frame pointer for Volt
10      ADD R6, R6, #-2   ; Allocate memory for Volt's local variables

26. Figure 14.7 summarizes the changes to memory accomplished by the function call code we have encountered so far. The layout in memory of these stack frames—one for Watt and one for Volt—is apparent. Notice that some entries of the stack frame of Volt are written by Watt. In particular, the parameter ﬁelds of Volt’s stack frame are initialized using the argument values from Watt. Watt writes the value of its local variable w as the ﬁrst argument and the value 10 for the second argument. Keep in mind that these values are pushed from right to left according to their position in the function call. Therefore, the value of w appears on top of the value 10. Once invoked, Volt will refer to these values as the parameters q and r. Question: What are the initial values of Volt’s local variable? Recall from Chapter 11 that local variables such as these are uninitialized.

27. Notice that each stack frame on the stack has the same structure. Each con- tains locations for the function’s local variables, for the bookkeeping information (consisting of the caller’s return address and caller’s frame pointer), the return value, and the function’s parameters.

28. Ending the Callee Function: Once the callee function has completed its work, we prepare to return to the caller. This essentially involves tearing down the stack frame and restoring the run-time stack to the state it was in when the caller initiated its function call. To accomplish this, we use the following four actions:

a. If there is a return value, it is written into the return value entry of the active stack frame.

b. The local variables for the callee are popped oﬀ the stack. This can be accomplished by individually popping them, or simply by setting the stack pointer R6 to the location immediately after the frame pointer R5.

c. The caller frame pointer and return address are restored.

d. Control to the caller function via the RET instruction.

29. The LC-3 instructions corresponding to this for Volt are as follows. Keep in mind that even though the stack frame for Volt is popped oﬀ the stack, its values remain in memory until they are explicitly overwritten.

1    LDR  R0,R5,#0 ; Load local variable k
2    STR  R0,R5,#3 ; Write it in return value slot, which will always be at location R5 + 3
3
4
5    ADD  R6,R5,#1 ; Pop local variables
6
7    LDR  R5,R6,#0 ; Pop the frame pointer
8    ADD  R6,R6,#1 ;
9
10   LDR R7, R6, #0   ; Pop the return address
11   ADD R6, R6, #1   ;
12   RET

30. Returning to the Caller Function: After the callee function executes the RET instruction, control is passed back to the caller function. In some cases, there is no return value (if the callee is declared of type void) and, in some cases, the caller function ignores the return value. Again, from our previous example, the return value is assigned to the variable w in Watt. In particular, there are two actions to be performed:

a. The return value (if there is one) is popped oﬀ the stack.
b. The arguments are popped oﬀ the stack.

The code after the JSR looks like the following. Once this code starts executing, R6 points to the top of the stack, which is the return value, and R5 is again the frame pointer of Watt.

1  JSR   Volt
2  LDR   R0,R6,#0 ; Load the return value
3  STR   R0,R5,#0 ; w = Volt(w, 10);
4  ADD   R6,R6,#1 ; Pop return value
5
6  ADD   R6,R6,#2 ; Pop arguments

31. Once this code is done, the call is now complete, and the caller function can resume its normal operation. Notice that prior to the return, the callee restores the environment of the caller. From the caller’s perspective, it appears as if nothing has changed except that a new value (the return value) has been pushed onto the stack.

32. Caller Save/Callee Save: During the execution of a function, R0 through R3 can contain temporary values that are part of an ongoing computation. Registers R4 through R7 are reserved for other purposes: R4 is the pointer to the global data section, R5 is the frame pointer, R6 is the stack pointer, and R7 is used to hold return addresses. If we make a function call, based on the calling convention we’ve described, R4 through R7 do not change, or they change in a predetermined fashion. But what happens to registers R0, R1, R2, and R3?

33. To address this, digital systems typically adopt one of two strategies: (1) The caller will save these registers by pushing them onto its stack frame. This is the caller-save convention. When control is returned to the caller, the caller will restore these registers by popping them oﬀ the stack. 

34. (2) Alternatively, the callee can save these registers by adding four ﬁelds in the bookkeeping area of its record. This is called the callee-save convention. When the callee is initiated, it will save R0 through R3 and R5 and R7 into the bookkeeping region and restore these registers before returning to the caller.

35. Tying It All Together: The code for the function call in Watt and the beginning and end of Volt is listed in Figure 14.8. The LC-3 code segments presented in the previous sections are all combined, showing the overall structure of the code. This code is more optimized than the previous individual code segments. We’ve combined the manipulation of the stack pointer R6 associated with pushing and popping the return value into single instructions.

36. Let’s summarize our LC-3 C function call protocol. The caller function pushes the value of each argument onto the stack and performs a Jump To Subroutine (JSR) to the callee. The callee allocates a space for the return value, saves the caller’s frame pointer and return address, and then allocates space on the stack for its local variables. The callee then proceeds to carry out its task. When the task is complete, the callee writes the return value into the space reserved for it, pops and restores frame pointer and return value for the caller, and returns to the caller. The caller then pops the return value and arguments from the stack and resumes its execution.

37. Is it really necessary to go through all these steps just to make a function call? One of the characteristics of real calling conventions is that in the general case, any function should be able to call any other function. To enable this, the calling convention should be organized so that a caller does not need to know anything about a callee except its interface (i.e., the type of value the callee returns and the types of values it expects as arguments). Likewise, a callee is written to be independent of the functions that call it. Because of this generality, the functional calling protocol needs these steps. It is all part of the overhead required to make functions an essential building block for large-scale software.

chapter 15

1. Programs are not correct by construction, particularly code written in C or C++. We must actively test and debug software as an integral part of the development process.

2. Anecdotally, experienced coders spend more than half of their time debugging code as opposed to writing code. The best programmers are those who have mastered debugging. 

3. Testing is the process of exposing bugs, and debugging is the process of ﬁxing them. Testing a piece of code involves subjecting it to as many input conditions as possible, in order to stress the software into revealing its bugs. 

4. To better understand how to ﬁnd and ﬁx errors in our code, or to avoid errors in the ﬁrst place, it’s helpful to build a taxonomy of types of errors. There are four broad categories of errors that programmers introduce into code.

5. Syntactic errors are the easiest to deal with because they are caught by the compiler. The compiler notiﬁes us of such errors when it tries to translate the source code into machine code, often pointing out exactly in which line the error occurred. Semantic errors, on the other hand, are problems that can often be very diﬃcult to repair. They occur when the
program is syntactically correct but does not behave exactly as we intended.

6. Both syntactic and semantic errors are generally typographic in nature— they occur when we write something we did not mean to write.

7. Algorithmic errors,onthe other hand, are less casual mistakes. They are errors in which our approach to solving a problem is wrong. They are costly to the overall software development process because they are hard to detect and often hard to ﬁx.

8. Speciﬁcation errors are due to poorly deﬁned program requirements, or misinterpretations of those requirements by the person or team implementing them.

9. As far as overall digital systems go, bugs can be anywhere, and they aren’t limited to the software side of the house. The hardware can have bugs, sensors can be ﬂaky, and physical systems can fail, which can manifest in the device not working properly. And any of these systems can fail transiently due to an adverse operating situation—the device can fail for just a brief moment and then resume correct operation. 

10. In C and C++ and all programming languages, syntactic errors (or syntax errors or parse errors) are always caught by the compiler or other translator. These types of errors occur when we ask the compiler to translate code that does not conform to the C/C++ speciﬁcation. 

11. Speciﬁcation Errors: Perhaps the most infamous software bug of all was the Year 2000 computer bug, or Y2K bug. Many early computer systems had small memories, and this required programmers to economize on the size of data items they stored in memory. When storing dates, many early software systems only stored enough bits to represent the last two digits of the year; for example, in storing the year 1975, only 75 was stored, with the century being implicitly the 1900s. 

12. With this shortcut, the year 2000 became indistinguishable from the year 1900 (or 1800 or 2100, for that matter). This presented a worldwide challenge as we anticipated the current year transitioning into the 2000s after December 31, 1999. Plenty of software written originally on memory-constrained systems was still functional, and this software needed ﬁxing in order to properly roll over with the century changeover. As a consequence, a lot of money and eﬀort were invested in tracking down Y2K- related bugs before January 1, 2000, rolled around.

13. We call this type of bug a speciﬁcation bug. The software worked as speciﬁed, but the speciﬁcation itself was ﬂawed. The software architects of the day decided that it was OK to encode only the last two digits of a year because they didn’t expect the software would still be operational at the end of 1999. Speciﬁcation errors can arise from poor speciﬁcations that don’t properly anticipate the operating requirements for the software, and the Y2K bug is an example of this. 

14. In an ideal world, we could test a program by examining its operation under every possible input condition. For most programs, testing for every input combination is impossible.

15. The modern software development process views testing more systematically. In particular, black-box testing is used to check if the code meets its speciﬁcations, and white-box testing targets various facets of the program’s implementation in order to provide some assurance that many lines (if not every line) of code are tested.

16. Black-Box Testing: With black-box testing, we examine if the program meets its input and output speciﬁcations, disregarding the internals of the program. We treat the software being tested as a black box where the internals are not visible to us.

17. White-Box Testing: With black-box testing, it is not possible to know which lines of code have been tested and which have not, and therefore, according to the adage, all are presumed to be buggy. White-box tests isolate various internal components of the software and test whether the components conform to their intended design.

18. Source-level debuggers are software development tools that enable us to examine variables, memory objects, registers, and memory at any point during the execution of our code. A source-level debugger can allow us to execute our code one C statement at a time and examine the values of any program state (variables, registers, memory, run-time stack, etc.) along the way. 

19. For a source-level debugger to be used on a program, the program must be compiled such that the compiler augments the executable image with enough additional information for the debugger to do its job. Among other things, the debugger will need information from the compilation process in order to map every machine language instruction to its corresponding statement in the high-level source code. 

20. The debugger also needs information about variable names and their locations in memory (i.e., the symbol table). This is required so that a programmer can examine the value of any variable within the program using its name in the source code.

21. Most programmers today use an integrated development environment (IDE) for developing their code. These environments integrate the common tools needed to develop code, such as code repository, editor, and compilation system, into a single user interface. 

chapter 16

1. A pointer is simply the address of a memory object, such as a variable. With pointers, we can indirectly access these objects, which provides for some very useful capabilities. With pointers, we can create sophisticated data organizations that grow and shrink (like the run-time stack) during a program’s execution.

2. An array is a list of data objects of the same type arranged sequentially in memory. To access a particular item in an array, we specify which element we want to access by providing its index. So, an expression like a[4] will access the ﬁfth element in the array named a—it is the ﬁfth element because we start numbering the array at element 0. Arrays are useful because they allow us to conveniently process groups of data such as vectors, matrices, lists, and character strings, which are naturally representative of certain objects in the real world.

3. Pointers: In the C program in Figure 16.1, the function Swap is designed to switch the value of its two arguments. The function Swap is called from main with the arguments valueA, which in this case equals 3, and valueB, which equals 4. Once
Swap returns control to main, we expect valueA and valueB to have their values swapped. However, compile and execute the code and you will notice that those variables in Swap remain unchanged. 

4. To analyze why, let’s examine the run-time stack during the execution of Swap. Figure 16.2 shows the state of the run-time stack just prior to the completion of the function, just after the statement on line 25 has executed but before control returns to function main. 

5. Notice that the function Swap has modiﬁed the values of its parameters ﬁrstVal and secondVal within its own stack frame. When Swap ﬁnishes and control returns to main, these modiﬁed values are lost when the stack frame for Swap is popped oﬀ the stack. The values from main’s perspective have not been swapped. And we are left with a buggy program.

6. In C, arguments are always passed from the caller function to the callee by value. C evaluates each argument that appears in a function call as an expression and pushes the value of the expression onto the run-time stack in order to pass them to the function being called. In the callee, the argument values then become values for the function’s parameter variables. In the callee, the argument values then become values for the function’s parameter variables. 

7. For Swap to modify the arguments that the caller passes to it, it must have access to the caller function’s stack frame—it must access the locations at which the arguments are stored in order to modify their values. The function Swap needs the addresses of valueA and valueB in main in order to change their values.

8. Just as an integer variable contains a bit pattern that is treated and interpreted as an integer value, a pointer variable contains a bit pattern that is treated as an address of a memory object, such as a variable. A pointer is said to point to the variable whose address it contains. Associated with a pointer variable is the type of object to which it points. So, for instance, an integer pointer points to an integer variable. 

9. If a pointer variable is declared as a local variable, it will not be initialized automatically. C has two operators for pointer-related manipulations, the address operator & and the indirection operator *.

10. The address operator, whose symbol is an ampersand, &, generates the memory address of its operand, which must be a memory object such as a variable. In the following code sequence, the pointer variable ptr will point to the integer variable object. The expression on the right-hand side of the second assignment statement generates the memory address of object.

int object;
int *ptr;
object = 4;
ptr = &object;

11. Let’s examine the LC-3 code for this sequence. Both declared variables are local variables allocated on the run-time stack. Recall that R5, the base pointer, points to the ﬁrst declared local variable, or object in this case.

AND R0, R0, #0 ; Clear R0
ADD R0, R0, #4 ;R0=4
STR R0, R5, #0 ; object = 4;
ADD R0, R5, #0 ; Generate memory address of object
STR R0, R5, #-1 ; Ptr = &object;

12. Figure 16.3 shows the stack frame of the function containing this code immediately after the statement ptr = &object; has executed. In order to make things more concrete, each memory location is labeled with an address, which we’ve arbitrarily selected to be in the xEFF0 range. The base pointer R5 currently points to xEFF2. Notice that object contains the integer value 4 and ptr contains the memory address of object.

13. The Indirection Operator *: The second pointer operator is called the indirection,ordereference, operator, and its symbol is the asterisk, *. This operator allows us to indirectly manipulate the value of a memory object. Adding to the previous C code example,

int object;
int *ptr;
object = 4;
ptr = &object;
*ptr = *ptr + 1;

14. The statement *ptr = *ptr + 1; accomplishes the same thing as object = object + 1;. The expression *ptr means diﬀerent things depending on which side of the assignment operator it appears on. On the right-hand side of the assign- ment operator, it refers to the value that appears at that location (in this case the value 4). On the left-hand side, it speciﬁes the location that gets modiﬁed (in this case, the address of object).Let’s examine the LC-3 code for the last statement in the preceding code.

LDR R0, R5, #-1 ; R0 contains the value of ptr
LDR R1, R0, #0 ; R1 <- *ptr
ADD R1, R1, #1 ;*ptr+1
STR R1, R0, #0 ; *ptr = *ptr + 1;

15. Notice that this code is diﬀerent from what would be generated if the ﬁnal C statement had been object = object + 1;. With the pointer dereference, the compiler generates two LDR instructions for the indirection operator on the right-hand side, one to load the value of ptr, which is a memory address, and another to get the value stored at that address. With the dereference on the left-hand side, the compiler generates a STR R1, R0, #0. Had the statement been object = *ptr + 1;, the compiler would have generated STR R1, R5, #0.

16. Passing a Reference Using Pointers: Using the address and indirection operator, we can repair the Swap function from Figure 16.1, which did not quite accomplish the swap of its two input arguments. Figure 16.4 lists the same program with a revised version of Swap called NewSwap.

17. The ﬁrst modiﬁcation we’ve made is that the parameters of NewSwap are no longer integers but are now pointers to integers (int *). These two parameters are the memory addresses of the two variables that are to be swapped. Within the func- tion body of NewSwap, we use the indirection operator * to obtain the values that these pointers point to.

18. Now when we call NewSwap from main, we need to supply the addresses for the two variables we want swapped, rather than the values of the variables as we did in the previous version of the code. For this, the & operator does the trick.

19. Figure 16.5 shows the run-time stack when various statements of the function NewSwap are executed. The three subﬁgures (A–C) correspond to the run-time stack after lines 23, 24, and 25 execute.

20. By design, C passes information from the caller function to the callee by value; that is, each argument expression in the call statement is evaluated, and the resulting value is passed to the callee via the run-time stack. However, in NewSwap we created a call by reference for the two arguments by using the address operator &. When an argument is passed as a reference, its address is passed to the callee function—for this to be valid, the argument must be a variable or other memory object (i.e., it must have an address). The callee function then can use the indirection operator * to access (and modify) the original value of the object.

21. Null Pointers: Sometimes it is convenient for us to have a pointer point to nothing so that we can diﬀerentiate it from an actual pointer value. A pointer that points to nothing is a null pointer. In C, we make this designation with the following assignment:

int *ptr;
ptr = NULL;

22. Here, we are assigning the value of NULL to the pointer variable ptr.InC,NULL is a specially deﬁned preprocessor macro that contains a value 0. So by convention, we consider a pointer that points to memory address 0 to be a special case pointer that points to nothing. 

23. An Example Problem Involving Pointers: Say we want to develop a C program that calculates the quotient and remainder given an integer dividend and integer divisor. That is, our code will calculate dividend / divisor and dividend % divisor. The code in Figure 16.6 contains a function that does just that. The function IntDivide has four parameters, two of which are integers and two of which are pointers to integers. The function divides the ﬁrst parameter x by the second parameter y. 

24. The integer portion of the result is assigned to the memory location pointed to by quoPtr, and the integer remainder is assigned to the memory location pointed to by remPtr. Using call-by-reference with pointers, we can create a function that “returns” multiple output values back to its caller.

25. Notice that the function IntDivide also returns a value to indicate its status: It returns a −1 if the divisor is zero, indicating to the caller that an error has occurred. It returns a zero otherwise, indicating to the caller that the computation proceeded successfully. The function main, upon return, checks the return value to determine if the values in quotient and remainder are correct. Using the return value to signal error conditions during a function call is a common programming convention, particularly for complex functions.

26. An array is a collection of similar data items that are stored sequentially in memory and accessible through a single name or identiﬁer. Speciﬁcally, all the elements in the array are of the same type.

27. Declaring and Using Arrays: As with all other declarations, arrays must have a type associated with them. The type indicates the properties of the values stored in the array. The following declaration creates an array of ten integers:

int grid[10];

The keyword int indicates that we are declaring something of integer type named grid. The brackets indicate we are declaring an array, and the 10 indicates that the array is to contain ten integers, all of which will be consecutively located in memory. Figure 16.7 shows a pictorial representation of how grid is allocated. The ﬁrst element, grid[0], is allocated in the lowest memory address and the last element, grid[9], in the highest address. 

28. To access a particular element, we provide an index within brackets. For example, 

grid[6] = grid[3] + 1;

Let’s look at the LC-3 code for this example. Let’s say that grid is the only local variable allocated on the run-time stack. By our run-time stack convention, this means that the frame pointer R5 will point to grid[9],orthe
last element in the array.

ADD R0, R5, #-9     ; Put the base address of grid into R0
LDR R1, R0, #3      ; R1 <-- grid[3]
ADD R1, R1, #1      ; R1 <-- grid[3] + 1
STR R1, R0, #6      ; grid[6] = grid[3] + 1;

29. Notice that the ﬁrst instruction calculates the base address of the array, which is the address of grid[0], and puts it into R0. The base address of an array in general is the address of the ﬁrst element of the array. We can access any element in the array by adding the index of the desired element to the base address.

20. The power of arrays comes from being able to compute an array index using a C integral expression. The following example demonstrates this. Here we are accessing the array grid using another variable x. 

grid[x+1] = grid[x] + 2;

Let’s look at the LC-3 code for this statement. Assume x is allocated on the run-time stack directly on top of the array grid.

LDR R0, R5, #-10    ; Load the value of x
ADD R1, R5, #-9     ; Put the base address of grid into R1
ADD R1, R0, R1      ; Calculate address of grid[x]
LDR R2, R1, #0      ; R2 <-- grid[x]
ADD R2, R2, #2      ; R2 <-- grid[x] + 2
LDR R0, R5, #-10    ; Load the value of x
ADD R0, R0, #1      ; R0 <-- x + 1
ADD R1, R5, #-9     ; Put the base address of grid into R1
ADD R1, R0, R1      ; Calculate address of grid[x+1]
STR R2, R1, #0      ; grid[x+1] = grid[x] + 2;

21. Arrays as Parameters: Say we want to create a set of functions that calculates the mean and median on an array of integers. We would need either (1) to pass the entire array of values from one function to another or (2) to pass a reference to the array. If the array contains a large number of elements, copying each element from one stack frame onto another could be very costly in execution time. Fortunately, C naturally passes arrays by reference. Figure 16.10 is a C program that contains a function Average whose single parameter is an array of integers.

22. When calling the function Average from main, we use as the argument the name of the array numbers. Here, we are not using the standard notation involving brackets [ ] that we normally use for arrays. In C, an array’s name refers to the address of the base element of the array. The name numbers is equivalent to &numbers[0]. The type of numbers is similar to int *, because numbers is a pointer to something of integer type.

23. In using numbers as the argument to the function Average, we are causing the address of the array numbers to be pushed onto the stack and passed to the function Average. Within the function Average, the parameter inputValues is assigned the address of the array. Within Average we can access the elements of the original array using standard array notation. Figure 16.11 shows the run-time stack just prior to the execution of the return from Average (line 34 of the program).

24. Notice how the input parameter inputValues is speciﬁed in the declaration of the function Average. The brackets []indicate to the compiler that the corresponding parameter will be the base address to an array of the speciﬁed type, in this case an array of integers. Since arrays are passed by reference in C, any modiﬁcations to the array values made by the called function will be visible to the caller once control returns to it. 

25. How would we go about passing only a single element of an array by value? How about by reference?

26. Strings in C: Strings are sequences of characters that represent text. Strings in C are sim- ply arrays of character type, with each subsequent element containing the next character of the string. For example,

char word[10];

declares an array that can contain a string of up to ten characters. 

27. We adopt a special protocol for strings in C where the end of a string is denoted by the null character whose ASCII value is 0. This character serves as a sentinel that identiﬁes the end of the string. Such strings are also called null-terminated strings.’\0’ is the special character sequence that we can use in our C code to designate the null character.

28. Continuing with our previous declaration,

char word[10];
word[0] = 'g';
word[1] = 'i';
word[2] = 'r';
word[3] = 'a';
word[4] = 'f';
word[5] = 'f';
word[6] = 'e';
word[7] = '\0';
printf("%s", word);

29. Here, we are assigning each element of the array individually such that the string will contain “giraﬀe”. Notice that the end-of-string character itself is a character that occupies an element of the array. Even though the array is declared for ten elements, we must reserve one element for the null character, and therefore strings that are longer than nine characters cannot be stored in this array. 

30. We also used a new printf format speciﬁcation %s in this example. This speciﬁcation prints out a string of characters, starting with the character pointed to by the corresponding parameter and ending at the end-of-string character ‘\0’.

31. C also allows strings to be initialized within their declarations. For instance, the preceding example can be rewritten to the following:

char word[10] = "Hello";
printf("%s", word);

32. Make note of two things here: First, character strings are distinguished from single characters with double quotes,“ ”. Single quotes are used for single characters, such as ‘A’. Second, the null character is automatically added to the end of the string.

33. Examples of Strings: Figure 16.12 contains C code that performs a common, useful primitive operation on strings: It calculates the length of a string. Notice that we are using the format speciﬁcation %s in the scanf statement. This speciﬁcation causes scanf to read in a string of characters from the keyboard until the ﬁrst white space character. In C, any space, tab, new line, carriage return, vertical tab, or form-feed character is considered white space. Notice that the white space is automatically discarded by this %s speciﬁcation. 

33. What happens if the ﬁrst word is longer? The scanf function has no information on the size of the array input and will keep storing characters to the array address it was provided until white space is encountered. So what then happens if the ﬁrst word is longer than 20 characters? Any local variables that are allocated after the array input in the function main will be overwritten. Draw out the stack frame before and after the call to scanf to see why. 

34. Let’s examine a slightly more complex example that uses functions we developed in previous code examples in this chapter. In the code example in Figure 16.13, we read an input string from the keyboard using scanf, then call a function to reverse the string. The reversed string is then printed out. The function Reverse ﬁrst determines the length of the string using the StringLength function from the previous example. Then it performs the reversal by swapping the ﬁrst character with the last, the second character with the second to last, the third character with the third to last, and so on. 

35. The Relationship Between Arrays and Pointers in C: You might have noticed that there is a similarity between an array’s name and a pointer variable to an element of the same type as the array. For instance,

char word[10]; 
char *cptr; 
cptr = word;

is a legal, and sometimes useful, sequence of code. Here we have assigned the pointer variable cptr to point to the base address of the array word. Because they are both pointers to characters, cptr and word can be used interchangeably.

36. For example, we can access the fourth character within the string by using either word[3] or *(cptr + 3). One diﬀerence between the two, though, is that cptr is a variable and can be reassigned (i.e., it can appear on the left-hand side of an assignment operator). The array identiﬁer word, on the other hand, cannot be reassigned. For example, the following statement is illegal: word = newArray. It generates a compiler error. The identiﬁer always points to a ﬁxed spot in memory where the compiler has placed the array. Once it has been allocated, it cannot be moved.

37. Table 16.1 shows the equivalence of several expressions involving pointer and array notation. Rows in the table are expressions with similar meanings.

38. Problem Solving: Insertion Sort; We will write C code to sort an array of integers into ascending order. That is, the code should arrange the data in array a[] such that a[0] ≤ a[1] ≤ a[2] .... There are many algorithms for sorting, and you will encounter various techniques in later computing courses. We use insertion sort here because it parallels how we might sort items in the physical world, with real objects. 

39. Unlike some other modern programming languages, C does not provide protec- tion against exceeding the size (or bounds) of an array. Recall that C originated during an era when memory and computer processing power were precious resources, and programmers had to be very economical in the operations their code performed. In the spirit of minimizing overhead, C performs no size enforcement on arrays. This enables programs written in C to be fast and eﬃcient, but at the cost of potential bugs. Programmer beware!

40. In all of our discussion of arrays up until this point, we’ve worked under the assumption that an array in C is of ﬁxed size. That is, the size of the array is ﬁxed and is known when the code is compiled. In order to allocate an array on the run-time stack, the compiler needs to know the exact size. If the exact size is not known, then the oﬀsets from the frame pointer (R5) for the array and other variables in the stack frame cannot be properly determined, and everything falls apart.

41. But this particular restriction proves to be quite limiting. Often we want to size our arrays based on the particular situation we’ve encountered during execution. Starting in 1999, the ANSI C standard adopted support for variable-length arrays. Variable-length arrays are arrays whose sizes are variable integer expres- sions, rather than constants. The following code fragment

int Calculate(int len)
{
int data[len];

illustrates the declaration of a variable-length array. The size of the array data can only be determined during execution of the code, and it is not known at compile time. The array data is still allocated on the run-time stack in this case but using a diﬀerent type of allocation scheme than with standard, statically sized arrays. This protocol requires additional instructions during allocation and access, which adds performance overheard. Variable-length arrays are a nice programming convenience at the expense of additional performance.

42. Multidimensional Arrays in C: Nearly everyone alive today has taken or will take a picture with a smartphone. It’s an activity that’s simple enough for a person to accomplish, but it triggers an incredible amount of activity within a smartphone. Some of this activity involves physics and optics, as light from the scene being captured enters the lens of the phone to form an image on a device called a CMOS image sensor (think of it as the digital retina of the phone’s camera). Much of this activity is digital; the image sensor and a slew of associated software on the phone convert the signals cap- tured by the sensor into a high-quality picture. What exactly is this picture? Each element of the picture, or image, is called a pixel, and it represents the intensity of green, blue, and red at a particular point in the image. The image itself is a collection of these pixels (short for picture elements), arranged in a two-dimensional grid, with each pixel belonging to a particular row and column within the image. For example, an image might have 1080 rows and 1920 columns of pixels and would contain about two million pixels altogether.

43. We can easily extend our idea of arrays to incorporate multidimensional concepts like images. In C, the syntax for doing so is simple:

int image[1080][1920];

This declaration creates an array called image that is organized as a two-dimensional array. The ﬁrst dimension is of size 1080, or the number of rows of pixels, and the second dimension is of size 1920, and it represents the number of columns of pixels. Instead of providing a single index value to access elements of a single dimensional array, we now need to provide two, one for the row and one for the column. 

44. This 2D array will need to be mapped into memory somehow, just as we did with a simple 1D array. In the 1D case, the mapping is easy because the arrangement in memory corresponds to increasing indices of the array. In the 2D case, we have two options. Either we can map consecutive elements of each column into consecutive memory locations, or we can map consecutive elements of each row into consecutive memory locations. With C and C++, consecutive elements of each column are in adjacent memory locations, which is an ordering often called row-major order. Figure 16.16 provides a diagram of how this ordering applies to the array image. The image is so large that it won’t ﬁt into the LC- 3’s 16-bit address space. The LC-3 only has 216  or 65,536 locations, and this image requires 2,073,600. We need a larger address space! So for this ﬁgure, we extended the address space to be 32 bits to make the example work.

45. Let’s take a look at a simple image processing function that operates on images represented as 2D arrays. Using our example of an image, let’s say that each element of the image array is an integer, and this integer represents the inten- sity of light at that position in the image. The higher the value, the brighter that particular pixel. As such, the value represents the “white value” of the pixel. More generally, we’d incorporate color into the representation, but for now we’ll keep it simple.

46. The function Adjust in Figure 16.17 divides each pixel value by 2. When viewed visually, what would you expect in the resulting image? to be darker 

47. The idea of multidimensional arrays in C extends beyond 2D arrays, too. We can declare a 3D array by attaching another set of brackets to the declaration, thus adding a dimension.

int dataVolume[40][50][60]; // This declares 120,000 elements

48. The layout in memory of a 3D array in C follows the same pattern as a 2D array: Consecutive elements of the rightmost index are allocated sequentially in memory. And we move through the indices right to left. So immediately in memory after dataVolume[0][0][59] will be dataVolume[0][1][0].

chapter 17

1. Suppose we want to ﬁnd a particular student’s exam in a stack of exams that are already sorted into alphabetical order. Our procedure for doing so could be as follows: Pick a random point in the stack, and check for a match. If we ﬁnd a match, great! We are done. If we don’t ﬁnd the exam (which is the more likely case, initially), we now know the exam we’re looking for is either in the upper stack or in the lower stack based on whether the name occurs alphabetically before or after the name at the random point. Here’s the key: We can now repeat the same procedure on a stack of exams (lower or upper) that is necessarily smaller than our original stack. For example, say we are looking for Mira’s exam. We ﬁnd at our selected random point Salina’s exam. We clearly didn’t ﬁnd Mira’s exam, but we know that it must in the portion of the stack that precedes Salina’s exam. We repeat our search on that smaller substack. Fairly quickly, we will locate Mira’s exam, if it exists in the set.

2. The technique we’ve described is recursive. We are solving the problem (ﬁnding an exam in a stack of exams) by stating that we’ll solve it on successively smaller versions of the problem (ﬁnd the exam on this smaller stack).

3. Recursion is similar to iteration in that both describe a repeating ﬂow of computation. The power of recursion lies in its ability to elegantly express the computation ﬂow for certain programming tasks. There are some programming problems for which the recursive solution is far simpler than the corresponding iterative solution.

4.  Nearly always, recursion comes at the cost of additional execution overhead compared to iteration. So recursion must be applied carefully with a thorough understanding of the underlying costs. 

5. What Is Recursion? A function that calls itself is a recursive function. The function RunningSum in Figure 17.1 is an example. This function calculates the sum of all the integers between the input parameter n and 1, inclusive. For example, RunningSum(4) calculates 4+3+2+1. This recursive deﬁnition is the basis for a recursive algorithm. In other words,

RunningSum(n) = n + RunningSum(n − 1)

6. In order to complete the evaluation of this equation, we must also supply an initial case. So in addition to the preceding formula, we need to state

RunningSum(1) = 1

before we can completely evaluate the recurrence. Now we can fully evaluate RunningSum(4):

RunningSum(4) = 4 + RunningSum(3)
              = 4 + 3 + RunningSum(2)
              = 4 + 3 + 2 + RunningSum(1)
              = 4 + 3 + 2 + 1

7. During execution of the function call RunningSum(4), RunningSum makes a function call to itself, with an argument of 3 (i.e., RunningSum(3)). However, before RunningSum(3) ends, it makes a call to RunningSum(2). And before RunningSum(2) ends, it makes a call to RunningSum(1). RunningSum(1), however, makes no additional recursive calls and returns the value 1 to RunningSum(2), which enables RunningSum(2) to end and return the value 2+1backtoRunningSum(3). This enables RunningSum(3) to end and pass a value of 3 + 2 + 1 to RunningSum(4). Figure 17.2 pictorially shows how the execution of RunningSum(4) proceeds.

8. Recursion vs. Iteration: There is a parallel between using recursion and using conventional iteration (such as for and while loops) in programming. All recursive functions can be written using iteration. For certain programming problems, however, the recur- sive version is simpler and more elegant than the iterative version. Solutions to certain problems are naturally expressed in a recursive manner, such as problems that are expressed with recurrence equations. It is because of such problems that recursion is an indispensable programming technique.

9. Knowing which problems require recursion and which are better solved with iteration is part of the art of computer programming, and it is a skill one develops through coding experience.

10. Recursion, as useful as it is, comes at a cost. As an experiment, write an iterative version of RunningSum and compare the running time for large n with the recursive version. To do this you can use library functions to get the time of day (e.g., gettimeofday) before the function starts and when it ends. Plot the running time for a variety of values of n and you will notice that the recursive version is relatively slower (provided the compiler did not optimize away the recursion, which it can do through a simple transformation that converts certain types of recursive code to iterative code when the recursion is the last operation in the function, i.e., it occurs at the tail of the function). Recursive functions incur function call overhead that iterative solutions do not. Understanding the under- lying overheads of recursion is something we cleanly explore with our bottom-up approach, and it will assist you in knowing when, and when not, to apply recursion for a particular programming task.

11. Towers of Hanoi: The puzzle involves a platform with three posts. On one of the posts sit a number of wooden disks, each smaller than the one below it. The objective is to move all the disks from their current post to one of the other posts. However, there are two rules for moving disks: Only one disk can be moved at a time, and a larger disk can never be placed on top of a smaller disk. For example, Figure 17.3 shows a puzzle where ﬁve disks are on post 1. To solve this puzzle, these ﬁve disks must be moved to one of the other posts obeying the two rules. 

12. Now how would we go about writing C code to solve this puzzle? If we view the problem from the end ﬁrst, we can make the following observation: The ﬁnal sequence of moves must involve moving the largest disk from post 1 to the target post, say post 3, and then moving all of the other disks back on top of it. Conceptually, we need to move all n − 1 disks oﬀ the largest disk and onto the intermediate post, then move the largest disk onto the target post. Finally, we move all n − 1 disks from the intermediate post onto the target post.

13. Moving n − 1 disks in one move is not a singular, legal move. However, we have stated the problem in such a manner that we can solve by solving two smaller subproblems.

14. We now have a recursive deﬁnition of the problem: In order to move n disks to the target post, which we symbolically represent as Move(n, target), we ﬁrst move n − 1 disks to the intermediate post, Move(n-1, intermediate), then move the nth disk to the target, which is a singular move, and ﬁnally move n − 1 disks from the intermediate to the target, Move(n-1, target). So in order to Move(n, target), two recursive calls are made to solve two smaller subproblems involving n − 1 disks.

15. In the way we have formulated the problem, the base case involves moving the smallest disk (disk 1). Moving disk 1 requires no other disks to be moved since it is always on top and can be moved directly from one post to any another without moving any other disks. Without a base case, a recursive function would never end, similar to an inﬁnite loop in conventional iteration. Figure 17.4 is a recursive C function of this algorithm.

16. Let’s see what happens when we solve the puzzle with three disks. Following is the initial function call to MoveDisk. We start oﬀ by saying that we want to move disk 3 (the largest disk) from post 1 to post 3, using post 2 as the intermediate storage post. That is, we want to solve a three-disk Towers of Hanoi puzzle. See Figure 17.5.

// diskNumber 3; startPost 1; endPost 3; midPost 2
MoveDisk(3, 1, 3, 2)

17. This call invokes another call to MoveDisk to move disks 1 and 2 oﬀ disk 3 and onto post 2 using post 3 as intermediate storage. The call is performed at line 10 in the source code.

// diskNumber 2; startPost 1; endPost 2; midPost 3
MoveDisk(2, 1, 2, 3)

18. To move disk 2 from post 1 to post 2, we ﬁrst move disk 1 oﬀ disk 2 and onto post 3 (the intermediate post). This triggers another call to MoveDisk again from the call on line 10.

// diskNumber 1; startPost 1; endPost 3; midPost 2
MoveDisk(1, 1, 3, 2)

19. For this call, the condition of the if statement on line 7 will not be true, and disk 1 can be moved directly to the target post. The printf statement on lines 19–20 is executed. See Figure 17.6.

Move disk 1 from post 1 to post 3.

20. This  invocation  of  MoveDisk returns  to  its  caller,  which  was  the  call MoveDisk(2, 1, 2, 3). Recall that we were waiting for all disks on top of disk 2 to be moved to post 3. Since that is now complete, we can move disk 2 from post 1 to post 2. The printf on lines 19–20 is the next statement to execute, signaling another disk to be moved. See Figure 17.7.

Move disk 2 from post 1 to post 2.

21. Next, a call is made to move all disks that were on disk 2 back onto disk 2. This happens at the call on line 16 of the source code for MoveDisk.

// diskNumber 1; startPost 2; endPost 3; midPost 1
MoveDisk(1, 2, 3, 1)

22. Again, since disk 1 has no disks on top of it, we see the move printed. See Figure 17.8.

Move disk number 1 from post 3 to post 2.

23. Control passes back to the call MoveDisk(2, 1, 2, 3) which, having com- pleted its task of moving disk 2 (and all disks on top of it) from post 1 to post 2, returns to its caller. Its caller is MoveDisk(3, 1, 3, 2). All disks have been moved oﬀ disk 3 and onto post 2. Disk 3 can be moved from post 1 onto post 3. The printf is the next statement executed. See Figure 17.9.

Move disk 3 from post 1 to post 3.

24. The next subtask remaining is to move disk 2 (and all disks on top of it) from post 2 onto post 3. We can use post 1 for intermediate storage. The following call occurs on line 16 of the source code.

// diskNumber 2; startPost 2; endPost 3; midPost 1
MoveDisk(2, 2, 3, 1)

25. In order to do so, we must ﬁrst move disk 1 from post 2 onto post 1, via the call on line 16.

// diskNumber 1; startPost 2; endPost 1; midPost 3
MoveDisk(1, 2, 1, 3)

26. The move requires no submoves. See Figure 17.10.

Move disk 1 from post 2 to post 1.

Return passes back to the caller MoveDisk(2, 2, 3, 1), and disk 2 is moved onto post 3. See Figure 17.11.

Move disk 2 from post 2 to post 3.

27. The only thing remaining is to move all disks that were on disk 2 back on top.

// diskNumber 1; startPost 1; endPost 3; midPost 2
MoveDisk(1, 1, 3, 2)

28. The move is done immediately. See Figure 17.12.

Move disk 1 from post 1 to post 3.

and the puzzle is completed!

Let’s summarize the action of the recursion by examining the sequence of function calls that were made in solving the three-disk puzzle:

MoveDisk(3, 1, 3, 2)  // Initial Call
MoveDisk(2, 1, 2, 3)
MoveDisk(1, 1, 3, 2)
MoveDisk(1, 2, 3, 1)
MoveDisk(2, 2, 3, 1)
MoveDisk(1, 2, 1, 3)
MoveDisk(1, 1, 3, 2)

29. Consider how you would write an iterative version of a solver for this puz- zle. You’ll no doubt quickly appreciate the simplicity of the recursive version. Returning to the legend of the Towers of Hanoi: The world will end when the monks ﬁnish solving a 64-disk version of the puzzle. For a three-disk puzzle, the solution required seven moves. If each move takes one second, how long will it take the monks to solve the 64-disk puzzle? Would the number of moves for an iterative version be any diﬀerent?

30. Fibonacci Numbers: We considered this a bad application of recursion when we introduced it for the LC-3, and it still is in C! But this example is worth reexamining. It’s simple enough to express with a short C function, yet complex enough to have interesting stack behavior during execution. Also, we can view a complete translation to LC-3 assembly and take note of how the recursion is handled by the run-time stack.

31. The following recurrence equations generate a well-known sequence of num- bers called the Fibonacci numbers, which has some interesting mathematical, geometrical, and natural properties.

f (n) = f (n − 1) + f (n − 2)
f (1) = 1
f (0) = 1

32. The nth Fibonacci number is the sum of the previous two. The series is 1, 1, 2, 3, 5, 8, 13, … This series was popularized by the Italian mathematician Leonardo of Pisa around the year 1200 (it is thought to have ﬁrst been described by Indian mathematicians around 200 BC). 

33. We can formulate a recursive function to calculate the nth Fibonacci number directly from the recurrence equations. Fibonacci(n) is recursively calculated by Fibonacci(n-1) + Fibonacci(n-2). The base case of the recursion is simply the fact that Fibonacci(1) and Fibonacci(0) both equal 1. Figure 17.13 lists the recursive code to calculate the nth Fibonacci number.

34. Whenever a function is called, whether from itself or another function, a new copy of its stack frame is pushed onto the run-time stack. That is, each invocation of the function gets a new, private copy of parameters and local variables. And once each invocation completes, this private copy must be deallocated. The run-time stack enables this in a natural fashion. If the variables of a recursive function were statically allocated in memory, each recursive call to Fibonacci would overwrite the values of the previous call.

35. Let’s take a look at the run-time stack when we call the function Fibonacci with the parameter 3, Fibonacci(3).Westartoﬀwiththestackframefor Fibonacci(3) on top of the run-time stack. Figure 17.14 shows the progression of the stack as the original function call is evaluated.  

36. The  func- tion call Fibonacci(3) will ﬁrst calculate Fibonacci(3-1) as the expression Fibonacci(n-1) + Fibonacci(n-2) is evaluated left to right. Therefore, a call is ﬁrst made to Fibonacci(2), and a stack frame for Fibonacci(2) is pushed onto the run-time stack (see Figure 17.14, step 2). 

37.  For Fibonacci(2), the parameter n equals 2 and does not meet the terminal condition; therefore, a call is made to Fibonacci(1) (see Figure 17.14, step 3). This call is made in the course of evaluating Fibonacci(2-1) + Fibonacci(2-2). The call Fibonacci(1) results in no more recursive calls because the parameter n meets the terminal condition. The value 1 is returned to Fibonacci(2), which now can complete the evaluation of Fibonacci(1) + Fibonacci(0) by calling Fibonacci(0) (see Figure 17.14, step 4). 

38. The call Fibonacci(0) immediately returns a 1. Now, the call Fibonacci(2) can complete and return its subcalcula- tion (its result is 2) to its caller, Fibonacci(3). Having completed the left-hand component of the expression Fibonacci(2) + Fibonacci(1), Fibonacci(3) calls Fibonacci(1) (see Figure 17.14, step 5), which immediately returns the value 1. Now Fibonacci(3) is done—its result is 3 (Figure 17.14, step 6). We could state the recursion of Fibonacci(3) algebraically, as follows:

Fibonacci(3) = Fibonacci(2) + Fibonacci(1)
             = (Fibonacci(1) + Fibonacci(0)) + Fibonacci(1)
             = 1 + 1 + 1 = 3 

39. The sequence of function calls made during the evaluation of Fibonacci(3) is as follows:

Fibonacci(3)
Fibonacci(2)
Fibonacci(1)
Fibonacci(0)
Fibonacci(1)

40. Walk through the execution of Fibonacci(4) and you will notice that the sequence of calls made by Fibonacci(3) is a subset of the calls made by Fibonacci(4). No surprise, since Fibonacci(4) = Fibonacci(3) + Fibonacci(2). Likewise, the sequence of calls made by Fibonacci(4) is a subset of the calls made by Fibonacci(5). 

41. it’s worthwhile to compare the running time of the recursive version of Fibonnaci in C to an iterative version. The simple recursive version, while it falls directly out of the recurrence equations and is easy to code, is far more costly than its iterative counterpart. It is more expensive not only because of the function call overhead, but also because the recursive solution has a signiﬁcant number of repeated calculations that the iterative version does not.

42. Figure 17.15 lists the LC-3 C compiler generated for this Fibonacci program. Notice that no special treatment was required to handle the program’s recursive nature. Because of the run-time stack mechanism for activating functions, a recursive function gets treated like every other function. If you examine this code closely, you will notice that the compiler generated a temporary variable in order to translate line 24 of Fibonacci properly. Most compilers will generate such temporaries when compiling complex expressions and will allocate storage in the stack frame on top of programmer-declared local variables.

43. Binary Search: Say we want to ﬁnd a particular integer value in an array of integers that is in ascending order. The function should return the index of the integer, or a −1 if the integer does not exist. To accomplish this, we will use the binary search technique as follows: Given an array and an integer to search for, we will examine the midpoint of the array and determine if the integer is (1) equal to the value at the midpoint, (2) less than the value at the midpoint, or (3) greater than the value at the midpoint. If it is equal, we are done. If it is less than, we perform the search again, but this time only on the ﬁrst half of the array. If it is greater than, we perform the search only on the second half of the array. Notice that we can express cases (2) and (3) using recursive calls.

44. What happens if the value we are searching for does not exist within the array? Given this recursive technique of performing searches on smaller and smaller subarrays of the original array, we eventually perform a search on an array that has no elements (e.g., of size 0) if the item we are searching for does not exist. If we encounter this situation, we will return a −1. This will be a base case in the recursion.

45. Figure 17.16 contains the recursive implementation of the binary search algorithm in C. Notice that in order to determine the size of the array at each step, we pass the starting and ending points of the subarray along with each call to BinarySearch. Each call reﬁnes the variables start and end to search smaller and smaller subarrays of the original array list. The variable start contains the array index of the ﬁrst data item, and the variable end contains the index of the last data item.

46. Figure 17.17 provides an illustration of this code during execution. The array list contains eleven elements as shown. The initial call to BinarySearch passes the value we are searching for (item) and the array to be searched.  (Recall from Chapter 16 that this is the address of the very ﬁrst element, or base address, of the array.) Along with the array, we provide the extent of the array. That is, we provide the starting and ending points of the portion of the array to be searched.

47. In every subsequent recursive call to BinarySearch, this extent is made smaller, eventually reaching a point where the subset of the array we are searching has either only one element or no elements at all. These two situations are the base cases of the recursion.

48. A more straightforward search technique would be to sequentially search through the array. That is, we could examine list[0], then list[1], then list[2], etc., and eventually either ﬁnd the item or determine that it does not exist. Binary search, however, will require fewer comparisons and can potentially execute faster if the array is large enough.

49. Escaping a Maze:  Let’s start by considering how to represent a maze in C. we’ll use a two-dimensional array, with each element in the array representing whether the maze position is blocked (because it contains a wall), is open, or contains an exit. The maze will be a character array, where each element of the array contains the character X for a blocked space, a space ’ ’ character for an open space, and the character E for an exit. Our maze solver will take this 2D array as input, along with coordinates of the initial starting point, and will search through the maze to ﬁnd a path to the exit, if it exists. 

50. Figure 17.18 shows an example of a simple 4 × 4 maze represented in our 2D array format. In this example, maze[3][0] = 'E' designates the exit, and maze[0][2] = 'X' is an example of a space that is blocked. If we set the initial position to maze[1][2], then there exists a path to the exit.

51. Now the question is, how might a maze solver compute the path to the exit? We can use the following idea: From the starting point, if a path to the exit exists, it must go through the space either directly to the left, directly to the right, directly up, or directly down from the initial point. So we set the new position to one of those spaces and recursively solve the maze from there. That is, from the new point, if a solution exists, it must go through space to the left, to the right, directly up, or directly down from the new point.

52. Eventually, we’ll hit a blocked space X or the exit E. And these designate base cases for the recursion. We’ll also need to mark spaces that we’ve already visited with a V. This will enable us to skip over spaces that we’ve already evaluated, and it will prevent us from going in circles (literally!). This will also be a base case.

53. Figure 17.19 provides the C code implementation of the ExitMaze function. It takes as its parameters a maze represented as a 2D character array of dimensions MAZE_HEIGHT by MAZE_WIDTH, and two integers that represent the current position as x and y indices in the maze array. 

54. The initial portion of the function checks to see if we’ve hit any of our terminal conditions: Either xpos or ypos is out of the maze, or the current position is the exit or corresponds to a space in the maze that has already been visited or is blocked. If not, we mark the current position as visited and recursively check the neighboring positions.

55. This algorithm performs something called a depth-ﬁrst search through all the possible paths through the maze. We can represent the recursive calls as a graph, where each node in the graph corresponds to an invocation of the function ExitMaze. In the general case, each invocation of ExitMaze can make up to four recursive calls (one call for each direction). So each node can end up creating up to four new invocations of ExitMaze. Figure 17.20 provides a graphical depiction of ExitMaze in action. The initial call shows the initial maze conﬁguration, along with the starting point (maze[1][2]). That initial call generates four new calls, each evaluated one after the other. The ﬁrst call (move down) returns immediately, as does the next call (move right), as does the third call (move up). The fourth call (move left) is a move into an open space, and thus it causes new calls to be generated.


chapter 18

1. Whether it be to the screen, to a ﬁle, or to another computer across a network, all useful programs perform output of some sort or another. Most programs also require some form of input. As is the case with many other modern programming languages, input and output are not directly supported by C. Instead input/output (I/O) is handled by a set of standard library functions that extend the base language. 

2. The behavior of these standard library functions is precisely deﬁned by the ANSI C standard. The functions putchar and printf write to the output device, and getchar and scanf read from the input device. The more general functions fprintf and fscanf perform ﬁle I/O, such as to a ﬁle on disk. We have used printf and scanf extensively throughout the second half of this book.

3. The C Standard Library: The C standard library is a major extension of the C programming language. It provides support for input/ouput, character string manipulations, mathematical functions, ﬁle access functions, and various system utilities that are not specifically required for a single program but are generally useful in many programs.

4. The standard library is intended to be a repository of useful, primitive functions that serve as components for building complex software. This component-based library approach is a characteristic of many contemporary programming languages such as C++, Java, and Python, which also have similar standard libraries of primitive functions, types, and other facilities.

5. The library’s functions are typically developed by the designers of the underlying device and system—the Android smartphone, for example—and are optimized for the system on which they are developed.

6. To use a function deﬁned within the C standard library, we must include the appropriate header ﬁle (.h ﬁle). The functions within the standard library are grouped according to their functionality. Each of these groups has a header ﬁle associated with it. For example, mathematical functions such as sin and tan use the common header ﬁle math.h. The standard I/O functions use the header ﬁle stdio.h. These header ﬁles contain, among other things, function declarations for the I/O functions and preprocessor macros relating to I/O. A library header ﬁle does not contain the source code for library functions.

7. If the header ﬁles do not contain source code, how does the machine code for, say, printf get added to our applications? Each library function called within a program is linked in when the executable image is formed. 

8. The object ﬁles containing the library functions are stored somewhere on the system and are accessed by the linker, which links together the various function binaries into a single executable program. We refer to this as static linking.

9. Libraries can be linked dynamically into the application. With certain types of libraries (dynamically linked libraries, or DLLs), the machine code for a library isn’t directly integrated into the executable image but is “linked” on demand, while the program executes. This has a number of advantages over a statically linked library. It reduces the size of the executable, it enables multiple programs to link the same code, thereby reducing memory requirements, and it allows the library to be upgraded independently from the application.

10. I/O, One Character at a Time: The functions getchar and putchar perform input and output on a single character at a time. Input is read in as ASCII and output is written out as ASCII, in a manner similar to the IN and OUT TRAP routines of the LC-3.

11. I/O Streams: Conceptually, all character-based input and output is performed in streams. The sequence of ASCII characters typed by the user at the keyboard is an example of an input stream. As each character is typed, it is added to the end of the stream. Whenever a program reads keyboard input, it reads from the beginning of the stream. The sequence of ASCII characters printed by a program, similarly, is added to the end of the output stream. In other words, this stream abstraction allows us to further decouple the producer from the consumer, which is helpful because the two are usually operating at diﬀerent rates.

12. For example, if a program wants to perform some output, it adds characters to the end of the output stream without being required to wait for the output device to ﬁnish displaying the previous character. Many other popular languages, such as C++, provide a similar stream-based abstraction for I/O.

13. In C, the standard input stream is referred to as stdin and is mapped to the keyboard by default. The standard output stream is referred to as stdout and is mapped by default to the display. The functions getchar and putchar operate on these two streams.

14. putchar: The function putchar is the high-level language equivalent of the LC-3 OUT TRAP routine. The function putchar displays on the stdout output stream the ASCII value of the parameter passed to it. It performs no type conversions—the value passed to it is assumed to be ASCII and is added directly to the output stream. All the calls to putchar in the following code segment cause the same character (lowercase h) to be displayed. The function putchar is the high-level language equivalent of the LC-3 OUT TRAP routine. The function putchar displays on the stdout output stream the ASCII value of the parameter passed to it. It performs no type conversions—the value passed to it is assumed to be ASCII and is added directly to the output stream. All the calls to putchar in the following code segment cause the same character (lowercase h) to be displayed.

15. A putchar function call is treated like any other function call, except here the function resides within the standard library. The function declaration for putchar appears in the stdio.h header ﬁle. Its code will be linked into the executable during the compiler’s link phase.

char c = 'h';
:
putchar(c);
putchar('h');
putchar(104);

16. getchar: The function getchar is the high-level language equivalent of the LC-3 IN TRAP function. It returns the ASCII value of the next input character appearing in the stdin input stream. By default, the stdin input stream is simply the stream of characters typed at the keyboard. In the following code segment, getchar returns the ASCII value of the next character typed at the keyboard. This return value is assigned to the variable c.

char c;
c = getchar();

17. Buffered I/O: Run the C code in Figure 18.1 and you will notice something peculiar. The program prompts the user for the ﬁrst input character and waits for that input to be typed in. Type in a single character (say z, for example) and nothing happens. The second prompt does not appear, as if the call to getchar has missed the keystroke. In fact, the program seems to make no progress at all until the Enter/Return key is pressed. Such behavior seems unexpected considering that getchar is speciﬁed to read only a single character from the keyboard input stream. This unexpected behavior is due to buﬀering of the keyboard input stream. On most devices, I/O streams are buﬀered.

18. streams are buﬀered. Every key typed on the keyboard is captured by the lower levels of the system software and kept in a buﬀer, which is a small array or queue (see Section 8.4), until it is released into the stream. In the case of the input stream, the buﬀer is released when the user presses Enter. The Enter key itself appears as a newline character in the input stream. 

19. So in the example in Figure 18.1, if the user types the character A and presses Enter, the variable inChar1 will equal the ASCII value of A (which is 65) and the variable inChar2 will equal the ASCII value of newline (which is 10). 

20. There is a good reason for buﬀering, particularly for keyboard input: Pressing the Enter key allows the user to conﬁrm the input. Say you mistyped some input and wanted to correct it before the program detects it. You can edit what you type using the Backspace and Delete keys, and then conﬁrm your input by pressing Enter.

21. The output stream is similarly buﬀered. Observe by running the program in Figure 18.2. This program uses a new library function called sleep that suspends the execution of the program for approximately the number of seconds provided as the integer argument, which in this case is 5. This library function requires that we include the unistd.h header ﬁle. 

22. Run this code and you will notice that the output of the character a does not happen quite as you might expect. Instead of appearing prior to the ﬁve-second delay, the character a appears afterwards, only after the newline character releases the output buﬀer to the output stream. We say that the putchar('\n') causes output to be ﬂushed.Addaputchar('\n') statement immediately after line 6 and the program will behave diﬀerently.

23. Despite the slightly complex behavior of buﬀered I/O streams, the underlying mechanism used to make this happen is the device’s native I/O functionality, which in the case of the LC-3 is the IN and OUT TRAP routines described in Chap- ter 8. The buﬀering of streams is accomplished by the interrupt service routines that handle the arrival of input data, or the OUT service routine.

24. Formatted I/O: The functions putchar and getchar suﬃce for simple I/O tasks but are cumbersome for performing non-ASCII I/O. The functions printf and scanf perform more sophisticated formatted I/O, and they are designed to more conveniently handle I/O of integer and ﬂoating point values.

25. printf: writes formatted text to the output stream. Using printf, we can print out ASCII text embedded with values generated by the running program. The printf function takes care of all of the type conversions necessary for this to occur. For example, the following code prints out the value of integer variable x. In doing so, the printf must convert the integer value of x into a sequence of ASCII characters that can be embedded in the output stream.

int x;
printf("The value is %d\n", x);

26. Generally speaking, printf writes its ﬁrst parameter to the output stream. The ﬁrst parameter is the format string. It is a character string (i.e., of type char *) containing text to be displayed on the output device. Embedded within the format string are zero or more conversion speciﬁcations.

27. The conversion speciﬁcations indicate how to print out any of the parameters that follow the format string in the function call. Conversion speciﬁcations all begin with a % character. As their name implies, they indicate how the values of the parameters that follow the format string should be treated when converted to ASCII.

28. In many of the examples we have encountered so far, integers have been printed out as decimal numbers using the %d speciﬁcation. We could also use the %x speciﬁcation to print integers as hexadecimal numbers, or %b to print them as binary numbers (represented as ASCII text, of course). Other conversions include %c, which causes a value to be interpreted as straight ASCII, and %s, which is used for strings and causes characters stored consecutively in memory to be output (for this the corresponding parameter is expected to be of type char*).

29. The speciﬁcation %f interprets the corresponding parameter as a ﬂoating point number and displays it in a ﬂoating point format. What if we wanted to print out the % character itself? We use the sequence %%. As mentioned in Chapter 11, when we ﬁrst encountered C I/O functions, special characters such as newline can also be embedded in the format string. The \n prints a new line, and a \t character prints a tab; both are examples of these special characters. All special characters begin with a \ and they can appear anywhere within a format string. To print out a backslash character, we use a \\.

30. The function printf begins by examining the format string a single character at a time. If the current character is not a % or \, then the character is directly written to the output stream. (Recall that the output stream is buﬀered, so the output might not appear on the display until a new line is written.) If the character is a \, then the next character indicates the particular special character to print out. For instance, the escape sequence \n indicates a newline character. If the current character is a %, indicating a conversion speciﬁcation, then the next character indicates how the next pending parameter should be interpreted. For instance, if the conversion speciﬁcation is a %d and the next pending parameter has a value that corresponds to the bit pattern 0000000001101000, then the number 104 is written to the output stream.

31. If the conversion character is a %c, then the character h is written. A diﬀerent value is printed if %f is the conversion speciﬁcation. The conversion speciﬁer indicates to printf how the next parameter should be interpreted. It is important to realize that, within the printf routine, there is no relationship between a conversion speciﬁcation and the type of a parameter.

32. Question: What happens with the following function call? 

printf("The value of nothing is %d\n");

There is no argument corresponding to the %d speciﬁcation. When the printf routine is called, it assumes the correct number of values was written onto the stack, so it blindly reads a value oﬀ the stack for the %d spec, assuming it was intentionally placed there by the caller. Here, a garbage value is displayed to the screen, in decimal.

33. scanf: is used to read formatted ASCII data from the input stream. A call to scanf is similar to a call to printf. Both calls require a format string as the ﬁrst argument followed by a variable number of other arguments. Both func- tions are controlled by characters within the format string. The function scanf diﬀers in that all arguments following the format string must be pointers. As we discussed in Chapter 16, scanf must be able to access the original locations of the objects in memory in order to assign new values to them.

34. The format string for scanf contains ASCII text and conversion speciﬁcations, just like the format string for printf. The conversion characters are similar to those used for printf. A table of these speciﬁcations can be found in Appendix D. Essentially, the format string represents the format of the input stream.

35. For example, the format string "%d" indicates to scanf that the next sequence of non–white space characters (white space is deﬁned as spaces, tabs, new lines, carriage returns, vertical tabs, and form feeds) is a sequence of digits in ASCII representing an integer in decimal notation. After this decimal number is read from the input stream, it is converted into an integer and stored in the corresponding argument. Since scanf modiﬁes the values of the variables passed to it, arguments are passed by reference using the & operator. 

36. In addition to conversion speciﬁcations, the format string also can contain plain text, which scanf tries to match with the input stream. We use the following code to demonstrate.

char name[100];
int month, day, year;
double gpa;

printf("Enter : lastname birthdate grade_point_average\n"); 
scanf("%s %d/%d/%d %lf", name, &month, &day, &year, &gpa);

printf("\n");
printf("Name : %s\n", name);
printf("Birthday : %d/%d/%d\n", month, day, year);
printf("GPA : %f\n", gpa);

37. In this scanf statement, the ﬁrst speciﬁcation is a %s that scans a string of characters from the input stream. In this context, all characters starting from the ﬁrst non–white space character and ending with the next white space character (conceptually, the next word in the input stream) are stored in memory starting at the address of name.An\0 character is automatically added to signify the end of the string. Since the argument name is an array, it is automatically passed by reference; that is, the address of the ﬁrst element of the array is passed to scanf.

38. The next speciﬁcation is for a decimal number, %d.Nowscanf expects to ﬁnd a sequence of digits (at least one digit) as the next set of non–white space char- acters in the standard input stream. Characters from standard input are analyzed, white space characters are discarded, and the decimal number (i.e., a sequence of digits terminated by a nondigit) is read in. The number is converted from a sequence of ASCII characters into a binary integer and stored in the memory location indicated by the argument &month.

39. The next input ﬁeld is the ASCII character /.Now,scanf expects to ﬁnd this character, possibly surrounded by white space, in the input stream. Since this input ﬁeld is not a conversion speciﬁcation, it is not assigned to any variable. Once it is read in from the input stream, it is discarded, and scanf moves onto the next ﬁeld of the format string. Similarly, the next three input ﬁelds %d/%d read in two decimal numbers separated by a /. These values are converted into integers and are assigned to the locations indicated by the pointers appearing as the next two arguments (which correspond to the addresses of the variables day and year).

40. The last ﬁeld in the format string speciﬁes that the input stream contains a long ﬂoating point number, which is the speciﬁcation used to read in a value of type double. For this speciﬁer, scanf expects to see a sequence of decimal numbers, and possibly a decimal point, possibly an E or e signifying exponential notation, in the input stream (see Appendix D.2.4). This ﬁeld is terminated once a nondigit (excluding the ﬁrst E, or the decimal point or a plus or minus sign for the fraction or exponent) or white space is detected. The scanf routine takes this sequence of ASCII characters and converts them into a properly expressed, double-precision ﬂoating point number and stores it into gpa.

41. Once it is done processing the format string, scanf returns to the caller. It also returns an integer value. The number of format speciﬁcations that were suc- cessfully scanned in the input stream is passed back to the caller. In this case, if everything went correctly, scanf would return the value 5. In the preceding code example, we chose to ignore the return value.

42. So, for example, the following line of input yields the following output:

Enter : lastname birthdate grade_point_average
Mudd 02/16/69 3.02

Name : Mudd
Birthday : 2/16/69
GPA : 3.02

Since scanf ignores white space for this format string, the following input stream yields the same results. Remember, newline characters are considered white space.

Enter : lastname birthdate grade_point_average
Mudd 02
/
16 / 69 3.02

Name : Mudd
Birthday : 2/16/69
GPA : 3.02

43. What if the format of the input stream does not match the format string? For instance, what happens with the following stream?

Enter : lastname birthdate grade_point_average Mudd 02 16 69 3.02

Here, the input stream does not contain the / characters encoded in the format string. In this case, scanf returns the value 2, since the variables name and month are correctly assigned before the mismatch between the format string and the input stream is detected. The remaining variables go unmodiﬁed. Since the input stream is buﬀered, unused input is not discarded, and subsequent reads of the input stream begin where the last call left oﬀ.

44. If the next two reads of the input stream are 

a = getchar();
b = getchar();

what do a and b contain? The answer ''(the space character) and 1 should be no surprise.

45. Variable Argument Lists: printf and scanf have a variable number of arguments passed to them. The number of arguments passed to printf and scanf depends on the number of items being printed or scanned. We say such functions have variable argument lists. In the case of printf and scanf, there is a one-to-one correspondence between each conversion speciﬁcation in the format string and each argument that appears after the format string in such function calls. 

printf("Char %c.\t String %s\n Float %f\n", c, banner, pi);

46. In the above printf statement the format string contains three format speciﬁcations; therefore, three argu- ments should follow it in the function call. The %c spec in the string is associated with the ﬁrst argument that follows (the variable c). The %s is associated with banner, and %f with pi. There are three values to be printed; therefore, this call contains four arguments altogether. If we want to print ﬁve values, the printf call should contain six arguments.

47. Recall from Chapter 14 that our LC-3 calling convention pushed items onto the run-time stack from right to left of the order in which they appear on the function call. This places the pointer to the format string immediately at the top of the stack when printf or scanf takes over. Since it is the leftmost argument, it will always be the last item pushed onto the stack before the function call (JSR instruction) occurs. Once printf or scanf takes over, it can access the ﬁrst parameter directly oﬀ the top of the stack. Once this parameter (which is the format string) is analyzed, the functions can determine the other parameters on the stack. If the arguments on a function call were pushed from left to right, it would be much more diﬃcult for printf and scanf to discern the location of the format string parameter.

48. Figure 18.3 shows two diagrams of the run-time stack. In diagram (a), the arguments to the call for printf are passed from right to left, and in (b) they are passed from left to right. Consider for which case the resulting LC-3 code for printf will be simpler.

49. In version (a), the oﬀset of the format string from the stack pointer will always be zero, regardless of the number of other parameters on the stack. In version (b), the oﬀset of the format string from the stack pointer depends on the number of parameters on the stack. The format string, like all other strings embedded within a program’s source code, is stored in a special region of memory reserved for constants, or literal values.

50.  I/O from Files: I/O in C is based on streams, as we described earlier, and these streams are conceptually all bound to ﬁles. The functions printf and scanf are in fact special cases of more general-purpose C I/O functions. These two functions operate speciﬁcally on two special ﬁles called stdin and stdout. In C,stdin and stdout are mapped by default to the keyboard and the display.

51. The general-purpose version of printf is called fprintf, and the general-purpose version of scanf is called fscanf. The functions fprintf and fscanf work like their counterparts, with the main diﬀerence being that they allow us to specify the stream on which they act. For example, we can tell fprintf to write its output to a speciﬁc ﬁle with a particular name at a precise location on the device. 

52. The ﬁrst step in performing ﬁle I/O is to declare a ﬁle pointer for each ﬁle we want to manipulate. Typically, ﬁles are stored on the ﬁle system of the device, which provides protected and secure access to all the documents, images, exe- cutables, videos, text ﬁles, and other data stored on the devices. In C, we can declare a ﬁle pointer called inﬁle as follows:

FILE *infile;

53. Here we are declaring a pointer to something of type FILE. The type FILE is deﬁned within the header ﬁle stdio.h. Its details are not important for current purposes. Once the ﬁle pointer is declared, we need to map it to a ﬁle on the device’s ﬁle system. The C library call fopen performs this mapping. Each fopen call requires two arguments: the name of the ﬁle to open and the description of what type of operation we want to perform on the ﬁle. An example follows.

FILE *infile;
infile = fopen("aapl_stock_prices", "r");

54. The ﬁrst argument to fopen is the string aapl_stock_prices, which is the name of the ﬁle to open. The second argument is the operation we want to per- form on this ﬁle. Several useful modes are "r" for reading, "w" for writing (a ﬁle opened with this mode will lose its previous contents), "a" for appending (here, previous contents is not lost; new data is added to the end of the ﬁle), and "r+" for reading and writing. Note that both arguments must be character strings; therefore, they are surrounded by double quotes in this example. In this case, we are opening the ﬁle called "aapl_stock_prices" for reading.

55. If the fopen call is successful, the function returns a ﬁle pointer to the phys- ical ﬁle. If the open for some reason fails (as in a case when the ﬁle cannot be found), then the function returns a null pointer. Recall that a null pointer is an invalid pointer that has the value NULL. It is always good practice to check to determine if the fopen call was successful.

FILE *infile;
infile = fopen("ibm_stock_prices", "r");
if (infile == NULL)
     printf("fopen unsuccessful!\n");

56. Now with the ﬁle pointer properly mapped to a physical ﬁle, we can use fscanf and fprintf to read and write it just as we used printf and scanf to read the standard devices. The functions fscanf and fprintf both require a ﬁle pointer as their ﬁrst argument to indicate on which stream the operations are to be performed. The example in Figure 18.4 demonstrates this.

57. Here, we are reading from an ASCII text ﬁle called aapl_stock_prices and writing to a ﬁle called buy_hold_or_sell. The input ﬁle contains the stock prices represented as ﬂoating point data, each separated by white space. Even though the ﬁle can contain more, our program will process at most 10,000 items.

58. The fscanf function returns a special value when no more data can be read from the input ﬁle, indicating the end of ﬁle has been reached. We can check the return value of fscanf against this special character, which is deﬁned to the preproces- sor macro EOF. The while loop terminates once we encounter the EOF character, or if we reach the data limit of 10,000 items. After reading the input ﬁle, the program processes the input data and generates the string answer, which is then written to the output ﬁle. The function printf is equivalent to calling fprintf using stdout as the ﬁle pointer. Likewise, scanf is equivalent to calling fscanf using stdin.

chapter 19

1. C at its core provides support for just a few fundamental types of data. That is, C natively supports the allocation of variables of integers, ﬂoating point values, characters, and booleans. C also supports operators that manipulate these types, such as + for addition and * for multiplication. With C, we can quite easily declare variables of these native types, and we can also create arrays of them and pointers to them.

2. Ultimately, though, when we write code, we often deal with things that can- not be easily described by an integer, or ﬂoating point value, or character, or boolean, or even by arrays of them. If we are, for example, modeling an aircraft wing or developing the path planner for an autonomous vehicle, we need more sophisticated types in order to map the real world (or virtual world) into the digital world of the computing device.

3. The next two chapters deal primarily with the framework that C and C++ provide for creating and organizing more complex data types. We’ll discover that the fundamental data types, as limited as they are, form the building blocks with which we can build nearly any general, complex type we might need. Creating these types, organizing them, connecting them together, and deﬁning operations to manipulate them are a large part of the coding process.

4. In C, we can create a new type that is a collection of basic types by using a structure. Structures provide us with a convenient way of representing objects that are best represented by combinations of the basic types. For example, an employee might be represented as a structure containing a name (character string), job title (character string), department (perhaps integer), and employee ID (integer) within a corporate database. With this structure, we can declare a single memory object representing an employee just as simply as we can declare an integer variable.

5. In addition to structures, we’ll explore dynamic memory allocation in C, which is a framework for allocating memory objects that are more persistent than those allocated on the run-time stack. With the pairing of structures and dynamic memory allocation, we can create dynamic data structures that can grow and shrink and persist in memory across diﬀerent function calls. This capability is so incredibly useful that it forms the basis of most software development.

6. Let’s leap straight into an example. Let’s say we wanted to track airborne aircraft around a particular geographic point, say the city of Urbana, Illinois. There are several characteristic features that we would want to associate with each aircraft. for example, we’d want the following values:

char ID[7];         // Max 6 characters
int altitude;       // in meters
int longitude;      // in tenths of degrees
int latitude;       // in tenths of degrees
int heading;        // in tenths of degrees
double airSpeed;    // in kilometers/hour

7. Structures allow the programmer to deﬁne a new type that consists of a combination of other, simpler types such as int, char, and double, as well as pointers to them and arrays of them. Structure variables are declared in the same way variables of fundamental data types are declared. Before any structure variables are declared, however, the structure itself needs to be deﬁned.

8. For our aircraft tracking app, we could create a structure deﬁnition as such:

struct flightType {
     char ID[7];         // Max 6 characters
     int altitude;       // in meters
     int longitude;      // in tenths of degrees
     int latitude;       // in tenths of degrees
     int heading;        // in tenths of degrees
     double airSpeed;    // in kilometers/hour
};

9. With this structure deﬁnition, we create a new type consisting of six values, or members. If we were to declare something of this new type, it would be allocated in contiguous storage, with enough space for all its members. To declare a variable of this new type, we do the following:

struct flightType plane;

This declares a variable called plane that consists of the six members deﬁned in the structure deﬁnition.

10. We can access the individual members of this structure variable using the following syntax:

struct flightType plane;
plane.airSpeed = 800.00;
plane.altitude = 10000;

Each member can be accessed using the variable’s name as the base name followed by a dot “.” followed by the member name.

11. The variable plane gets allocated onto the stack just like any other local variable, and it occupies a contiguous region of memory large enough to hold all member elements. In this case, if each of the basic types occupied one LC-3 memory location, the variable plane would occupy 12 locations (7 for the character string, 5 for the integers, and 1 for the double). Figure 19.1 shows a portion of the run-time stack when a function that contains the following declarations is invoked.

int x;
struct flightType plane;
int y;

12. More generally, the syntax for a structure declaration is as follows:

struct tag {
     type1 member1;
     type2 member2;
     ...
     typeN memberN
} identifiers;

13. The tag ﬁeld provides a handle for referring to the structure later in the code, as in the case of declaring variables of the structure’s format. The list of members deﬁnes the organization of a structure and is syntactically a list of declarations in types that have been previously deﬁned. A member can be of any type, including another structure type. We can optionally include identiﬁers in a structure’s dec- laration to actually declare variables of that structure’s type. These appear after the closing brace of the structure declaration, prior to the semicolon.

14. typedef: C structures enable programmers to deﬁne their own aggregate types. C typedef enables programmers to name their own types. It has the general form 

typedef type name;

It’s not so much a type deﬁnition, as its name implies, as it is a type synonym. This statement causes the identiﬁer name to be synonymous with the type type, which can be any basic type or aggregate type (e.g., a structure). For instance,

typedef int Color;

allows us to deﬁne variables of type Color, which will now be synonymous with integer. Using this deﬁnition, we can declare:

Color pixels[200][100];

which could be used to represent an image, for example, of size 200 × 100 pixels.

15. The typedef facility is particularly useful when dealing with structures. For example, we can create a simpler, more meaningful name for our airborne aircraft structure.

struct flightType {
     char ID[7];         // Max 6 characters
     int altitude;       // in meters
     int longitude;      // in tenths of degrees
     int latitude;       // in tenths of degrees
     int heading;        // in tenths of degrees
     double airSpeed;    // in kilometers/hour
};

typedef struct flightType Flight;

Now we can declare structure variables using the type name Flight. For example,

Flight plane;

is now equivalent to the declaration used previously:

struct flightType plane;

16. The typedef declaration provides no additional functionality. However, its purpose is to provide additional clarity to our code, particularly code that is heavy with programmer-deﬁned types. Well-chosen type names connote properties of the variables they declare even beyond what can be expressed by the names of the variables themselves.

17. Implementing Structures in C: A structure variable is a regular variable like an int, char,or ﬂoat, but with more moving parts. Each of these parts is necessarily a simpler type that can be directly manipulated using existing operators.
For example, in the following code, the member altitude of the structure variable of type Flight is accessed.

int x;
Flight plane;
int y;
plane.altitude = 0;

18. Here, the variable plane is of type Flight, meaning it contains the six mem- ber ﬁelds we deﬁned previously. The member ﬁeld labeled altitude is accessed using the variable’s name followed by a period, followed by the member ﬁeld label. The compiler, knowing the layout of the structure, generates code that accesses the structure’s member ﬁeld using the appropriate oﬀset. Figure 19.1 shows the layout of the portion of the stack frame for this function. The compiler keeps track, in its symbol table, of the position of each variable in relation to the base pointer R5, and if the variable is an aggregate data type, it also tracks the position of each ﬁeld within the variable. Notice that for the particular reference plane.altitude = 0;, the compiler must generate code to access the second variable on the stack and the second member element of that variable. Following is the code generated by the LC-3 C compiler for the assignment statement plane.altitude = 0;

AND R1, R1, #0      ; zero out R1
ADD R0, R5, #-12    ; R0 contains base address of plane
STR R1, R0, #7      ; plane.altitude = 0;

19. Arrays of Structures: An easy, straightforward way to represent the set of airborne aircraft would be to use an array. We are already familiar with arrays for building contiguous collections of simple variables, and here we’ll apply the same concept to objects of ﬂightType. We quickly run into a design issue in that we need to pick a size for the array, either statically or using a variable-sized array. For the sake of example, let’s make the determination that no more than 100 aircraft will exist in this airspace (but what if we are wrong?). For this the following declaration suﬃces:
Flight aircraft[100];

20. This declaration is like a declaration of a regular array, except instead of declaring 100 integer values, we have declared a contiguous region of memory contain- ing 100 structures, each of which is composed of the six members indicated in the declaration struct ﬂightType. The reference aircraft[12], for example, would refer to the 13th object in the region of 100 such objects in memory.

21. Each object contains enough storage for its six constituent member ele- ments. Each object in this array is of type Flight (which is a synonym of struct ﬂightType) and can be accessed using standard array notation. For example, accessing the ﬂight characteristics of the ﬁrst aircraft can be done using the identiﬁer aircraft[0]. Accessing a member ﬁeld is done by accessing an element of the array and then specifying a ﬁeld:

aircraft[0].heading

22. What if there are fewer than 100 aircraft? We’d need some convenient way of tracking the actual number of airborne aircraft in our array.

23. We can also create pointers to structures. The following declaration creates a pointer variable that contains the address of a variable of type Flight.

Flight *aircraftPtr;

We can assign this variable as we would any pointer variable.

aircraftPtr = &aircraft[34];

24. If we want to access any of the member ﬁelds pointed to by this pointer variable, we could use an expression such as the following:

(*aircraftPtr).longitude

25. Let’s decode this expression. We are dereferencing the variable aircraftPtr. It points to something of type Flight, which is a structure. We can access one of the member elements of this structure by using the dot operator (.). Pointers to structures are an incredibly powerful and therefore commonly used concept, so the creators of the C programming language provided for a simple, intuitive syntax for this type of dereferencing. The previous expression is equivalent to:

aircraftPtr->longitude

26. That is, the expression -> is like the dereference operator *, except it is used for directly dereferencing a member element of a structure type. The symbol -> visually evokes that something is being pointed at.

27. Say we want to add some functionality that determines, for each aircraft, which of the other aircraft is clos- est in physical distance. To accomplish this, we need to examine the position and altitude of each aircraft and determine the one that is closest to the reference aircraft. In Figure 19.2, the function NearestNeighbor calls the function AirDistance on pairs of aircraft to determine distance and ﬁnds the minimum of all pairs. The function AirDistance isn’t completely coded. It uses the position and altitude of each of its two arguments to determine their distance apart.

28. Notice that NearestNeighbor passes AirDistance two pointers rather than the structures themselves. While it is possible to pass structures, passing pointers is more eﬃcient because it involves less pushing of data onto the run-time stack; that is, in this case two pointers are pushed rather than 24 locations’ worth of data for two objects of type Flight.

29. Dynamic Memory Allocation: The choice of array of Flight types for our core data structure is quite problem- atic for several reasons. We needed to choose a size for this array and hard-code that size into our code. If the number of aircraft is fewer than that size, then we are okay, except that we have more space allocated than we actually need. Yes, we also need a means for identifying which array elements contain real aircraft and which are unused. But if we had more than that number of aircraft in the sky, then our code would not function correctly. Such rigid assumptions make our code brittle. When the assumptions don’t hold, our code is likely to fail. It would be better if we could make our sizing choice ﬂexible to accommodate however many aircraft are in the air.

30. Another reason that the array of Flight types is a poor choice of core struc- ture arises from the dynamic nature of airborne aircraft. They tend to land, take oﬀ, exit the airspace, or enter it with relatively high frequency. Our core data structure will need to add and remove aircraft as they enter and exit the airspace. Adding or removing a data item from the middle of an array is easy enough to code, but it requires moving all the items that follow in the array over one spot, which amounts to a lot of data movement over time, which could slow down our app or put a higher load on our device’s battery.

31. The solution to these issues (the ﬁxed data structure size and the ineﬃcient delete of objects) is to use a dynamic data structure. 

32. Memory objects (e.g., variables) in C programs are allocated to one of three spots in memory: the run-time stack, the global data section, or the heap. Variables declared local to functions are allocated during execution onto the run-time stack by default. Global variables are allocated to the global data section and are accessible from all parts of a program. Dynamically allocated data objects are allocated onto the heap, and their allocation and deallocation are determined completely by the logic of our code.

33. At a high level, dynamic memory allocation works as follows: A memory allocator (which is a C system library function named malloc) manages an area of memory called the heap. During execution, a program can make a request to the memory allocator for blocks of memory of a particular size in bytes. The memory allocator locates a contiguous block of this size, reserves this block by marking it as allocated, and returns a pointer to this block. 

34. A block of memory that is allocated on the heap stays allocated until we decide to explicitly deallocate it by calling the memory deallocator (it works in  concert  with  the  allocator  and  is  also  a  C  system  library  function.  It’s named free). The deallocator adds the block back onto the heap for subsequent reallocation.

35. Figure 19.3 is a copy of Figure 12.7; it shows the relationship of the various regions of memory, including the heap. Notice that as blocks are allocated and deallocated, the heap grows and shrinks. The heap and the stack both grow toward each other. The size of the stack is based on the depth of the current function call, whereas the size of the heap is based on how much memory the memory allocator has reserved for the requests it has received.

36. Objects that are allocated in the heap stay “alive” until we, the programmer, explicitly deallocate them. This is unlike the stack, where objects are deallocated once the code blocks (e.g., functions) in which they are declared have exited. This additional programmer control is invaluable. It will enable us to create data structures that are persistent across multiple functions and across large spans of program execution.

37. Dynamically Sized Arrays: Dynamic allocation and deallocation are handled by the C standard library functions malloc and free. They both have simple interfaces—they each take one argument 

int numAircraft;
Flight *planes;
printf("Total number of aircraft?");
scanf("%d", &numAircraft);
planes = malloc(24 * numAircraft);

38. The  function  malloc allocates a contiguous region of memory on the heap of the size in bytes indicated by the single parameter. If the heap has enough unclaimed memory and the call is successful, malloc returns a pointer to the allocated region. Here we allocate a chunk of memory consisting of 24 * numAircraft bytes, where numAircraft is the number of aircraft in the air.

39. What about the 24? Recall that the type Flight is composed of six members— an array of seven characters, four integers, and a double, each occupying a single two-byte location on the LC-3. Each structure requires 24 bytes of memory on the LC-3. But this same structure on a Windows PC might require 31 bytes, due to the different sizes of integers, characters, and double types. As a necessary convenience for programmers, the C language supports a compile-time operator called sizeof. This operator returns the size, in bytes, of the memory object or type on the particular system being compiled for.

40. For example, sizeof(Flight) will return the number of bytes occupied by an object of type Flight on the particular device the code is being compiled for. In this way, we can create more portable code that works on different systems without having to modify it.

41. If all the memory on the heap has been allocated and the current allocation cannot be accomplished, malloc returns the value NULL. Recall that the symbol NULL is a preprocessor macro symbol that represents a null pointer. It is good programming practice to check that the return value from malloc indicates that the memory allocation was successful.

42. The function malloc returns a pointer, but of what type? In the preceding example, we are treating the pointer that is returned by malloc as a pointer to some variable of type Flight. In other places, we might want malloc to allocate an array of integers, characters, or of some other type. In other words, malloc needs to return a generic pointer of type void *. This generic pointer needs to be type cast to the appropriate type during assignment.

43. That is, whenever we call the memory allocator, we need to convert the void * pointer from malloc to the type of the pointer variable we are assigning it to. In the preceding example, we assigned the pointer to planes, which is of type Flight *; we therefore should cast the pointer to type Flight *. To do otherwise makes the code less portable, and most compilers generate a warning message because we are assigning a pointer value of one type to a pointer variable of another.

44. To type cast a value from one type to a newType, we use the following syntax. The variable var should be of newType.
var = (newType) expression;

45. Now that we’ve discussed type casting, the sizeof operation, and error checking of the return value from malloc, the correct way to write the code from the previous example is:

int numAircraft;
Flight *planes;

printf("Total number of aircraft?");
scanf("%d", &numAircraft);
planes = (Flight *) malloc(sizeof(Flight) * numAircraft);
if (planes == NULL) {
     printf("Error in malloc...\n");
     :
     :

46. Since the region that is allocated by malloc is contiguous in memory, we can switch between pointer notation and array notation. Now we can use the expression planes[29] to access the characteristics of the 30th aircraft (provided that numAircraft was larger than 30, of course). Notice that we smoothly switched from pointer notation to array notation; this is an example of the equivalence between array and pointer notation that we discussed earlier

47. What about deallocation? To deallocate memory and return it to the heap, we can use the function free. It takes as an argument a pointer to a block that was previously allocated by malloc and deallocates it. After a region has been free’d, it is once again eligible for allocation. 

48. The function malloc is only one of several memory allocation functions in the standard library. The function calloc allocates memory and initializes it to the value 0. The function realloc attempts to grow or shrink previously allocated regions of memory. To use the memory allocation functions of the C standard library, we need to include the stdlib.h header ﬁle.

49. We can use realloc to create an array that adapts to the data size. For exam- ple, the function AddMoreAircraft() could double the size of our core aircraft array if the current size of the planes were too small. Likewise, we could use ReduceAircraft() when the size of the array is larger than what is required. Both of these functions would call realloc to adjust the array’s size.

50. Dynamically sized arrays (or dynamic arrays) are allocated on the heap, which means that we can access them through- out our code and not just within a single function, which is the case with stack-allocated variable-sized arrays. Dynamic arrays can also grow and shrink, whereas variable-length arrays are of ﬁxed size throughout program execution. Even if we chose to use variable-length arrays for our aircraft tracker code, if the number of aircraft in our airspace surged, our code might not have enough space to track all aircraft.

51. Linked Lists: A linked list is a data structure that is similar to an array in that both can be used for data that is a sequential list of elements. In an array, each element (except the last) has a next element that follows it consecutively in memory. Likewise in a linked list, each element has a next element (except the last), but the elements need not be adjacent in memory. Rather, each element in a linked list contains a pointer to the next element, which enables the next element to be placed anywhere in relation. The pointer is used to reconstruct the sequential order.

52. A linked list is a collection of elements, or nodes, where each node is one “unit” of data, such as the Flight structure for tracking airborne aircraft, plus a pointer to the next node. Given a starting node, we can traverse the list from one node to another by following the pointers. 

53. The following code shows how this is accomplished in C. Here we have added a single new member element to the structure, the pointer Flight * next. As a side note, we rearranged this code slightly from the example in Figure 19.2 by moving the typedef to precede the structure deﬁnition. Why? This enables us to use the more convenient Flight * rather than struct ﬂightType * as the type for next.

1  // Structure definition
2  typedef struct flightType Flight; 
3  struct flightType {
4    char ID[7];         // Max 6 characters
5    int altitude;       // in meters
6    int longitude;      // in tenths of degrees
7    int latitude;       // in tenths of degrees
8    int heading;        // in tenths of degrees 
9    double airSpeed;    // in kilometers/hour
10   Flight *next;       // Pointer to next element
11 };

54. Like an array, a linked list has a beginning and an end. Its beginning, or head, is accessed using a pointer called the head pointer. The ﬁnal node in the list, or tail, points to the NULL value, which signiﬁes that no additional elements follow, similar to the way the NULL character indicates the end of a string. Figure 19.4 shows two representations of a linked list data structure: an abstract depiction where nodes are represented as blocks and pointers are represented by arrows, and a more physical representation that shows what the data structure might look like in memory. Nodes can appear anywhere, and it is the pointers that help re-create the linear order. Given a head pointer, we can access all elements in the list by traversing from one node to the next via the next pointer.

55. Despite their similarities, arrays and linked lists have fundamental diﬀer- ences. An array can be accessed in random order. We can access element number 4, followed by element 911, followed by 45, for example, by providing the index of the element we wish to access. A simple linked list must be traversed sequentially starting at its head; if we wanted to access node 29, then we would have to start at node 0 (the head node) and then go to node 1, then to node 2, and so forth. This sequential access may seem like a disadvantage, and it is! But there is a strong beneﬁt to linked lists

56. Linked lists are dynamic in nature; additional nodes can be added or deleted without movement of the other nodes. Existing nodes stay in place, with the new node added, or old node deleted, by rearranging the node-to-node links. Both add and delete are accomplished by rearranging pointers, and they don’t require copying or moving data. While it is straightforward to dynamically size an array, it is more costly to add or remove a single element in an array.

57. Support Functions: There are two basic functions we’ll develop in this example, AddFlight, which will add an aircraft to the linked list as it enters our airspace, and DeleteFlight to remove an aircraft. Our starting point will be the variable

Flight *airspace = NULL;

and it will replace the array we used in Figure 19.2. It is initially empty, as signiﬁed by its initialization to NULL.

58. Before we dive into the linked list itself, let’s build up the code surrounding the AddFlight and DeleteFlight functions. Figure 19.5 lists the C source code for the support functions for our linked list–based ﬂight tracker. The structure definition is just as we developed previously, with the addition of the Flight *next pointer to enable us to link nodes together.

59. The function CreateFlight takes as arguments the various properties of an aircraft to create a new node via malloc. The function then returns a pointer to this new node.

60. The function PrintAirspace prints all the aircraft in the airspace by travers- ing the linked list, which is provided as an input parameter. Notice that the while loop is the analog of the for loop we would typically use for traversing a ﬁxed-size array. Since we don’t know the number of nodes in the list, we use a while loop to keep traversing from node to node until we reach the NULL pointer. And instead of the i++ which is typical of a for loop, the iteration is accomplished by list = list ->next; 

61. The function main orchestrates everything, and it contains example calls to the functions AddFlight and DeleteFlight.

62. One note about the code in Figure 19.5 is that we needed to include two additional header ﬁles from the C standard library. The header ﬁle stdlib.h contains the deﬁnitions for the memory allocation functions that we’ll use, e.g., malloc and free. The header ﬁle string.h contains various string functions, including strcmp, which we’ll use in the functions to add and delete aircraft to and from our linked list.

63. Adding a Node to a Linked List: Since the linked list of aircraft will be maintained in sorted order by aircraft ID, there is a precise spot within the list where each new aircraft should be added. For example, if our list contains two aircraft, one with ID A, followed by one with ID C, then the new aircraft B will be inserted in between those two aircraft. The new list will be A, B, C.

64. The basic insertion algorithm is simple: the next pointer of A, which currently points to C, should be changed to point to the new aircraft B, and the next pointer of B should be changed to point to C. Only two values are modiﬁed in order to add the new node. Compare this to what is required to add a node to a sorted array!

65. We want to traverse the list, searching for the spot in the list at which to insert B. We’ll use a while loop, as we did for the PrintAirspace support function, to traverse the list. We’re searching for a node with an ID that is greater than B because that indicates we’ve found the spot at which to insert B. In this case, A is not greater than B, so we keep iterating. C is greater than B, and therefore we insert B just before C.

66. Note that because ID is represented as a character string, we’ll use the C standard string function strcmp, which compares two strings, stringX and stringY:

comp = strcmp(stringX, stringY);

It returns a 0 if both are equal, or a value <0ifstringX appears before stringY in alphabetical order, according to ASCII, or a value >0ifstringX appears after stringY.

67. To insert B prior to node C, we need to modify the next pointer of A, which is prior to node C. To accomplish this, we need to retain a “previous” pointer that points to the node prior to node C. In other words, the current pointer serves as our index through the linked list, and the previous pointer lags it by one node. The current pointer helps us locate the point of insertion, and the previous pointer assists in the insertion by providing a way to access the node whose next pointer needs to be modiﬁed.

68. The code provided in Figure 19.6 provides the basic structure, albeit incomplete, of our code. Notice that the while loop iterates through the nodes in the linked list using the pointer variable current. The pointer variable previous lags current by one node.

69. This code is incomplete. It doesn’t take into account some of the diﬀerent cases we will encounter during use. How does the preceding situation change if C doesn’t exist, or if A doesn’t exist, or if neither exists? Let’s walk through the permutations of A and C (and B) existing in the list prior to the insertion of B.

70. We’ve already covered the situation where both A and C are in the list in the code in Figure 19.6. Here B is inserted in between two existing nodes. We’ll call this the “Add to Middle” case. Let’s consider the other cases.

71. Empty List: What if neither A nor C exists prior to the insertion of B? Here we are adding B to an empty list. We want to change the value of the head pointer of the list (allAircraft in the function main), which currently points to NULL,to point instead to B. The next pointer of B will point to NULL. The list now contains a single aircraft, B.

72. Add at Tail: What if A exists, but C does not? In this case, we will be adding B to the end, or tail, of the list. The next pointer of A will be modiﬁed to point to B instead of NULL. B’s next pointer will be set to NULL.

73. Add at Head: What if C exists, but A does not? In this case, B will be inserted prior to C. This requires modifying the head pointer of the list (allAircraft in the function main), which currently points to C, to point to B instead. B’s next pointer will be set to point to C.

74. B Exists: What if A and C exist, but so does B? In this case, we will not insert a duplicate of B; instead we will signal that a special condition has occurred. Figure 19.7 provides another view of each of these ﬁve cases. We’ll have to ensure that our AddFlight code from Figure 19.6 handles all ﬁve of these situations. Some of these cases are rather easy to address, such as “B Exists”. “Add at Tail” is also rather simple. Here we exit the while loop without having added B. At this point, we know that B will be added to the tail, which requires modifying the previous node to point to B and having B point to NULL.

75. The other two cases, Add at Head and Empty List, are more problematic. They both require modifying the parameter list to point to a new node.

76. To address this issue, we’ll need to pass list by reference to AddFlight (see Section 16.2.3). That is, we’ll need to pass a pointer to it, instead of the value itself. We’ve seen how to do this for typical variables, but it gets a little confusing when dealing with pointer variables. In C, this parameter would be expressed as a pointer to a variable of type Flight *, or as expressed as code:

Flight **list;

77. It’s often distractingly diﬃcult to clearly think about what this actually means. The double asterisks can require some mental processing for most programmers to decode. It is helpful to keep in mind that the concept is just the same as if we were passing an integer variable by reference:

int *x;

78. And in order to modify the variable x, say by incrementing it, we can use the following notation:

*x = *x + 1;

79. Likewise, to modify a pointer variable passed by reference, we can use the following notation:

*list = *list->next;

80. We’ve provided the complete version of AddFlight in Figure 19.8. The places in the code where we handle each of the ﬁve diﬀerent cases are identiﬁed in the comments.

81. Deleting Node from a Linked List: The delete function requires an ID of the aircraft to be deleted. The corresponding node can exist somewhere within the list, at the head of the list, at the tail of the list, or it might not exist at all. As with our code to add an element to the list, our delete code needs to handle each of these cases.

82. We traverse the list looking for the node to delete. If found, the node previous to it is modiﬁed to point to the node following it. The node to delete is then deallocated using the free function. As with the add function, DeleteFlight returns a 0 if the delete proceeded successfully or a −1 if it didn’t.

83. When deleting a node from a linked list, we can encounter situations analogous to those we encountered when adding a node: Delete from Middle, Empty List, Delete from Tail, Delete from Head, and Doesn’t Exist.

84. Each of these situations is simple to code on top of the basic while loop structure. Some of these cases are similar to each other: Empty List and Doesn’t Exist are in eﬀect the same. Neither actually performs a delete, and each returns a −1 to signal an error. Also, Delete from Middle and Delete from Tail are the same due to the type similarity between a NULL pointer and a pointer to a real node. The Delete from Head case requires that we modify the parameter list in order to assign a new head node after the delete operation. Figure 19.9 provides the complete source code for DeleteFlight.

85. Arrays vs. Linked Lists: We can now replace our core array data structure in our ﬂight tracker app with the more dynamic linked list. Throughout this chapter, we’ve discussed some of the advantages in doing so. But as with many things in computing, there are tradeoﬀs involved: linked lists provide some advantages over arrays, but they also have some disadvantages. Wisely choosing which method of data organization to use in a particular situation requires consideration of these tradeoﬀs (and also a deeper sense of how these structures are implemented at the lower level).

86. Let’s ﬁrst examine the impact to memory space. Arrays are quite memory eﬃcient. If we create an array of 1000 integers, we will be allocated 1000 inte- gers’ worth of memory space. Additional storage is not required. If the array is dynamically allocated on the heap, there is likely some additional overhead to keep track of the block of memory, but that is small in relation to the actual array. Linked lists, in contrast, require a pointer per node to link to the next node. Also, since the nodes are individually allocated on the heap, each node will incur addi- tional dynamic allocation overhead. If the node size is small, then this overhead can be a signiﬁcant fraction of overall data structure size. While arrays are eﬃcient in terms of allocation, they suﬀer in our inability to precisely size them to our needs. We often need to declare strings that are long enough to hold the longest string we expect to encounter, which is larger than necessary for the typical case.

87. Now, what if we wanted to add an element, or delete an element, or search the structure for a particular element? These are primitive operations that we may want to perform on any list of data. For adding and deleting elements, which we’ve examined when developing our ﬂight tracker app, a linked list oﬀers the ability to dynamically add and remove nodes by rearranging links. And because the data structure need not be contiguous in memory, we can dynamically allocate nodes to ﬁt the actual run-time needs of the application. With arrays, adding an element requires that enough space exists for it in the array; if there is enough space, existing elements must then be moved around to create a spot for the new data. Likewise, when deleting an element from an array, we need to ﬁll the vacated spot by moving data elements in order to keep data contiguous. As for searching, linked lists require sequential traversal, whereas with an array, we can use binary search which is a highly eﬃcient algorithm for searching a sorted list.

88. These diﬀerences arise because we’ve improved the add and delete operations at the expense of random access. Array elements can be randomly accessed, whereas nodes in a linked list require sequential traversal. This in turn aﬀects our ability to do eﬃcient search.

89. Arrays and linked lists form the opposite ends of a spectrum of data structure choices. There is a near continuum of variations created by inventive programmers and computer scientists to ﬁt particular situations, each of which provides some advantages of one end of the spectrum without the disadvantages of the other. A subsequent course in data structures and algorithmic analysis will provide deeper exposure to the data structure zoo.
