what should you know about fundamentals? they do not change very often

what will mastery of the fundamentals yield? there is no limit to how high I will soar provided I continue to put in the
work 

what is this book about? mastering the fundamentals of computing

what is the conventional wisdom when it comes to teaching computer science? start  with a high level programming language
which leads to the memorisation of technical details without an understanding of basic underpinnings

how does the book approach mastering computing fundamentals? a bottom up approach where it continually builds on what is 
covered (scaffolding)

what is technique is widely pervasive when it comes to teaching students any subject? information hiding approach

why is it used? because it is a useful productivity enhancer and allows the student to hit the ground running

what are its drawbacks? information hiding gets in the way of understanding which leads to problems when students have to
think from first principles about for example why a particular error is happening (understanding not memorising)

information hiding is only useful once one has an understanding of the fundamentals. bottom up approach is best for learning
in order to acquire an understanding

does that mean that the top down design approach is flawed?

what was their  concern about including C++ in their instructional approach? many of the languages features are too far 
abstracted from the underlying layers to make for an easy fit to their instructional approach. Additionally C++ is a vast 
language that would have necessiated more pages to be added to the book. 

why do they still use C in the book? serves as the defacto development language for systems aand hardware oriented projects

what are the two major segments that the book can be broken down into? (a) the underlying structure of a computer (b) programming
in a high level language

why does the C programming language fit very nicely with the bottom up approach? its low level nature allows students to see
clearly the connection between software and the underlying hardware 

why lc-3 ISA and not ARM or RISCV? because commercial ISAs have no place in an introductory course but still have to be
understood in order to be used effectively. They wanted an ISA that was clean with no special cases to deal with, with as few
opcodes as necessary so that you the student spends all your time on the fundamental concepts of the course and very little 
time on the nuaances of the instruction set

the lc-3 instruction set with only 15 four-bit opcodes, is small enough that the students can absorb the ISA without struggling
too much

what are the stand out observations of the approach taken in the book?

(a) understanding and not memorising: bottom up learning approach leads to less memorisation of seemingly arbitrary rules
which is prevalent in traditional programming courses. by the time a topic is taught, you will have an understanding of how
the topic is implemented at the levels below it. this approach is good for design courses where understanding of and insights
gained from fundamentals are essential to making the required design trade offs.
(b) you get to debug your own programs
(c) preparation for the future: cutting through protective layers; as a professional, if you are ignorant of what is going
on inside computers you will likely discover the hard way that the effectiveness of your solutions is impacted adversely by
things other than the actual programs you write. serious programmers will write more efficient code if they understand what
is going on beyond the statements in their high level language. high level programming language courses where the compiler 
protects the student from everything ugly underneath does not serve most engineering students well
(d) rippling effects through the curriculum: the material taught in the book has a rippling effect on what can be taught in 
subsequent courses. subsequent programming courses cannot only assume the students know the syntax of C/C++ but also understand
how it relates to the underlying architecture. ergo, the focus can be on problem solving and more sophisticated data structures

how to install the simulator debugger written by the authors for the lc-3 ISA:

download link for the material can be found here: https://highered.mheducation.com/sites/1260150534/student_view0/lc-3_simulator.html

LC3Tools is a cross-platform set of tools to build code for and simulate the LC-3 system described in the book.

The latest version of LC3Tools for all platforms can be found at https://github.com/chiragsakhuja/lc3tools/releases

Windows Users: lc3tools-setup-VERSION.exe
macOS Users: LC3Tools-VERSION.dmg
Linux Users: lc3tools-VERSION-x86_64.AppImage

There are several other resources, including more documentation and instructions on the command line tools, at https://github.com/chiragsakhuja/lc3tools.git 

chapter 1

1. what is the intent of the book? there is no magic to computing as computers are deterministic systems; computers are not 
electronic geniues infact they are electronic idiots that do exactly as they are told 

2. a computer is a complex system made up of? systematically interconnected collection of very simple parts; it is
these simple parts that the book will introduce, explain and tie together to show how they make up a computer

3. what is the main goal of the book? by the time you are finished, you will be able to write programs using a language like C 
and be able to understand what is going on underneath the computer

4. how will we get there? you will see that all information processed by computers is in the form of 0's and 1's. therefors, all 
information processed by computers is therefore encoded as 0's and 1's. you will learn how to process such information

5. what is meant by all information processed by computers is encoded in 0's and 1's? each piece of information has a code point made up
of 1's and 0's

6. what is the lc-3? it is a microprocessor that has all the important characteristics of real microprocessors without being so complicated
that it gets in the way of my understanding. so it is a piece of hardware excet that it doesn't exist hence when you write code in assembly
language or machine language for the lc3 processor, you will need a simulator to see what would happen in the registers and memoy of a 
real lc3 during the execution of a program. all that exists is the ISA and microarchitecture which would implement the ISA

7. what do high level languages enable programmers to do? effectively develop complex sofware by abstracting away the details of the 
underlying hardware

8. what are the two recurring themes in the book? abstraction and not separating hardware and software layers of a computer

9. define abstraction? technique of establishing a simpler way to interact with a system

10. what is the premise that allows us to use abstraction effectively? allows not getting bogged down in the details of a system when 
everything is working fine; establishes a simpler way for a person to interect with a system

11. why is abstraction favoured? it is a productivity enhancer as i can deal with a situation at a higher level focusing on the essential
apects whilst keeping component ideas in the background

12. when the detail is not working fine, what must you be able to do? unabstract i.e. go from the abstraction back to its component parts

13. what are modern processors comprised of? transistors

14. what do transistors combine to form? logic gates 

15. what do opportunity do logic gates provide? the ability to think in 1's and 0's instead of varying voltages across the transistor 
wires

16. what does a combination of logic gates produce? a logic circuit - a further abstraction

17. what putting together logic circuits, should a designer be thinking of the internals of each individual gate or treat each gate as A
component? treat each gate as a component as thinking of the internals of each gate would slow down the process of designing the logic
circuit

18. how can the above thinking be applied to the design of an application program? each component should be thought of as an abstraction
(thinking about the internals of each component would be detrimental to progress)

19. why should you be careful about letting abstractions be the deepest level of my understanding? because you will be at the mercy of the 
component parts working together; if one of them breaks then you won't be able to intervene to get the system up and running again

20. how will the material in the book be presented in terms of abstraction? the level of abstraction will be continually raised i.e. from
individual transistors to gates to logic circuits to even larger abstractions

21. what should you keep in mind during your study and practice of computing? hardware and software are component parts of a computing 
system that work best when they are designed by people who take into account the capabilities and limitations of both

22. what allows engineers to be able to work on computing systems whilst ignoring the other side i.e. software people ignoring the hardware
it runs on, and hardware people ignoring the software that will run on it? abstraction

23. why is being clueless about the underlying layers not advisable? because you will not be able to take advantage of the nuances of 
underlying layers when it is important to be able to do so

24. what do the authors suggest about the your study and practice of computing? 

12. definition of a computer? system consisting of software that directs and specifies the processing of information and the hardware that 
performs the actual processing of information in response to what the software specifies

13. what piece of hardware actually does the processing in a computer? CPU

14. when did the first computers show their face on planet earth? 1940s

15. what was the name of the first computer? ENIAC

16. what is marked about the computing devices of today and those of yesteryear? the weights have decreased tremendously, so has the power 
consumption. the computing power has increased by many orders of magnitude

17. what has brought about this increase in computational power? integrated circuit packages have seen phenomenal improvement e.g first 
intel microprocessor (intel 4004) contained 2300 transistors and operated at 106 KHz; one of the latest intel microprocessors Core 
i9-13900K contains a reported 25.9 billion transistors and and can operate at a frequency of 5.8 GHz

18. what does this mean? that a computer running on on intels latest CPU today can do many more things in the time it took the first intel 
pc to do one thing 

19. what does this mean? we have computers today that seem able to understand languages people speak, recognise peoples faces which many
seeas the magin of artificial intelligence. however, these feats are only possible because the electronic idiots are able to run simple 
operations blazingly fast concurrently 

20. what two ideas are at the core of computing? all computers (fastest, slowest, cheapest, most expensive) are capable of computing 
exactly the same things if they are given enough time and memory and problems are expressed in human language but are solved by electrons 
moving due to voltage potentials inside the computer. this means a series of systematic transformations have to be made from a problem 
expressed in a human language in order for the electrons to do our bidding inside a computer

21. what has happened to these sequence of transformations over the last 70 years? they have been developed, refined and improved 

22. how do analogue machines work? produce an answer by measuring some physical quantity such as distance or voltage

23. why are analogue machines difficult to work with? it is very hard to increase their accuracy 

24. why did digital machines come to dominate computing? it is easy to increase their accuracy

25. definition of a digital machine? machines that perform computations by manipulating a fixed finite set of digits or letters 

26. what limitations did digital machines of yesteryear have? the mechanical or electro-mechanical devices could only perform a specific 
type of computation

27. how are digital computers different from machines of yesteryear? when you think of a new computation, you do not have to buy or design 
a new computer, you just give the same computer a new set of instructions to carry out the new computation

28. why do we call digital computers universal computational devices? because of the point made above

29. what does the study of computing involve? study the fundamentals of all computing along with learning what computation is and what can 
be computed

30. who is attributed with the idea of a universal computation device?

31. what did alan turing propose? that all computations could be carried out by a particular kind of machine - a turing machine

32. what do computers and turing machines have in common? they are programmable

33. what implication does the answer to question 32 have? big or expensive computers cannot do anything that a small cheap computer can't
more money will buy you an faster computer but if you have a small inexpensive laptop then you already have a universal computation device

34. how do we get the electrons to do our bidding inside of a computer? work through the levels of transformation for a particular problem

35. what is the first level of transformation? describe a problem in a natural language whilst avoiding ambiguity because the electronic 
idiot would not know what to do

36. what is the second level of transformation? convert the problem expressed in natural language into an algorithm thereby getting rid of 
the ambiguity inherent in natural language

37. what are the three characteristics of an algorithm?

38. what is the 3rd level of transformation? transform the algorithm into source code using a chosen programming language

39. what are the two kinds of programming language that exist? high level and low level

40. provide a definition for a high level language? independent of the computer from which they will execute on i.e. they are machine 
independent

41. provide a definition for a low level langauge? tied to the computer on which the programs will execute i.e. assembly language

42. what is the fourth level of transformation? translating the source code into the ISA of the computer that will be used to
execute the program.

43. what does ISA specify? the interface between the source code and the hardware of the machine that will be used to execute the program

44. using the automobile and driver analogy, what is represents the source code, the ISA and the hardware?

45. what do opcode and operand mean? operand is the data value

46. ISA specifies the acceptable representations for operands, what are the operands called? 

47. ISA specifies the mechanisms that the computer can use to figure out where operands are located. what are these mechanisms called? 

48. are the number of opcodes, operands and addressing modes unique to each ISA?

49. what else does ISA specify (apart from opcodes, operands, and addressing modes)? number of unique locations that comprise the computers 
memory (address space) and the number of bits contained in each location (addressability)

50. name a few ISAs in use today? x86 by intel (currently also developed by AMD an other companies), SPARC oracle, power (IBM), arm and 
thumb (ARM)

51. what is the name of the program that is used to translate source code into the ISA of the machine that will be responsible for 
executing it? 

52. what is the name of the program that translates assembly languaage of a computer to its ISA? assembler

53. what is the 5th level of transformation? micro-architecture i.e. using the automobile analagy from earlier, it refers to what goes on 
under the hood of a car this micro-architecture is dependent on the performance, cost and energy trade offs made by designers 

54. what is the 6th level of transformation? logic circuits i.e. the micro-architecture is implemented out of simple logic circuits

55. what is 7th level of transformation? logic circuits can be implemented different device technologies e.g. CMOS circuits, 
NMOS circuits or gallium arsenide circuits


chapter 2

1. what do you call the tiny little devices inside computer that control the movement of electrons by reacting to the presence or absence 
of voltages?

2. could these tiny devices be designed to detect actual value of voltages instead of the presence or absence of them?

3. why is this not done? it would make the control and detection circuits more complex than they need to be

4. do these tiny devices actually detect the absence of a voltage i.e. 0 and the presence of a voltage?

5. how do we symbollicaly represent the presence of a voltage?

6. how do we symbollically represent the absence of a voltage?

7. how many things can we differentiate with one wire and what values are assigned to them?

8. in order to get useful work done by a computer, it is necessary to be able to distinguish a large number of distinct values and assign 
each of them a unique representation. what is done in order to achieve this?

9. what is the word "bit" a short hand of? 

10. what qualifies a representation as a data type? if there are operations in the computer that can operate on information encoded in that 
representation

11. describe the unsigned integer representation?

12. describe the signed integer number representation (how many bits are assigned to positive numbers and how many bits to negative 
numbers)?

13. define signed magnitude representation of data? if a leading 0 signifies a positive integer then a leading 1 signifies a negative 
integer

14. define the 1s complement representation of data? a negative number is represented by taking the representation of the positive number
that has the same magnitude and flipping all the bits

15. can a computer designer assign any bit pattern he wants to represent any integer he wants?

16. why would this not be a good idea? it would complicate matters when they try to build electronic circuits capable of adding the numbers

17. define 2's complement integer representation?

18. almost all computers use the same mechanism to perform addition, what is it called?

19. if you know the bit representation of integer A, what is a short cut you can use to work out -A? 

20. how many floating point data types do most ISAs specify?

21. how many bits does the float data type use?

22. how are the bits allocated?

23. what is the equation of the normalised form of float numbers? 

24. what is special about the 8 bit exponent? for normalised numbers it must be restricted to 254 unsigned values i.e. between 1 (00000001) 
and 254 (11111110) for the two remaining values 0 and 255, the data type does not represent normalised numbers

25. if the exponent field contains 255 (11111111), what number is represented by the floating point data type?

26. what is the smallest number that can be represented in normalised form?

27. what are subnormal numbers?

28. what equation is used to represent subnormal numbers?

29. wht are ASCII codes used for? transferring characters between main computer processing unit and the input and output devices

30. define encoding? converting data into a format that is required for processing including transmission, storage and retrieval


chapter 3

1. what are most semiconductors used in processors today manufactured from? 

2. what are the two type of MOS transistors? 

3. how do n type transistors work? when the gate is supplied with 1.2v, the transistor acts like a piece of wire; when supplied
with 0 volts it acts like an open wire

4. what of the p type transistor?

5. name the 5 types of logic gates that can be constructed from n type and p type transistors?

6. what did you notice about the configuration of both transistors when they are used to construct logic gates? the n type is always 
connected to ground; the ptype is never connected to ground

7. what happens when you connect a p type transistor to 1.2 volts or an n type to the ground? there is no voltage across the transistors

8. what happens when you connect a p type transistor to the ground and an n type transistor to 1.2 volts? because of 
the electrical characteristics of the transistors, we get what is usually referred to as a transmission voltage of 
approximately 0.5 volts across the transistor. 

9. there are two types of logic structures, what are they called and what do? those that include storage of information and those that do 
not. those that do not store information are called decision elements or combinational logic structures. those that store information and 
make decisions as well are called sequential logic circuits

10. name three decision elements? decoder, mux (multiplexer), full adder 

11. how does the decoder work? only one of its output value is asserted (i.e. has a value of 1) that corresponds to the input pattern that 
it is expected to detect. it basically interprets a bit pattern

12. what logic gates is the decoder made of? NAND and AND gates

13. how does the mux work? the select signal selects one of the inputs (the source) and connects it to the output   

14. what gates is the mux constructed out of? NAND, AND and OR gates

15. how does the full adder work? it adds two binary numbers 

16. what logic gates is the one bit adder made up of? NAND, AND, and OR gates

17. if you wish to implement a logic circuit for adding two 16 bit numbers, how many one bit adders will you require? 16 one bit adders

18. what is the name of the building block that is used to implement any collection of logic functions? 

19. what logic gates is the PLA made up of? collection of AND gates (called AND arrays) followed by an array of OR gates

20. what does the number of OR gates correspond to in the PLA? the number of logic functions that we wish to implement i.e. the number of 
output columns in the truth table

21. name 2 logic structures that do include storage information? R-S latch and gated D latch

22. how does the R-S latch work? stores 1 bit of information, a 0 or a 1. can be implemented in many ways; inputs S and R are normally held 
at a logic level 1.

23. what is meant when we state that the R-S latch is in a quiescent state? when the latch is storing a bit and nothing is trying to change 
that value

24. what contributes to this quiescent state? the fact that both R and S are held at a logic level of 1

25. in order for the R-S latch to work properly, what must be done to R and S? must never be set to 0 at the same time

26. how can you set the latch to a 1 or a 0? you an set the latch to a 1 by temporarily setting s to 0 and having R remain at logic level 
1; the latch can be set to 0 by temporarily setting R to 0 and having S remain at logic level 1

27 what happens if both S and R are set to 0 at the same time? outputs a and b would both be 1 and the final state of the latch would 
depend on the electrical properties of the transistors making up the gates

28. what logic gates make up he R-S latch? NAND gates

29. how does a gated d latch work? controls when the R-S latch is set to the value of D when write enable is asserted. in this case exactly 
one of the outputs S and radio is set to 0 depending on the value of D

30. what happens when WE is not asserted? the outputs of S and R are both equal to a 1

31. what do we call the unique identiﬁer associated with each memory location?

32. what name do we give to the number of bits of information stored in each location?

33. what do we call the total number of uniquely identiﬁable memory locations?

34. what do we mean by stating that a computing device has a 2GB memory? colloquially we say the computing device has 2 billion memory 
locations, however, the address space is actually 1024x1024x1024x2 which yields 2,147,483,648 locations

35. why 1024? because 1024 bytes make a kb and 1024 kb make a mb and 1024 mb make a GB

36. why are most memories byte-adddressable? most computers got their start processing data where one character on the keyboard corresponds 
to one 8-bit ASCII code

37. summarise how sequential logic circuits operate? they base their decisions on the input values present but also on what has happened 
before; they  contain storage elements that allow them to keep track of prior history information

38. what machines are sequential logic circuits used to implement? 

39. can you give two examples; one for a combination decision element and the other for a sequential logic element?

40. define what is meant by the state of a mechanism/system? snapshot of a system with all relevant items explicitly expressed.

41. how many elements does a finite state machine consist of?

42. can you state all 5? a finite number of states, a finite number of external inputs, a finite number of external outputs, 
an explicit specification of all state transitions, an explicit specification of what determines each external output value

43. what is a characteristic of asynchronous machines? there is nothing that synchronises when each state transition occurs

44. are computers synchronous or aynchronous systems? synchronous because state transitions take place one after another at identical fixed 
units of time

45. what is the common characteristic of synchronous and asynchronous finite state machines? they carry out work, one state transition at 
a time, moving closer to a goal

46. what controls the synchronous behaviour of finite state machines? a clock circuit which produces a signal whose value alternates 
between 0 volts and 1 volt

47. what is a clock cycle? an identical interval that is repeated in the value of the clock signal as a function of time. it starts when 
the clock signal transitions from 0 to 1 and ends the next time the clock signal transitions from 0 to 1

48. what is meant by a laptop running at a frequency of 2GHz? it can perform 2 billion pieces of work each second since 2 GHz means 2 
billion clock cycles each second the synchronous finite state machine makes one state transition each cycle

49. what does a state diagram show? all of the 5 characteristics of finite state system

50 what is the problem with gated D latches as storage elements? when WE is asserted (i.e. the clock signal value is 1), the value of the 
storage elements would immediately change which in turn would trigger new inputs to the logic gates they are connected to. This cycle would 
repeat thereby making it impossible to for the current state to remain unchanged

51. how do flip flops work? they are storage elements that allow the reading of the current state throughout the current clock cycle and 
not write the next state into the storage elements until the beginning of the next clock cycle. reading must be allowed throughout the 
current clock cycle and writing must occur at the end of the clock cycle

52. what is a flip flop made of? two gated D latches in a master/slave relationship

53. how do flip flops work when used as storage elements? at the start of each clock cycle, the output of the storage elements i.e. the 
slave latch are input to the logic gates which produce the next state for the storage elements. in the timing diagram, there is a 
propagation delay as the combinational logic takes place to achieve this. despite the next state values being produced
sometime during half cycle A, the WE signal (i.e. the clock) to the master latches is 0 hence the next state cannot be written. at the 
start of half cycle b, the WE to the slave latches becomes 0 which means the clock signal for the mster latches is 1 - hence the master 
latches can be written. however, since the WE signal for the slave latches is 0, they cannot yet write the new information stored in the 
master latches. at the start of the next clock cycle, the WE signal to the slave latches becomes 1 and hence they can now be written into 
by the master latches thereby storing the next state that was created using combinational logic in the previous clock cycle. this becomes 
the current state of the next clock cycle. this process is repeated as long as the switch is on and the clock signal value alternates 
between 1v and 0v

54. what does the data path of a computer consist of? all of the logic structures that combine to process information in the core of the 
computer

55. what is a register made of? flip flops i.e. gated D latches where one bit of information can be stored in one flip flop hence a 16 bit 
register is composed of 16 flip flops

56. can a register be any size you need?

chapter 4

1. what two things do you need to get a task done by a computer? a computer that will do the work and a computer program specifying the 
task that needs to be achieved

2. what is the name of the smallest piece of work specified in a computer program? an instruction

3. who proposed the fundamental model of computers?

4. what are the basic components of the model? 

5. in which of the components is the computer program contained in?

6. which of the components can hold the data that the program will operate on?

7. which component controls the order in which operations are carried out?

8. what does the 16GB when talking about memory refer to? the "16 giga" refers to the 2^(34) memory locations and the "byte" refers to the 
eight bits stored in each location the term is 16 giga because 16 is 2^(4) and giga is the term used to represent 2^(30) which is 
approximately one billion, 2^(4) x 2^(30) = 2^(34)

9. if you have k bits, how many unique items can you represent?

10. ergo, to uniquely identify 2^(34) memory locations, how many bits do you need? 

11. to read the contents of a memory location, where do we place the address of that location in memory? in the memory address register

12. where will the information stored in the address stored in MAR be placed? in the MDR register

13. what is the process of writing or storing a value in a memory location? location of the address to be written to is first stored in 
MAR and the data stored to be written is stored in the MDR register. computer memory is then interrogated using with the WE signal asserted 
such that the information stored in MDR is writtent to the address stored in MAR

14. what are the two characteristics of a memory location? its address and what is stored there

15. what component carries out the processing of information in a computer? 

16. what is processing unit in a computer comprised of? many sophisticated functional units each performing one particular operation 
(divide, square root etc) 
17. what is the name of simplest processing unit and the one thought of when discussing the von neumann model? ALU which is capable of 
performing basic arithmetic functions and basic logic operations 

18. what is the name given to the fixed size elements that the ALU processes?

19. what specifies the word length (depends on the intended use of the computer) of a computer? the ISA

20. what word length is specified by most ISAs today? 64 bits and 32 bits (though 32 bits is slowly being demised)

21. what range of word lengths can you expect to find being processed in inexpensive processors today? 8 bits to 16 bits

22. what is the name given to the most common form of storage used to temporarily cache results (e.g. close to the ALU) that will need to 
be accessed in the near future?

23. typically what is the size of a register equal to? values being processed by the ALU i.e. a word or any other processing unit 

24. what is the result of the importance of temporary storage for values that most modern computers will need shortly? many processors have 
access to an additional set of special purpose registers consisting of 128 bits to handle special needs

25. what component is used to keep track of both where we are within the process of executing a program and where we are in the process of 
executing an instruction?

26. what mechanism does the control unit use to keep track of which instruction is being executed? instruction register contains the 
instruction being executed

27. what mechanism does the control unit use to keep track of which instruction is to be executed next? program counter/(instruction pointer) 
contains the next instructions address

28. what is the keyboard data register (KBDR) used for? used for holding of ASCII codes of keys that have been struck

29. what is the keyboard status register (KBSR) used for? used to maintain status information about keys struck

30. what is the display data register (DDR) used for? for holding ASCII code of information to be displayed on a screen

31. what is the display status register (DSR) used for? for maintaining associated status of data displayed 

32. what does the control unit do? it comprises of all the structures needed to manage the processing that is carried out by the computer

33. what is the most important structure of the control unit? the finite state machine which directs all processing activity clock cycle by 
clock cycle

34. what is the central idea in the von neumann model of computer processing? program and data are both stored as sequences of bits in the 
computer's memory and the program is executed one instruction at a time under the direction of the control unit

35. what is the most basic unit of computer processing? an instruction

36. what is an instruction made up of? opcode (what the instruction does) and operand (what is does it to)

37. there are 3 types of opcodes (instructions), what are they? operates, data movement, and control

38. what do operate opcodes do? operate on data

39. what do data movement opcodes do? move data from processing unit to and from memory and to and from input/output devices

40. what do control opcodes do? they alter the sequential processing of instructions

41. for LC-3, which has 16 bits, and are numbered right to left from 0 to 15, how are they divided? bits 15:12 contain the opcode and bits 
11:0 are used to figure out where the operands are

42. how many opcodes does the LC-3 have? 15 opcodes; one is reserved for future use

43. how many operands does the ADD operate instruction have? 3 operands, two source operands the numbers to be added and one destination 
operand (where the sum is to be stored)

44. what does the ADD operate require? at least one of the two source operands must be stored in one of the 8 registers; the result should 
also be dumped in one of the 8 registers

45. since the LC-3 has 8 registers, how many bits are necessry to identify each register? 3

46. what is the four bit opcode (from 15:12) for the ADD operate in LC-3? 0001

47. in the ADD opcode, what do bits 11:9 specify? the register for storing the result 

48 in the ADD opcode, what do bits 8:6 specify? the register storing one of the two source operands

49. how many formats does the ADD instruction have? two

50. what is the difference between the two formats of the ADD instruction? the 1 or 0 stored in bit 5 and what they each mean

51. what does the 0 stored in bit 5 mean? that the second source operand is in the register specified by bits 2:0

52. what does the 1 stored in bit 5 mean? the second source operand is formed by sign-extending the integer in bits [4:0] to 16 bits.

53. what is the four bit opcode (from 15:12) for the AND operate in LC-3? 0101

54. what is the four bit opcode (from 15:12) for the LD operate in LC-3? 0010

55. what is load instruction used for? goes to a particular memory location, reads the value that is stored there and stores that value in 
one of the registers

56. how many operands does the load instruction require? two operands; are the value to be read from memory and the destination register 
that will contain that value after the instruction has completed processing

57. what is addressing mode? formulas that are used to calculate the address of the memory location to be read

58. what do bits 11:9 in the LD instruction represent? identifies the register that will contain the value read from memory after the 
instruction is executed. 

59. what do bits 8:0 in the LD instruction represent? used to calculate the address of the location to be read. 

60. what addressing mode is used by the load instruction? PC+offset where the address specified in bits 8:0 is sign extended to 16 bits 
and then added to the contents of the PC

61. what system is used to control instruction processing? the program counter

62. what is the entire sequence of steps needed to process an instruction called? instruction cycle

63. how many steps does the instruction cycle consist of? 6 sequential phases, each phase consisting of zero or more steps  

64. name the six phases of the instruction life cycle? fetch, decode, evaluate address, fetch operands, execute, store result

65. what does the fetch stage involve? fetches the next instruction from memory and loads it in the IR of the control unit

66. elaborate more on this fetch phase i.e. how it works from end to end? program made up of instructions; instructions comprised of bits
stored in memory per von neumann model; PC or instruction pointer contains address of next instruction to be executed; this address (in the 
PC) is loaded into the MAR (1); once in the MAR, the address is interrogated resulting in the instruction being loaded from the memory into 
the MDR (2); finally the IR is loaded with the instruction from the MDR (3)

67. what other task is accomplished in the fetch phase? incrementing of the PC/IP to point to the next instruction in memory; this
is done after the MAR has been loaded with the contents of the PC/IP

68. how many clock cycles does each of the 3 steps in the fetch cycle take? step 1 takes one clock cycle; step 2 takes one or many clock
cycles depending on how long it takes to access a computers memory; step 3 takes one clock cycle

69. in a modern digital computer, how long is a clock cycle? a very small fraction of a second

70. what does the decode phase of the instruction life cycle do? examines an instruction to figure out what the micro architecture is being
asked to do

71. how does the decode phase work? a decoder is used to identify which of the 16 opcodes is to be processed with the input being bits
15:12

72. what occurs in the evaluate address phase? CPU computes the address of the memory location that is needed to process the instruction; 
not all instructions access memory to load or store data

73. what occurs in the fetch operands phase? obtains the source operands needed to process the instruction

74. what is notable about the store result phase? in many computers, for some instructions such as ADD, the fetching of source operands,
performing the ADD in the ALU, and storing the result in the destination register happens all in a single clock cycle hence a separate 
store result phase is not needed

75. so far you have come across 2 types of instructions; operate (ADD, AND) and data movement (LOAD), what is the 3rd type of 
instruction called? control instruction

76. what do control instructions do? they change the sequence of instruction execution

77. if you want to change the sequence of instructions executed, what must be changed? the contents of the PC must change between the time
it is incremented (during the FETCH phase of one instruction) and the start of the FETCH phase of the next instruction

78. at which stage do the control instructions load the PC? execute

79. what is the most common control instruction? conditional branching

80. what is the 4 bit pattern that specifies conditional branching? 0000

81. what do bits 11:9 represent in the BR instruction? the condition to be tested

82. what do bits 8:0 contain in the BR instruction? the addressing mode bits that are used to form the address to be loaded into the PC if
the result of the previous instruction agrees with the test specified by bits 11:9.

83. what is the instruction cycle controlled by? a synchronous finite state machine

84. in the state diagram of the instruction cycle, how many clock cycles are used in the FETCH phase? 3

85. what happens in each of the 3 clock cycles of the FETCH phase? MAR <- PC and PC <- PC + 1; MDR <- MAR; IR <- MDR

86. when are registers loaded? at the end of a clock cycle if the corresponding control signal is asserted

87. in order for the contents of the PC to be loaded into the MAR, what must be asserted by the finite state machine? GatePC and LD.MAR

88. in order for the instruction to be loaded from MDR to the IR, what must the finite state machine assert? LD.IR and GateMDR

89. how many clock cycles does the DECODE phase (the 4th state) take? 1

90. what happens in this fourth state? the external input IR, in particular the opcode bits of the instruction 15:12, are read by the 
finite state machine to go to the appropriate next state for processing

91. what do we call instructions that change the flow of instruction processing? control instructions

92. what happens at the end of the conditional branch instruction? the PC contains one of two addresses; either the incremented PC that 
was loaded in state 1 or the new address computed from sign extending bits 8:0 of the BR instruction and adding it to the PC

93. what determines which address gets loaded into the PC? the test of the most recent result determined by testing against bit 11:9 of the
BR instruction

94. what controls the execution of a user program in a computer? the OS

95. are OS computer programs?

96. what can we do if we want to stop the infinite sequence of instruction cycles? stopping the clock which controls the transition from
state cycle to a different state cycle

97. how can this be achieved? setting the run latch of the clock circuit to 0 which makes the output of the clock circuit 0

98. how do machines set this run latch to 0? in some older machines, the HALT instruction is executed; in the LC-3 the TRAP instruction
(with opcode 1111 and an eight bit code called a trap vector x25) informs the OS that a program has finished executing and ergo the 
PC can stop executing instructions

99. What is misleading about the name program counter? The program counter does not maintain a count of any sort. 

100. Why is the name instruction pointer more insightful? The value stored in the program counter is the address of the next instruction 
to be processed. Hence the name ’Instruction Pointer’is more appropriate for it.

101. If a HALT instruction can clear the RUN latch, thereby stopping the instruction cycle, what instruction is needed to set the RUN 
latch, thereby reinitiating the instruction cycle? Once the RUN latch is cleared, the clock stops, so no instructions can be processed. 
Thus, no instruction can be used to set the RUN latch. In order to re-initiate the instruction cycle, an external input must be applied. 
This can be in the form of an interrupt signal or a front panel switch, for example.

chapter 5

1. what does the ISA specify? all the information about the computer that the sofware has to be aware of i.e. specifies everything in the 
computer that is available to a programmer when they write programs in the computer's own machine language.

2. what 3 things does ISA specify? memory organisation, register set, and instruction set

3. why do computers such as the LC-3 have/use registers? it takes more than one clock cycle to access an address in memory.
registers can be accessed in one clock cycle 

4. what do you call the number of bits stored in a register? a word

5. what is an instruction made up of? opcode (what the instruction is asking the computer to do)
and its operands (what the computer is expected to do it to)

6. what does the memory organisation specified by an ISA entail? address space (quantity of memory locations) and addressability (amount of 
bits in each memory location)

7. what does the register set specified by an ISA entail? these are temporary locations used to store data that a computer will need shortly.
these locations can be accessed quicker than memory (usually by a single clock cycle). each register is referred to as GPR. the number of
bits stored in each GPR is referred to as a word. also called a register file

8. what does the instruction set specified by an ISA entail? comprises of a set of opcodes, data types, and addressing modes.

7. what do addressing modes determine? where operands are located

8. what is a data type? a representation of an operand in 0's and 1's or you can also say it is a representation of information such that 
the ISA has opcodes that operate on that representation

9 what are the two addressing modes of the ADD instruction of the LC-3? register mode and immediate mode

10. how is the immediate addressing mode different to the register mode? one of the two operands is contained in bits 4:0 of the instruction

11. there are many ISA's out there, do they have the same number of opcodes? 

12. how many instructions does the LC-3 have? 15; each identified by a unique opcode

13. there are 3 different types of instructions, what are they? operate, data movement, and control

14. what does each of the 3 different types of instruction do? operate instructions process information; data movement instructions move
data between registers to memory and between registers/memory and input/output devices; control instructions change the sequence of
instructions that will be executed

15. how do opcodes interpret bit patterns of an operand? according to the data type it is designed to support

16. An operand can generally be found in one of three places, what are they? in memory, in a register, or in an instruction

17. if an operand is part of an instruction, what do we refer to it as? a literal or an immediate operand

18. where does the term 'literal' come from? from the fact that the bits of the instruction literally form the operand

19. where does the term immediate come from? from the fact that we can obtain the operand immediately from the instruction i.e. we do Not
have to look elsewhere for it

20. what are the 5 addressing modes supported by the LC-3? literal (or immediate), register, PC-relative, indirect, and base + offset

21. operate instructions use two addressing modes, what are they? register and immediate

22. how many addressing modes do data movement instructions use? 4 of 5 of the addressing modes

23. how many 3 single bit registers does the LC-3 have and what are they called? 3; they are referred to as N, Z, and P

24. what do N, Z, and P stand for? N stands for negative, Z stands for zero, and P stands for positive

25. how are these 3 single bit registers used? they are individually set (set to 1) or cleared (set to 0) each time one of the eight GPR's
is written into as a result of execution of one of the operate instructions or one of the load instructions 

26. how do the operate and load instructions work with respect to the GPRs? each operate instruction performs a computation and writes
the result into a GPR; each load instruction reads the contents of a memory location and writes the value found there into a general
purpose register

27. what is the set of the 3 single bit registers referred to as? condition codes 

28. why are the 3 single bit registers referred to as condition codes? because the condition of the 3 bits is used to change the sequence
of execution of instructions in a computer program

29. how many source operands does the NOT instruction operate on and what addressing mode does it use for both source and destination? one;
register mode

30. in the NOT instruction, what must bits 5:0 contain? all 1's

31. what 2 addressing modes can be used to specify the second source operand for the AND and ADD instructions? register mode for one of the
source operands and the destination operand; second operand is specified by either register mode or as an immediate operand

32. which bit determines which addressing mode will be used for the second operand in the AND and ADD instructions? bit 5

33. if bit 5 is 0 which addressing mode is used and what are bits 4:3 set to? register mode; set to 0

34. if bit 5 is 1 which addressing mode is used and what is done to bits 4:0? literal or immediate mode; they are sign extended to 16 bits

35. what must happen at the end of executing the AND and ADD Instruction (infact for load intructions as well)? the condition codes must be set

36. what implication does using immediate addressing mode present? since the literal operand must fit into bits 4:0 of the instruction, not
all 2 complement integers can be used as immediate operands (range of -32 through to 16)

37. can a register can be used as a source and also as a destination in the same instruction? yes

38. what does the LEA instruction do? loads a register specified by bits 11:9 with an address specified by adding the PC + sign extended
bits 8:0 of the instruction (the address is not accessed)

39. what do data movement instructions do? move information between GPRs and memory and between GPRs and input/output devices

40. what do you call the process of moving information from memory to a register? loading

41. what do you call the process of moving information from a register to a memory? storing

42. how many instructions does the LC-3 contain for moving information? 6

43. how many operands do data movement instructions require? two operands

44. name these operands? a source (data to be moved) and a destination

45. what do bits 8:0 contain for data movement instructions? address generation bits i.e. information used to compute the 16 bit address
of the second operand

46. in the case of LC-3, how many ways are there to interpret bits 8:0 for data movement instructions? 3 ways that are called addressing
modes

47. what speciﬁes how to interpret bits [8:0] in data movement instructions? the opcode

48. what two data movement instructions specify the PC-relative addressing mode? LD and ST

49. why is the PC-relative addressing mode named as such? because bits 8:0 of the instruction specify an offset relative to the PC

50. how is the memory address computed in pc-relative addressing mode? by sign extending bit 8:0 to 16 bits and adding the result to the incremented PC

51. in this case, what happens if the instruction is LD? the computed address (PC + offset) specifies the memory to be accessed. its
contents are loaded into register specified by bits 11:9 of the instruction

52. what if the instruction is ST? the contents of the register specified by bits 11:9 of the instruction is written into the memory 
location whose address is PC + offset

53. what happens after either the LD or ST instruction has been executed? the N, Z, P condition codes are set

54. what stands about the address generated in pc-relative addressing mode using bits 8:0? the range is limited to within 256 and -256
of the ld and st instruction 

55. which two instructions use indirect addressing mode? LDI and STI

56. how are the LDI and STI operand addresses formed? the same way LD and ST are formed i.e. sign extending bits 8:0 from the instruction and 
adding it to the incremented value of the PC

57. how is the addressing mode of the LDI and STI instructions different from that of the LD and ST instructions? instead of it being
the address of the operand to be loaded or stored, it is the address of the address of the operand to be loaded or stored

58. where in the instruction is the destination register for the LDI instruction and the source register for the STI instruction found? in
bits 11:9

59. what is the difference between the indirect mode and PC relative addressing modes in terms of the address of the operand in a computers
memory? for indirect addressing mode, the address of the operand can be anywhere in the computers memory and not just within the range 
provided by bits 8:0 of the instruction

60. which two instructions use the base + offset addressing mode? LDR and STR

61. how does the base + offset addressing mode work? address of the operand is obtained by adding a sign extended six bit offset (5:0)
to a base register specified by bits 8:6 

62. does the Base+oﬀset addressing mode also allow the address of the operand to be anywhere in 
the computer’s memory like indirect addressing mode?

63. what do control instructions do? they change the sequence of instructions to be executed otherwise the next instruction fetched would
always be after the current instruction finishes in the next sequential memory location

64. how many opcodes does the LC-3 have that allow sequential execution flow to be broken? 5

65. can you name them? conditional branch, unconditional jump, subroutine call, TRAP, and RTI (return from trap or interrupt)

66. what does the TRAP instruction (often called service call) do? allows programmer to get help from operating system to do things that
the typical programmer does not understand how to do e.g. getting information from input device into the cpu, sending information to output
device. it breaks the sequential execution of a user program to start a sequence of instructions in the OS 

67. summarise how the conditional branch (BR which is opcode 0000) works? when executed it decides based on a test whether to execute the 
next instruction in memory or to jump to another instruction in a different part of the memory that was allocated to the program by the
OS

68. what stage of instruction cycle does the BR instruction decide whether to load the PC with a new address? in the EXECUTE stage; if  
nothing occurs in this stage then the incremented PC will remain unchanged and the next instruction executed will be the next instruction
in the sequence, otherwise a new address will be loaded

69. what is the decision whether to do nothing to the incremented PC or whether to change it based on? it is based on the execution of
previous instruction in the program which are reflected in the condition codes (the conditional branch's execute phase results in either doing 
nothing or it loads the PC with the address of the instruction it wishes to execute next) 

70. what is the format of the conditional branch instruction? bits 15:12 display the opcode which in this case is all 0's; bits 11:9
display the condition codes N, Z, P respectively; bits 8:0 are sign extended to make 16 bits which are then added to the PC

71. in the LC-3, what instructions write into the GPR's and also set the condition codes? the operate instructions (ADD, AND, and NOT)
and the three load instructions (LD, LDI, LDR)

72. what can you summise about the contents of bits 11:9 in the BR instruction and its operation? the BR instruction uses the information
to determine whether to depart from the usual sequential execution of instructions that we get as a result of incrementing the PC during
the FETCH phase of each instruction

73. how does the above happen? during the EXECUTE phase of the BR instruction cycle, the processor examines the condition codes whose
associted bits in the instruction bits 11:9 are 1. if bit 11 is 1 then condition code N is examined; if bit 10 is 1 then condition code
Z is examined; similar action is taken for bit 9. if any of the bits 11:9 are 0 then the associated condition codes are not examined. if
any of the condition codes examined are set, then the PC is loaded with the address obtained in the EVALUTE ADDRESS phase. if none of the 
condition codes that are examined are set, the incremented PC is left unchanged

74. how is the address obtained during the EVALUATE ADDRESS phase generated? using PC-relative addressing mode

75. why is the uconditonal branch named so? because all bits 11:9 are set to 1 ergo all conditions are examined based on the
output of the previous instruction. ergo the instruction flow is changed unconditionally, independent ofthe data

76. there are two methods of loop control, name them: loop control with a counter and loop control with a sentinel

77. what is the difference between the two? a counter will control the number of times a loop executes by being decremented in
each cycle and then checked to see if it is zero (conditional branch instruction). if not the loop body is executed again; otherwise 
next instruction to be executed is after the last instruction of the loop body. on the other hand, sentinels are used when we do
not know beforehand how many iterations we will want to perform; each iteration will be based on processing a value and when the
sentinel is encountered the loop is broken

78. what is the limitation of the conditional branch instruction? the next instruction that it loads the PC with (computed from 
sign-extending bits 8:0 and adding them to the incremented PC) can be at most +256 or -256 locations from the currently executing branch 
instruction

79. what if you want to execute an instruction that is 2000 locations from the BR instruction? you cannot use the BR instruction
since you cannot fit 2000 into the 9 bit field 

80. what instruction provided by the LC-3 can do the above? the jmp instruction

81. how does it work? the jmp instruction loads the PC with the contents of the register specified by bits 8:6

82. how the TRAP instruction work? it changes the PC to a memory address that is part of the operating system so that the
OS will perform some task on behalf of the executing program. it is said to invoke an operating system service call

83. how are the bits arranged in the TRAP instruction? bits 7:0 form the trap vector; which is an eight bit code that
identifies the os service call 

84. what happens after an os finishes executing a service call? the PC is set to the address of the instruction following the 
TRAP instruction thereby allowing a program to resume execution

85. what are the basic components of the data path? the global bus, memory, the alu and the register file, the pc and the pcmux,
and the marmux

86. what does the LC-3 global bus consist of? 16 wires and associated electronics

87. what is the global bus used for? allows one structure to transfer upto 16 bits of information to another structure by making
the necessary electronic connections on the bus. exactly one value can be transferred on the bus at one time. each structure that 
supplies a signal to the bus has a triangle just behind its input arrow to the bus

88. what is this triangle called? the tri-state device

89. what is it used for? allows the computer's control logic to enable exactly one supplier to provide information
to the bus at one time. the structure wishing to obtain the value being supplied can do so by asserting its ld.x (load enable)
signal

90. how does memory work? it contains both instructions and data. it is accessed by loading the MAR with the address of the 
location to be accessed. control signals then read the contents of that memory location and the result of that read
is stored in the MDR

91. how does it work when it comes to storing? value to be stored in loaded into the MDR. the control signals then assert a WE signal
in order to store the value contained in the MDR in the memory location specified by the MAR

92. how does the ALU work? as the processing element, it has two inputs, source 1 from a register and source 2 from either
a register or the sign-extended immediate value provided by the instruction

93. what happens at the start of each instruction cycle? the PC supplies the MAR via the global bus the address of the instruction to be
fetched 

94. the PC is supplied via the three-to-one PCMUX. how is this three-to-one MUX configured? the rightmost input to the PCMUX is used to
increment and write into the PC by one; when a control signal such as BR is executed and the sign-extended bits 8:0 are added to the incremented
PC (addition takes place in a separate adder not the ALU), the output of this adder is the middle input to the PCMUX; the third input to the 
PCMUX is obtained from the global bus

95. what does the MARMUX component do? it controls which source out of two will supply the MAR with the appropriate address during
the execution of a load, a store, or a TRAP instruction. The right input to the MARMUX is obtained by adding either the incremented PC or
a base register to zero or a literal value supplied by the IR. Whether the PC or a base register and what literal value depends on which 
opcode is being processed. The control signal ADDR1MUX speciﬁes the PC or base register. The control signal ADDR2MUX speciﬁes which of four 
values is to be added.

chapter 6

1. what two things will you learn about in this chapter? develop a methodology for constructing
programs to solve problems and develop a methodology for fixing said programs under the 
likely condition that i did not get things right the first time

2. what is structured programming? methodology developed in the 60s to dramatically improve
the ability of average programmers to take a complex description of a problem and systematically
decompose it into smaller manageable units so that they could ultimately write a program 
that executed correctly

3. what is the methodology also called? systematic decomposition

4. define the systematic decomposition/ stepwise refinement process? process of taking A
unit of work and breaking it into smaller units of work such that the collection of smaller
units carries out the same task as the larger unit.

5. what is the essential idea behind systematic decomposition or stepwise refinement?
replace a larger unit of work with a construct that correctly decomposes it

6. how many constructs are there for doing this? 3

7. what are they called? sequential, conditional, and iterative

chapter 7

1. mechanical languages are generally partitioned into two classes. what are they? high level and low level

2. describe high level languaages? are more user friendly, almost resemble statements in natural languge such as english

3. what must happen before a program that is written in a high-level language can be executed? it must be translated into a program
in the ISA of the computer on which it is expected to execute

4. is it often the case that each statement in a high level language specifies several instructions in the ISA of a computer? yes

5. what do you call the small step up from the ISA of a machine? the ISAs assembly language

6. what is assembly language? a low level language which cannot be confused with a statement in english language. it is ISA dependent
i.e. each ISA has only one assembly language 

7. does each assembly language instruction usually specify a single instruction in the ISA? yes

8. what is the purpose of assembly language? to make the programming process more user friendly than programming in machine language
i.e. in the ISA of the computer you are working on while providing the programmer with detailed control over the instructions the
computer can execute

9. what does assembly language do that help the program avoid minutae? let us use mnemonic devices for opcodes and give meaningful 
symbolic names to memory locations (they are called symbolic addresses)

10. what do you lose when you use a high level language like C? whilst it is user friendly you relinquish control over which ISA instruction
are to be used to carry out the work specified by the high level statement

11. what are pseudo ops (assembler directives)? message from the programmer to the translation program to help in the translation 
process (translating a program represented by a string of characters in assembly language to machine language)

12. what is the translation program that is used to translate assembly programs to machine language? assembler

13. what is the translation process called? assembly

14. instead of an instruction being 16 0's and 1's as is the case of the LC-3 ISA, an instruction in assembly language consists of 
four parts. what are they called? label, opcode, operands, comment

15. which two are optional? label and comment

16. in LC-3 assembly language, why are symbolic names called labels are assigned to memory locations? so that we do not have to remember
explicit 16 bit addresses

17. for literal values in assembly language that are used as operands in assembly language, how will know a number is a decimal,
hex, or a binary? decimal numbers will be preceeded by #, binary by b, and hex by X

18. what are the two reasons for explicitly referring to a memory location using a label? the location is a target of a branch 
instruction and the location contains a value that is loaded or stored

19. how many pseudo-ops does the LC-3 assembly language contain? 5

20 what are they? .ORIG, .FILL, .BLKW, .STRINGZ, and .END.

21. what does the .ORIG pseudo-op do? it tells the assembler where in memory to place the LC-3 program i.e. first instruction is placed
in the memory addressed specified, whilst the rest of the instructions in the program are placed in subsequent sequential locations.

22. what does the .FILL pseudo-op do? tells the assembler to set aside the next location in the program and initialise it with the value
of the operand. the value can either be a number or a label

23. what does the .BLKW pseudo op do? tells the assembler to set aside some number of sequential memory locations in the program. The
actual number is the operand of the .BLKW pseudo op

24. what does the .STRINGZ pseudo op do? tells the assembler to initialise a sequence of n+1 memory locations. The argument is a 
sequence of n characters inside double quotation marks. first n words of memory are initialised with zero extended ascii codes of the
corresponding characters in the string. final word of memory is initialised to 0

25. what does the .END pseudo op do? tells the assembler it has reached the end of the program and need not look at anything after it

26. how does the assembly process unfold? it is done in two complete passes (from beginning to .END) through the entire assembly language
program. the objective of the first pass is to identify the actual binary addresses corresponding to the symbolic names (or labels).
this is set of correspondences is known as the symbol table. in pass 2, we translate the individual assembly language instructions
into their corresponding machine language instructions

27. why are labels used in assembly language? to refer to memory locations either because it is a target of a branch instruction or because
it contains data that must be loaded or stored

28. how does the lc-3 assembler keep track of the location assigned to  each instruction? by meaans of the location counter. it is 
initialised to the address specified in .ORIG

29. when a computer begins execution of a program, what is the entity being executed called? executable image

30. what is the executable image created from? from modules created independently by individual pogrammers where each module is 
translated separately into an object file

31. are all modules written by users? no, some are supplied as library routines by the operating system

32. what does each object file consist of? instructions in the ISA of the computer being used along with its associated data

33. what is normally the final step? combining (linking) all of the object modules together into one executable image

34. what happens during the execution of the program? the fetch, decode... instruction cycle is applied to instructions in the executable
image

35. what does the pseudo-op .EXTERNAL do? identifies the symbolic name of an address that is not known at the time a program is 
assembled. it sends a message to the LC-3 assembler that the absence of a symbolic label is not an error in the program i.e. the 
symbolic name is a label in another module that will be translated independently. it allows references by one module to symbolic 
references in another module without a problem

chapter 8

1. how many instructions does the call/return mechanism consist of? two instructions

2. what is the first instruction? JSR(R) is in the caller program

3. what does the JSR(R) instruction do? it loads the PC with the starting address of the subroutine and it loads R7 with the address
immediately after the address of the JSR(R) instruction. the address immediately after the address of the JSR(R) instruction is
the address to come back to after executing the subroutine

4. what name is given to the address we come back to? return linkage

5. what is the second instruction? JMP R7; which happens to be the laast instruction in the subroutine

6. what does this instruction do? it loads the PC with the contents of R7, the address just after the address of the JSR instruction
thereby completing the round trip flow of control from the caller to the callee and back

7. the LC-3 specifies one control instruction for calling subroutines; what is it called? JSR

8. how many addressing modes does the JSR(R) control instruction have for computing the starting address of a subroutine? 2

9. what are the addressing modes? PC-relative addressing and base register addressing

10. what are the two things that the JSR(R) instruction does? loads the PC hence overwriting the incremented PC that was loaded 
during the fetch phase of the JSR(R) instruction and then it saves the return address in R7

11. what is the return address that is saved in R7? it is the incremented PC which is the address of the instruction following the
JSR(R) instruction

12. how many parts does the JSR(R) instruction consist of? 3 parts

13. what are the 3 parts? bits 15:12 specify the opcode; bit 11 specifies what addressing mode will be used (1 for PC-relative); bits
10:0 are the address evaluation bits

14. how does the JSR instruction compute the target address of a subroutine? by sign-extending the 11 bit offset (bits 10:0) of the
instruction to 16 bits and adding it to the incremented PC

15. What other control instruction shares a addressing mode? the BR instruction except in this instruction 9 bits are sign extended 
instead of 11 bits

16. how does the JSRR instruction differ from the JSR instruction? the addressing mode used;  it obtains the starting address of A
subroutine in exactly the same way that the JMP instruction  does i.e. bits 8:6 identify the base register that contains the address 
to be loaded into the PC

17. what problems do  subroutines pose when it comes to registers? they overwrite the contents of a register and therefore if the 
contents that were overwritten are needed by the caller program then you have a major problem at hand

18. how is the above problem aavoided? by having either the subroutine save the contents of the registers it will overwrite and restore
them before it finishes executing or have the caller program save the contents of the registers it is using before it invokes a 
subroutine and restore the contents when the subroutine has finished executing

19. of the two options, which is more efficient? having the callee program (the subroutine) save the contents of the registers is
more efficient because it knows which registers it will overwrite. The caller program has no way of knowing this in advance

20. what is the technique called? callee save

21. is the caller program or the callee program responsible for saving and restoring the contents of R7? the caller is responsible 
since it alone is capable of overwriting the value in R7 after the subroutine returns

22. what do we call the above process? caller save

23. what are some of the uses of the call/return mechanism expanded on above? ability of a user program to call library routines
that are part of the OS

24. can the stack (abstract data type), be implemented in many different ways? yes

25. what makes stack special? LIFO i.e. specification of how it is to be accessed that is the last thing that you stored in a stack 
is the first thing that you remove from it

26. what is the definition of an abstract data type? a storage mechanism that is defined by the operations performed on it and not
by the specific manner in which it is implemented

27. how is a stack implemented in computer memory? consists of a sequence of memory locations along with a mechanism called a stack
pointer which keeps track of the top of the stack

28. how are values inserted into the stack stored? they are stored in memory locations having decreasing addresses i.e. the stack 
grows towards zero.

30. when values are pushed and popped to and from the stack implemented in sequential memory locations, does the data already stored
on the stack physically move? no

31. in the LC-3, what is process of pushing a value onto a stack? first load the value into R0, then decrement the value in R6 
(which contains the memory address of the stack pointer) 

32. in the LC-3, what is the process of popping a value from the stack? the value is read and the stack pointer is incremented

33. what is the fancy name given to the rules that the stack follows? stack protocol

34. what does attempting to pop items that have not been previously pushed result in? underflow

35. What happens when we run out of available space and we try to push a value onto the stack? result in an overflow
